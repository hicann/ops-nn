# aclnnDynamicDualLevelMxQuant

[ğŸ“„ æŸ¥çœ‹æºç ](https://gitcode.com/cann/ops-nn/tree/master/quant/dynamic_dual_level_mx_quant)

## äº§å“æ”¯æŒæƒ…å†µ

| äº§å“                                                         | æ˜¯å¦æ”¯æŒ |
| :----------------------------------------------------------- | :------: |
| <term>Ascend 950PR/Ascend 950DT</term>                             |    âˆš     |
| <term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>     |    Ã—     |
| <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas A2 æ¨ç†ç³»åˆ—äº§å“</term> |    Ã—     |
| <term>Atlas 200I/500 A2 æ¨ç†äº§å“</term>                      |    Ã—     |
| <term>Atlas æ¨ç†ç³»åˆ—äº§å“</term>                             |    Ã—     |
| <term>Atlas è®­ç»ƒç³»åˆ—äº§å“</term>                              |    Ã—     |

## åŠŸèƒ½è¯´æ˜

- æ¥å£åŠŸèƒ½ï¼šç›®çš„æ•°æ®ç±»å‹ä¸ºFLOAT4ç±»çš„MXé‡åŒ–ã€‚åªå¯¹å°¾è½´è¿›è¡Œé‡åŒ–ï¼Œå‰é¢æ‰€æœ‰çš„è½´éƒ½åˆè½´å¤„ç†ï¼Œé€šè¿‡ç»™å®šçš„level0BlockSizeå°†è¾“å…¥åˆ’åˆ†æˆå¤šä¸ªæ•°æ®å—ï¼Œå¯¹æ¯ä¸ªæ•°æ®å—è¿›è¡Œä¸€çº§é‡åŒ–ï¼Œè¾“å‡ºé‡åŒ–å°ºåº¦level0ScaleOutï¼›ç„¶åå°†ä¸€çº§é‡åŒ–çš„ç»“æœä½œä¸ºæ–°çš„è¾“å…¥ï¼Œå¹¶é€šè¿‡ç»™å®šçš„level1BlockSizeå°†å…¶åˆ’åˆ†æˆå¤šä¸ªæ•°æ®å—ï¼Œå¯¹æ¯ä¸ªæ•°æ®å—è¿›è¡ŒäºŒçº§é‡åŒ–ï¼Œè¾“å‡ºé‡åŒ–å°ºåº¦level1ScaleOutï¼Œæ ¹æ®round_modeè¿›è¡Œæ•°æ®ç±»å‹çš„è½¬æ¢ï¼Œå¾—åˆ°é‡åŒ–ç»“æœyOutï¼Œå…·ä½“å‚è§[å›¾ç¤º](../../../docs/zh/figures/DynamicDualLevelMxQuant.png)ã€‚

- è®¡ç®—å…¬å¼ï¼š
  - å°†è¾“å…¥xåœ¨å°¾è½´ä¸ŠæŒ‰$k_0$ = level0BlockSizeä¸ªæ•°åˆ†ç»„ï¼Œä¸€ç»„$k_0$ä¸ªæ•°  $\{\{x_i\}_{i=1}^{k_0}\}$ åŠ¨æ€é‡åŒ–ä¸º $\{level0Scale, \{temp_i\}_{i=1}^{k_0}\}$, $k_0$ = level0BlockSizeï¼Œç„¶åå°†tempåœ¨å°¾è½´ä¸ŠæŒ‰$k_1$ = level1BlockSizeä¸ªæ•°åˆ†ç»„ï¼Œä¸€ç»„$k_1$ä¸ªæ•°  $\{\{temp_i\}_{i=1}^{k_1}\}$ åŠ¨æ€é‡åŒ–ä¸º $\{level1Scale, \{y_i\}_{i=1}^{k_1}\}$, $k_1$ = level1BlockSize

  $$
  input\_max_i = max_i(abs(x_i))
  $$

  $$
  level0Scale = input\_max_i / (FP4\_E2M1\_MAX)
  $$

  $$
  temp_i = cast\_to\_x\_type(x_i / level0Scale), \space i\space from\space 1\space to\space level0BlockSize
  $$

  $$
  shared\_exp = floor(log_2(max_i(|temp_i|))) - emax
  $$

  $$
  level1Scale = 2^{shared\_exp}
  $$

  $$
  y_i = cast\_to\_FP4\_E2M1(temp_i/level1Scale, round\_mode), \space i\space from\space 1\space to\space level1BlockSize
  $$

  - â€‹é‡åŒ–åçš„ $y_{i}$ æŒ‰å¯¹åº”çš„ $x_{i}$ çš„ä½ç½®ç»„æˆè¾“å‡ºyOutï¼Œlevel0ScaleæŒ‰å°¾è½´å¯¹åº”çš„åˆ†ç»„ç»„æˆè¾“å‡ºlevel0ScaleOutï¼Œlevel1ScaleæŒ‰å°¾è½´å¯¹åº”çš„åˆ†ç»„ç»„æˆè¾“å‡ºlevel1ScaleOutã€‚

  - max_iä»£è¡¨æ±‚ç¬¬iä¸ªåˆ†ç»„ä¸­çš„æœ€å¤§å€¼

  - emax: å¯¹åº”æ•°æ®ç±»å‹çš„æœ€å¤§æ­£åˆ™æ•°çš„æŒ‡æ•°ä½ã€‚

      |   DataType    | emax |
      | :-----------: | :--: |
      |  FLOAT4_E2M1  |  2   |

## å‡½æ•°åŸå‹

æ¯ä¸ªç®—å­åˆ†ä¸º[ä¸¤æ®µå¼æ¥å£](../../../docs/zh/context/ä¸¤æ®µå¼æ¥å£.md)ï¼Œå¿…é¡»å…ˆè°ƒç”¨â€œaclnnDynamicDualLevelMxQuantGetWorkspaceSizeâ€æ¥å£è·å–è®¡ç®—æ‰€éœ€workspaceå¤§å°ä»¥åŠåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹çš„æ‰§è¡Œå™¨ï¼Œå†è°ƒç”¨â€œaclnnDynamicDualLevelMxQuantâ€æ¥å£æ‰§è¡Œè®¡ç®—ã€‚

```cpp
aclnnStatus aclnnDynamicDualLevelMxQuantGetWorkspaceSize(
  const aclTensor *x, 
  const aclTensor *smoothScaleOptional, 
  char            *roundModeOptional, 
  int64_t          level0BlockSize, 
  int64_t          level1BlockSize, 
  aclTensor       *yOut, 
  aclTensor       *level0ScaleOut, 
  aclTensor       *level1ScaleOut, 
  uint64_t        *workspaceSize, 
  aclOpExecutor   **executor)
```

```cpp
aclnnStatus aclnnDynamicDualLevelMxQuant(
  void          *workspace, 
  uint64_t       workspaceSize, 
  aclOpExecutor *executor, 
  aclrtStream    stream)
```

## aclnnDynamicDualLevelMxQuantGetWorkspaceSize

- **å‚æ•°è¯´æ˜ï¼š**
  <table style="undefined;table-layout: fixed; width: 1550px"><colgroup>
  <col style="width: 240px">
  <col style="width: 120px">
  <col style="width: 271px">
  <col style="width: 330px">
  <col style="width: 223px">
  <col style="width: 101px">
  <col style="width: 190px">
  <col style="width: 145px">
  </colgroup>
  <thead>
    <tr>
      <th>å‚æ•°å</th>
      <th>è¾“å…¥/è¾“å‡º</th>
      <th>æè¿°</th>
      <th>ä½¿ç”¨è¯´æ˜</th>
      <th>æ•°æ®ç±»å‹</th>
      <th>æ•°æ®æ ¼å¼</th>
      <th>ç»´åº¦(shape)</th>
      <th>éè¿ç»­Tensor</th>
    </tr></thead>
  <tbody>
    <tr>
      <td>x (aclTensor*)</td>
      <td>è¾“å…¥</td>
      <td>è¡¨ç¤ºè¾“å…¥xï¼Œå¯¹åº”å…¬å¼ä¸­<em>x</em><sub>i</sub>ã€‚</td>
      <td><ul><li>xçš„æœ€åä¸€ç»´å¿…é¡»æ˜¯å¶æ•°ï¼›</li><li> ä¸æ”¯æŒç©ºTensorã€‚</td>
      <td>FLOAT16ã€BFLOAT16</td>
      <td>ND</td>
      <td>1-7</td>
      <td>âˆš</td>
    </tr>
    <tr>
      <td>smoothScalesOptional (aclTensor*)</td>
      <td>è¾“å…¥</td>
      <td>è¡¨ç¤ºå¯é€‰è¾“å…¥smoothScaleOptionalã€‚</td>
      <td>å½“å‰è¯¥åŠŸèƒ½æš‚ä¸æ”¯æŒï¼Œåªæ”¯æŒè¾“å…¥ä¸ºnullptrã€‚</td>
      <td>å’Œè¾“å…¥xä¸€è‡´</td>
      <td>ND</td>
      <td>1</td>
      <td>âˆš</td>
    </tr>
    <tr>
      <td>roundModeOptional (char*) </td>
      <td>è¾“å…¥</td>
      <td>è¡¨ç¤ºæ•°æ®è½¬æ¢çš„æ¨¡å¼ï¼Œå¯¹åº”å…¬å¼ä¸­çš„round_modeã€‚</td>
      <td><ul><li>æ”¯æŒ{"rint", "round", "floor"}ï¼›</li><li> é»˜è®¤å€¼ä¸º"rint"ã€‚</li></ul></td>
      <td>STRING</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td>level0BlockSize (int64_t)</td>
      <td>è¾“å…¥</td>
      <td>è¡¨ç¤ºç¬¬ä¸€çº§é‡åŒ–çš„block_sizeï¼Œå¯¹åº”å…¬å¼ä¸­çš„level0BlockSizeã€‚</td>
      <td>è¾“å…¥èŒƒå›´ä¸º{512}ã€‚</td>
      <td>INT64</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td>level1BlockSize (int64_t)</td>
      <td>è¾“å…¥</td>
      <td>è¡¨ç¤ºç¬¬äºŒçº§é‡åŒ–çš„block_sizeï¼Œå¯¹åº”å…¬å¼ä¸­çš„level1BlockSizeã€‚</td>
      <td>è¾“å…¥èŒƒå›´ä¸º{32}ã€‚</td>
      <td>INT64</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td>yOut (aclTensor*)</td>
      <td>è¾“å‡º</td>
      <td>è¡¨ç¤ºè¾“å…¥xé‡åŒ–åçš„å¯¹åº”ç»“æœï¼Œå¯¹åº”å…¬å¼ä¸­çš„<em>y</em><sub>i</sub>ã€‚</td>
      <td><ul><li>shapeå’Œè¾“å…¥xä¸€è‡´ï¼›</li><li> ä¸æ”¯æŒç©ºTensorã€‚</li></ul></td>
      <td>FLOAT4_E2M1</td>
      <td>ND</td>
      <td>1-7</td>
      <td>âˆš</td>
    </tr>
    <tr>
      <td>level0ScaleOut (aclTensor*)</td>
      <td>è¾“å‡º</td>
      <td>è¡¨ç¤ºç¬¬ä¸€çº§é‡åŒ–çš„scaleï¼Œå¯¹åº”å…¬å¼ä¸­çš„level0Scaleã€‚</td>
      <td><ul><li>shapeåœ¨å°¾è½´ä¸Šçš„å€¼ï¼Œä¸ºxå°¾è½´çš„å€¼é™¤ä»¥level0BlockSizeå‘ä¸Šå–æ•´ï¼›</li><li> ä¸æ”¯æŒç©ºTensorã€‚</li></ul></td>
      <td>FLOAT32</td>
      <td>ND</td>
      <td>1-7</td>
      <td>âˆš</td>
    </tr>
    <tr>
      <td>level1ScaleOut (aclTensor*)</td>
      <td>è¾“å‡º</td>
      <td>è¡¨ç¤ºç¬¬äºŒçº§é‡åŒ–çš„scaleï¼Œå¯¹åº”å…¬å¼ä¸­çš„level1Scaleã€‚</td>
      <td><ul><li>shapeçš„å¤§å°ä¸ºxçš„dim + 1ï¼›</li><li> shapeåœ¨æœ€åä¸¤è½´çš„å€¼ä¸º((ceil(x.shape[-1] / level1Blocksize) + 2 - 1) / 2, 2)ï¼Œå¹¶å¯¹å…¶è¿›è¡Œå¶æ•°padï¼Œpadå¡«å……å€¼ä¸º0ï¼›</li><li> ä¸æ”¯æŒç©ºTensorã€‚</li></ul></td>
      <td>FLOAT8_E8M0</td>
      <td>ND</td>
      <td>1-8</td>
      <td>âˆš</td>
    </tr>
    <tr>
      <td>workspaceSize</td>
      <td>è¾“å‡º</td>
      <td>è¿”å›éœ€è¦åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ã€‚</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td>executor</td>
      <td>è¾“å‡º</td>
      <td>è¿”å›opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
    </tr>
  </tbody>
  </table>


- **è¿”å›å€¼ï¼š**

  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

  ç¬¬ä¸€æ®µæ¥å£å®Œæˆå…¥å‚æ ¡éªŒï¼Œå‡ºç°ä»¥ä¸‹åœºæ™¯æ—¶æŠ¥é”™ï¼š

  <table style="undefined;table-layout: fixed;width: 1155px"><colgroup>
  <col style="width: 253px">
  <col style="width: 126px">
  <col style="width: 677px">
  </colgroup>
  <thead>
    <tr>
      <th>è¿”å›ç </th>
      <th>é”™è¯¯ç </th>
      <th>æè¿°</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ACLNN_ERR_PARAM_NULLPTR</td>
      <td>161001</td>
      <td>xå­˜åœ¨ç©ºæŒ‡é’ˆã€‚</td>
    </tr>
    <tr>
      <td rowspan="3">ACLNN_ERR_PARAM_INVALID</td>
      <td rowspan="3">161002</td>
      <td>xã€smoothScaleOptionalã€yOutã€level0ScaleOutã€level1ScaleOutçš„æ•°æ®ç±»å‹å’Œæ•°æ®æ ¼å¼ä¸åœ¨æ”¯æŒçš„èŒƒå›´ä¹‹å†…ã€‚</td>
    </tr>
    <tr>
      <td>xã€smoothScaleOptionalã€yOutã€level0ScaleOutæˆ–level1ScaleOutçš„shapeä¸æ»¡è¶³æ ¡éªŒæ¡ä»¶ã€‚</td>
    </tr>
    <tr>
      <td>roundModeOptionalã€level0BlockSizeã€level1BlockSizeä¸ç¬¦åˆå½“å‰æ”¯æŒçš„å€¼ã€‚</td>
    </tr>
    <tr>
      <td>ACLNN_ERR_RUNTIME_ERROR</td>
      <td>361001</td>
      <td>å½“å‰å¹³å°ä¸åœ¨æ”¯æŒçš„å¹³å°èŒƒå›´å†…ã€‚</td>
    </tr>
  </tbody></table>

## aclnnDynamicDualLevelMxQuant

- **å‚æ•°è¯´æ˜ï¼š**
  <table style="undefined;table-layout: fixed; width: 953px"><colgroup>
  <col style="width: 173px">
  <col style="width: 112px">
  <col style="width: 668px">
  </colgroup>
  <thead>
    <tr>
      <th>å‚æ•°å</th>
      <th>è¾“å…¥/è¾“å‡º</th>
      <th>æè¿°</th>
    </tr></thead>
  <tbody>
    <tr>
      <td>workspace</td>
      <td>è¾“å…¥</td>
      <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå†…å­˜åœ°å€ã€‚</td>
    </tr>
    <tr>
      <td>workspaceSize</td>
      <td>è¾“å…¥</td>
      <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ï¼Œç”±ç¬¬ä¸€æ®µæ¥å£aclnnDynamicDualLevelMxQuantGetWorkspaceSizeè·å–ã€‚</td>
    </tr>
    <tr>
      <td>executor</td>
      <td>è¾“å…¥</td>
      <td>opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
    </tr>
    <tr>
      <td>stream</td>
      <td>è¾“å…¥</td>
      <td>æŒ‡å®šæ‰§è¡Œä»»åŠ¡çš„Streamã€‚</td>
    </tr>
  </tbody>
  </table>

- **è¿”å›å€¼ï¼š**

  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

## çº¦æŸè¯´æ˜

- å…³äºxã€level0ScaleOutã€level1ScaleOutçš„shapeçº¦æŸè¯´æ˜å¦‚ä¸‹ï¼š
    - rank(level1ScaleOut) = rank(x) + 1ã€‚
    - level0ScaleOut.shape[-1] = ceil(x.shape[-1] / level0Blocksize)ã€‚
    - level1ScaleOut.shape[-2] = (ceil(x.shape[-1] / level1Blocksize) + 2 - 1) / 2ã€‚
    - level1ScaleOut.shape[-1] = 2ã€‚
    - å…¶ä»–ç»´åº¦ä¸è¾“å…¥xä¸€è‡´ã€‚
- ç¡®å®šæ€§è¯´æ˜ï¼šaclnnDynamicDualLevelMxQuanté»˜è®¤ç¡®å®šæ€§å®ç°ã€‚


## è°ƒç”¨ç¤ºä¾‹

ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼Œä»…ä¾›å‚è€ƒï¼Œå…·ä½“ç¼–è¯‘å’Œæ‰§è¡Œè¿‡ç¨‹è¯·å‚è€ƒ[ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹](../../../docs/zh/context/ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹.md)ã€‚

  ```Cpp
  #include <iostream>
  #include <memory>
  #include <vector>
  
  #include "acl/acl.h"
  #include "aclnnop/aclnn_dynamic_dual_level_mx_quant.h"
  
  #define CHECK_RET(cond, return_expr) \
      do {                             \
          if (!(cond)) {               \
              return_expr;             \
          }                            \
      } while (0)
  
  #define CHECK_FREE_RET(cond, return_expr) \
      do {                                  \
          if (!(cond)) {                    \
              Finalize(deviceId, stream);   \
              return_expr;                  \
          }                                 \
      } while (0)
  
  #define LOG_PRINT(message, ...)         \
      do {                                \
          printf(message, ##__VA_ARGS__); \
      } while (0)
  
      int64_t
      GetShapeSize(const std::vector<int64_t>& shape)
  {
      int64_t shapeSize = 1;
      for (auto i : shape) {
          shapeSize *= i;
      }
      return shapeSize;
  }
  
  int Init(int32_t deviceId, aclrtStream* stream)
  {
      // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
      auto ret = aclInit(nullptr);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
      ret = aclrtSetDevice(deviceId);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
      ret = aclrtCreateStream(stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
      return 0;
  }
  
  template <typename T>
  int CreateAclTensor(const std::vector<T>& hostData, const std::vector<int64_t>& shape, void** deviceAddr,
                      aclDataType dataType, aclTensor** tensor)
  {
      auto size = GetShapeSize(shape) * sizeof(T);
      // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
      auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);
      // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®æ‹·è´åˆ°deviceä¾§å†…å­˜ä¸Š
      ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);
  
      // è®¡ç®—è¿ç»­tensorçš„strides
      std::vector<int64_t> strides(shape.size(), 1);
      for (int64_t i = shape.size() - 2; i >= 0; i--) {
          strides[i] = shape[i + 1] * strides[i + 1];
      }
  
      // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
      *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_ND,
                                shape.data(), shape.size(), *deviceAddr);
      return 0;
  }
  
  void Finalize(int32_t deviceId, aclrtStream stream)
  {
      aclrtDestroyStream(stream);
      aclrtResetDevice(deviceId);
      aclFinalize();
  }
  
  int aclnnDynamicDualLevelMxQuantTest(int32_t deviceId, aclrtStream& stream)
  {
      auto ret = Init(deviceId, &stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);
  
      // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
      std::vector<int64_t> xShape = {1, 512};
      std::vector<int64_t> smoothScaleOptionalShape = {1};
      std::vector<int64_t> yOutShape = {1, 512};
      std::vector<int64_t> level0ScaleOutShape = {1, 1};
      std::vector<int64_t> level1ScaleOutShape = {1, 8, 2};
      void* xDeviceAddr = nullptr;
      void* smoothScaleOptionalDeviceAddr = nullptr;
      void* yOutDeviceAddr = nullptr;
      void* level0ScaleOutDeviceAddr = nullptr;
      void* level1ScaleOutDeviceAddr = nullptr;
      aclTensor* x = nullptr;
      aclTensor* smoothScaleOptional = nullptr;
      aclTensor* yOut = nullptr;
      aclTensor* level0ScaleOut = nullptr;
      aclTensor* level1ScaleOut = nullptr;

      // å¯¹åº” BF16 çš„å€¼ (0->0, 16640->8, 17024->64, 17408->512)
      std::vector<uint16_t> xHostData(512, 16640);
      std::vector<uint16_t> smoothScaleOptionalHostData = {0};
      // å¯¹åº” float4_e2m1 çš„å€¼ (0->0, 72->4, 96->32, 120->256)
      std::vector<uint8_t> yOutHostData(512, 0);
      // å¯¹åº” float32 çš„å€¼ (0->0)
      std::vector<float> level0ScaleOutHostData = {{0}};
      //å¯¹åº”float8_e8m0çš„å€¼(128->2)
      std::vector<std::vector<std::vector<uint8_t>>> level1ScaleOutHostData(1, std::vector<std::vector<uint8_t>>(8, std::vector<uint8_t>(2, 0)));
      const char* roundModeOptional = "rint";
      int64_t level0Blocksize = 512;
      int64_t level1Blocksize = 32;

      // åˆ›å»ºx aclTensor
      ret = CreateAclTensor(xHostData, xShape, &xDeviceAddr, aclDataType::ACL_BF16, &x);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> xTensorPtr(x, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void*)> xDeviceAddrPtr(xDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºsmoothScaleOptional aclTensor
      ret = CreateAclTensor(smoothScaleOptionalHostData, smoothScaleOptionalShape, &smoothScaleOptionalDeviceAddr, aclDataType::ACL_BF16, &smoothScaleOptional);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> smoothScaleOptionalTensorPtr(smoothScaleOptional, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void*)> smoothScaleOptionalDeviceAddrPtr(smoothScaleOptionalDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºyOut aclTensor
      ret = CreateAclTensor(yOutHostData, yOutShape, &yOutDeviceAddr, aclDataType::ACL_FLOAT4_E2M1, &yOut);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> yOutTensorPtr(yOut, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void*)> yOutDeviceAddrPtr(yOutDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºlevel0ScaleOut aclTensor
      ret = CreateAclTensor(level0ScaleOutHostData, level0ScaleOutShape, &level0ScaleOutDeviceAddr, aclDataType::ACL_FLOAT, &level0ScaleOut);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> level0ScaleOutTensorPtr(level0ScaleOut, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void*)> level0ScaleOutDeviceAddrPtr(level0ScaleOutDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºlevel1ScaleOut aclTensor
      ret = CreateAclTensor(level1ScaleOutHostData, level1ScaleOutShape, &level1ScaleOutDeviceAddr, aclDataType::ACL_FLOAT8_E8M0, &level1ScaleOut);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> level1ScaleOutTensorPtr(level1ScaleOut, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void*)> level1ScaleOutDeviceAddrPtr(level1ScaleOutDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
     
      // è°ƒç”¨CANNç®—å­åº“APIï¼Œéœ€è¦ä¿®æ”¹ä¸ºå…·ä½“çš„Apiåç§°
      uint64_t workspaceSize = 0;
      aclOpExecutor* executor;
   
      // è°ƒç”¨aclnnDynamicDualLevelMxQuantç¬¬ä¸€æ®µæ¥å£
      ret = aclnnDynamicDualLevelMxQuantGetWorkspaceSize(x, smoothScaleOptional, (char*)roundModeOptional, level0Blocksize, level1Blocksize, yOut, level0ScaleOut, level1ScaleOut, &workspaceSize, &executor);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnDynamicDualLevelMxQuantGetWorkspaceSize failed. ERROR: %d\n", ret);
                return ret);
      // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
      void* workspaceAddr = nullptr;
      std::unique_ptr<void, aclError (*)(void*)> workspaceAddrPtr(nullptr, aclrtFree);
      if (workspaceSize > 0) {
          ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
          CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret);
          workspaceAddrPtr.reset(workspaceAddr);
      }
      // è°ƒç”¨aclnnDynamicDualLevelMxQuantç¬¬äºŒæ®µæ¥å£
      ret = aclnnDynamicDualLevelMxQuant(workspaceAddr, workspaceSize, executor, stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnDynamicDualLevelMxQuant failed. ERROR: %d\n", ret); return ret);
  
      //ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
      ret = aclrtSynchronizeStream(stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);
  
      // è·å–è¾“å‡ºçš„å€¼ï¼Œå°†deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
      auto size = GetShapeSize(yOutShape) / 2;
      std::vector<uint8_t> yOutData(
          size, 0);  // Cè¯­è¨€ä¸­æ— æ³•ç›´æ¥æ‰“å°fp4çš„æ•°æ®ï¼Œéœ€è¦ç”¨uint8è¯»å‡ºæ¥ï¼Œè‡ªè¡Œé€šè¿‡äºŒè¿›åˆ¶è½¬æˆfp4
      ret = aclrtMemcpy(yOutData.data(), yOutData.size() * sizeof(yOutData[0]), yOutDeviceAddr,
                        size * sizeof(yOutData[0]), ACL_MEMCPY_DEVICE_TO_HOST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy yOut from device to host failed. ERROR: %d\n", ret);
                return ret);
      for (int64_t i = 0; i < size; i++) {
          LOG_PRINT("yOut[%ld] is: %d\n", i, yOutData[i]);
      }
      size = GetShapeSize(level0ScaleOutShape);
      std::vector<float> level0ScaleOutData(
          size, 0);
      ret = aclrtMemcpy(level0ScaleOutData.data(), level0ScaleOutData.size() * sizeof(level0ScaleOutData[0]), level0ScaleOutDeviceAddr,
                        size * sizeof(level0ScaleOutData[0]), ACL_MEMCPY_DEVICE_TO_HOST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy level0ScaleOut from device to host failed. ERROR: %d\n", ret);
                return ret);
      for (int64_t i = 0; i < size; i++) {
          LOG_PRINT("level0ScaleOut[%ld] is: %f\n", i, level0ScaleOutData[i]);
      }
      size = GetShapeSize(level1ScaleOutShape);
      std::vector<uint8_t> level1ScaleOutData(
          size, 0);  // Cè¯­è¨€ä¸­æ— æ³•ç›´æ¥æ‰“å°fp8çš„æ•°æ®ï¼Œéœ€è¦ç”¨uint8è¯»å‡ºæ¥ï¼Œè‡ªè¡Œé€šè¿‡äºŒè¿›åˆ¶è½¬æˆfp8
      ret = aclrtMemcpy(level1ScaleOutData.data(), level1ScaleOutData.size() * sizeof(level1ScaleOutData[0]), level1ScaleOutDeviceAddr,
                        size * sizeof(level1ScaleOutData[0]), ACL_MEMCPY_DEVICE_TO_HOST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy level1ScaleOut from device to host failed. ERROR: %d\n", ret);
                return ret);
      for (int64_t i = 0; i < size; i++) {
          LOG_PRINT("level1ScaleOut[%ld] is: %d\n", i, level1ScaleOutData[i]);
      }
      return ACL_SUCCESS;
  }
  
  int main()
  {
      // 1. ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–ï¼Œå‚è€ƒacl APIæ‰‹å†Œ
      // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
      int32_t deviceId = 0;
      aclrtStream stream;
      auto ret = aclnnDynamicDualLevelMxQuantTest(deviceId, stream);
      CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnDynamicDualLevelMxQuantTest failed. ERROR: %d\n", ret); return ret);
  
      Finalize(deviceId, stream);
      return 0;
  }
  ```