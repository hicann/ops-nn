# aclnnQuantMatmulV5

[ğŸ“„ æŸ¥çœ‹æºç ](https://gitcode.com/cann/ops-nn/tree/master/matmul/quant_batch_matmul_v4)

## äº§å“æ”¯æŒæƒ…å†µ

| äº§å“                                                         |  æ˜¯å¦æ”¯æŒ   |
| :----------------------------------------------------------- |:-------:|
| <term>Ascend 950PR/Ascend 950DT</term>                             |    âˆš    |
| <term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>     |    âˆš    |
| <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term> |    âˆš    |
| <term>Atlas 200I/500 A2 æ¨ç†äº§å“</term>                      |    Ã—    |
| <term>Atlas æ¨ç†ç³»åˆ—äº§å“ </term>                             |    Ã—    |
| <term>Atlas è®­ç»ƒç³»åˆ—äº§å“</term>                              |    Ã—    |
| <term>Atlas 200/300/500 æ¨ç†äº§å“</term>                      |    Ã—    |

## åŠŸèƒ½è¯´æ˜

- æ¥å£åŠŸèƒ½ï¼šå®Œæˆé‡åŒ–çš„çŸ©é˜µä¹˜è®¡ç®—ã€‚
  - <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ã€<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>ï¼šå…¼å®¹aclnnQuantMatmulV3ã€aclnnQuantMatmulV4æ¥å£åŠŸèƒ½ã€‚å®Œæˆé‡åŒ–çš„çŸ©é˜µä¹˜è®¡ç®—ï¼Œæœ€å°æ”¯æŒè¾“å…¥ç»´åº¦ä¸º1ç»´ï¼Œæœ€å¤§æ”¯æŒè¾“å…¥ç»´åº¦ä¸º2ç»´ã€‚ç›¸ä¼¼æ¥å£æœ‰aclnnMmï¼ˆä»…æ”¯æŒ2ç»´Tensorä½œä¸ºè¾“å…¥çš„çŸ©é˜µä¹˜ï¼‰ã€‚
  - <term>Ascend 950PR/Ascend 950DT</term>ï¼šå…¼å®¹aclnnQuantMatmulV3ã€aclnnQuantMatmulV4æ¥å£åŠŸèƒ½ï¼Œåœ¨å…¶åŸºç¡€ä¸Šæ–°å¢æ”¯æŒG-Bã€B-Bã€T-CGã€mx[é‡åŒ–æ¨¡å¼](../../../docs/zh/context/é‡åŒ–ä»‹ç».md)ç­‰ç‰¹æ€§ï¼Œæ–°å¢x1ï¼Œx2è¾“å…¥æ”¯æŒdtypeä¸ºFLOAT8_E4M3FNã€FLOAT8_E5M2ã€HIFLOAT8ã€FLOAT4_E2M1ã€FLOAT4_E1M2ã€‚å®Œæˆé‡åŒ–çš„çŸ©é˜µä¹˜è®¡ç®—ï¼Œæœ€å°æ”¯æŒè¾“å…¥ç»´åº¦ä¸º2ç»´ï¼Œæœ€å¤§æ”¯æŒè¾“å…¥ç»´åº¦ä¸º6ç»´ã€‚ç›¸ä¼¼æ¥å£æœ‰aclnnMmï¼ˆä»…æ”¯æŒ2ç»´Tensorä½œä¸ºè¾“å…¥çš„çŸ©é˜µä¹˜ï¼‰å’ŒaclnnBatchMatMulï¼ˆä»…æ”¯æŒä¸‰ç»´çš„çŸ©é˜µä¹˜ï¼Œå…¶ä¸­ç¬¬ä¸€ç»´æ˜¯Batchç»´åº¦ï¼‰ã€‚

- è®¡ç®—å…¬å¼ï¼š
  - <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ã€<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>ï¼š
    - x1ä¸ºINT8ï¼Œx2ä¸ºINT32ï¼Œx1Scaleä¸ºFLOAT32ï¼Œx2Scaleä¸ºUINT64ï¼ŒyOffsetä¸ºFLOAT32ï¼š

      $$
      out = ((x1 @ (x2*x2Scale)) + yOffset) * x1Scale
      $$

    - æ— x1Scaleæ— biasï¼š

      $$
      out = x1@x2 * x2Scale + x2Offset
      $$

    - bias INT32ï¼š

      $$
      out = (x1@x2 + bias) * x2Scale + x2Offset
      $$

    - bias BFLOAT16/FLOAT32ï¼ˆæ­¤åœºæ™¯æ— offsetï¼‰ï¼š

      $$
      out = x1@x2 * x2Scale + bias
      $$

    - x1Scaleæ— biasï¼š

      $$
      out = x1@x2 * x2Scale * x1Scale
      $$

    - x1Scaleï¼Œbias INT32ï¼ˆæ­¤åœºæ™¯æ— offsetï¼‰ï¼š

      $$
      out = (x1@x2 + bias) * x2Scale * x1Scale
      $$

    - x1Scaleï¼Œbias BFLOAT16/FLOAT16/FLOAT32ï¼ˆæ­¤åœºæ™¯æ— offsetï¼‰ï¼š

      $$
      out = x1@x2 * x2Scale * x1Scale + bias
      $$

    - x1ï¼Œx2ä¸ºINT8ï¼Œx1Scaleï¼Œx2Scaleä¸ºFLOAT32ï¼Œbiasä¸ºFLOAT32ï¼Œoutä¸ºFLOAT16/BFLOAT16  (pergroup-perblocké‡åŒ–)ï¼š

      $$
      out = (x1 @ x2) * x1Scale * x2Scale + bias
      $$

    - x1ï¼Œx2ä¸ºINT4ï¼Œx1Scaleï¼Œx2Scaleä¸ºFLOAT32ï¼Œx2Offsetä¸ºFLOAT16ï¼Œoutä¸ºFLOAT16/BFLOAT16 (pertoken-pergroupéå¯¹ç§°é‡åŒ–)ï¼š

      $$
      out = x1Scale * x2Scale @ (x1 @ x2 - x1 @ x2Offset)
      $$

  - <term>Ascend 950PR/Ascend 950DT</term>ï¼š

    æ”¯æŒT-C && T-Tã€K-C && K-Tã€G-B ã€B-B ã€mxã€T-CG[é‡åŒ–æ¨¡å¼](../../../docs/zh/context/é‡åŒ–ä»‹ç».md)ï¼Œä¸åŒé‡åŒ–æ¨¡å¼å¯¹åº”çš„è¾“å…¥è¾“å‡ºæ•°æ®ç±»å‹ç»„åˆå‚è§[çº¦æŸè¯´æ˜](#çº¦æŸè¯´æ˜)ã€‚
    - **T-C && T-Té‡åŒ–æ¨¡å¼**
      - x1ï¼Œx2ä¸ºINT8ï¼Œæ— x1Scaleï¼Œx2Scaleä¸ºINT64/UINT64ï¼Œå¯é€‰å‚æ•°x2Offsetä¸ºFLOAT32ï¼Œå¯é€‰å‚æ•°biasä¸ºINT32ï¼š

        $$
        out = (x1@x2 + bias) * x2Scale + x2Offset
        $$

      - x1ï¼Œx2ä¸ºINT8ï¼Œæ— x1Scaleï¼Œx2Scaleä¸ºINT64/UINT64ï¼Œå¯é€‰å‚æ•°biasä¸ºINT32ï¼›
      æˆ–x1ï¼Œx2ä¸ºFLOAT8_E4M3FN/FLOAT8_E5M2/HIFLOAT8ï¼Œæ— x1Scaleï¼Œx2Scaleä¸ºINT64/UINT64ï¼Œå¯é€‰å‚æ•°biasä¸ºFLOAT32ï¼š

        $$
        out = (x1@x2 + bias) * x2Scale
        $$

      - x1ï¼Œx2ä¸ºINT8ï¼Œæ— x1Scaleï¼Œx2Scaleä¸ºBFLOAT16/FLOAT32ï¼Œå¯é€‰å‚æ•°biasä¸ºBFLOAT16/FLOAT32ï¼š

        $$
        out = x1@x2 * x2Scale + bias
        $$

      - x1ï¼Œx2ä¸ºFLOAT8_E4M3FN/FLOAT8_E5M2/HIFLOAT8ï¼Œx1Scaleä¸ºFLOAT32ï¼Œx2Scaleä¸ºFLOAT32ï¼Œå¯é€‰å‚æ•°biasä¸ºFLOAT32ï¼š

        $$
        out = (x1@x2 + bias) * x2Scale * x1Scale
        $$

    - **K-C && K-Té‡åŒ–æ¨¡å¼**

      - x1ï¼Œx2ä¸ºINT8ï¼Œx1Scaleä¸ºFLOAT32ï¼Œx2Scaleä¸ºBFLOAT16/FLOAT32ï¼Œå¯é€‰å‚æ•°biasä¸ºINT32ï¼›
      æˆ–x1ï¼Œx2ä¸ºFLOAT8_E4M3FN/FLOAT8_E5M2/HIFLOAT8ï¼Œx1Scaleä¸ºFLOAT32ï¼Œx2Scaleä¸ºFLOAT32ï¼Œå¯é€‰å‚æ•°biasä¸ºFLOAT32ï¼š

        $$
        out = (x1@x2 + bias) * x2Scale * x1Scale
        $$

      - x1ï¼Œx2ä¸ºINT8ï¼Œx1Scaleä¸ºFLOAT32ï¼Œx2Scaleä¸ºBFLOAT16/FLOAT32ï¼Œå¯é€‰å‚æ•°biasä¸ºBFLOAT16/FLOAT32ï¼›
      æˆ–x1ï¼Œx2ä¸ºINT8ï¼Œx1Scaleä¸ºFLOAT32ï¼Œx2Scaleä¸ºFLOAT32ï¼Œå¯é€‰å‚æ•°biasä¸ºFLOAT16/FLOAT32ï¼š

        $$
        out = x1@x2 * x2Scale * x1Scale + bias
        $$

    - **G-B && B-B && mxé‡åŒ–æ¨¡å¼**

      $$
      out[m,n] = \sum_{j=0}^{kLoops-1} ((\sum_{k=0}^{gsK-1} (x1Slice * x2Slice))* (x1Scale[m/gsM, j] * x2Scale[j, n/gsN]))+bias[n]
      $$

      å…¶ä¸­ï¼ŒgsMï¼ŒgsNå’ŒgsKåˆ†åˆ«ä»£è¡¨groupSizeMï¼ŒgroupSizeNå’ŒgroupSizeKï¼›x1Sliceä»£è¡¨x1ç¬¬mè¡Œé•¿åº¦ä¸ºgroupSizeKçš„å‘é‡ï¼Œx2Sliceä»£è¡¨x2ç¬¬nåˆ—é•¿åº¦ä¸ºgroupSizeKçš„å‘é‡ï¼›Kè½´å‡ä»j*groupSizeKèµ·å§‹åˆ‡ç‰‡ï¼Œjçš„å–å€¼èŒƒå›´[0, kLoops)ï¼ŒkLoops = ceil(K / groupSizeK)ï¼ŒKä¸ºKè½´é•¿åº¦ï¼Œæ”¯æŒæœ€åçš„åˆ‡ç‰‡é•¿åº¦ä¸è¶³groupSizeKã€‚ä»…mxé‡åŒ–æ¨¡å¼ä¸‹åŒ…å«biasã€‚å¯¹äºG-Bï¼ŒB-Bå’Œmxé‡åŒ–æ¨¡å¼ï¼Œ[groupSizeMï¼ŒgroupSizeNï¼ŒgroupSizeK]å–å€¼ç»„åˆä»…åˆ†åˆ«æ”¯æŒ[1ï¼Œ128ï¼Œ128]ï¼Œ[128ï¼Œ128ï¼Œ128]å’Œ[1ï¼Œ1ï¼Œ32]ã€‚

    - **T-CGé‡åŒ–æ¨¡å¼**

      $$
      out = (x1@(x2 * x2Scale)) * yScale
      $$

## å‡½æ•°åŸå‹

æ¯ä¸ªç®—å­åˆ†ä¸º[ä¸¤æ®µå¼æ¥å£](../../../docs/zh/context/ä¸¤æ®µå¼æ¥å£.md)ï¼Œå¿…é¡»å…ˆè°ƒç”¨â€œaclnnQuantMatmulV5GetWorkspaceSizeâ€æ¥å£è·å–è®¡ç®—æ‰€éœ€workspaceå¤§å°ä»¥åŠåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹çš„æ‰§è¡Œå™¨ï¼Œå†è°ƒç”¨â€œaclnnQuantMatmulV5â€æ¥å£æ‰§è¡Œè®¡ç®—ã€‚

```c++
aclnnStatus aclnnQuantMatmulV5GetWorkspaceSize(
  const aclTensor *x1,
  const aclTensor *x2,
  const aclTensor *x1Scale,
  const aclTensor *x2Scale,
  const aclTensor *yScale,
  const aclTensor *x1Offset,
  const aclTensor *x2Offset,
  const aclTensor *yOffset,
  const aclTensor *bias,
  bool             transposeX1,
  bool             transposeX2,
  int64_t          groupSize,
  aclTensor       *out,
  uint64_t        *workspaceSize,
  aclOpExecutor   **executor)
```
```c++
aclnnStatus aclnnQuantMatmulV5(
  void          *workspace,
  uint64_t       workspaceSize,
  aclOpExecutor *executor,
  aclrtStream    stream)
```

## aclnnQuantMatmulV5GetWorkspaceSize

- **å‚æ•°è¯´æ˜**

  <table style="undefined;table-layout: fixed; width: 1554px"><colgroup>
  <col style="width: 248px">
  <col style="width: 121px">
  <col style="width: 170px">
  <col style="width: 397px">
  <col style="width: 220px">
  <col style="width: 115px">
  <col style="width: 138px">
  <col style="width: 145px">
  </colgroup>
    <thead>
      <tr>
        <th>å‚æ•°å</th>
        <th>è¾“å…¥/è¾“å‡º</th>
        <th>æè¿°</th>
        <th>ä½¿ç”¨è¯´æ˜</th>
        <th>æ•°æ®ç±»å‹</th>
        <th>æ•°æ®æ ¼å¼</th>
        <th>ç»´åº¦(shape)</th>
        <th>éè¿ç»­Tensor</th>
      </tr></thead>
    <tbody>
      <tr>
        <td>x1(aclTensor*)</td>
        <td>è¾“å…¥</td>
        <td>å…¬å¼ä¸­çš„è¾“å…¥x1ã€‚</td>
        <td>
          <ul>
            <li>ä¸æ”¯æŒç©ºTensorã€‚ç‰¹æ®Šæƒ…å†µï¼š<term>Ascend 950PR/Ascend 950DT</term>ï¼šä»…å¯¹m=0çš„ç©ºTensorè¾“å…¥ï¼Œè¿”å›ç©ºTensorä½œä¸ºè¾“å‡ºã€‚å…¶ä»–æƒ…å†µçš„ç©ºTensorä¸æ”¯æŒã€‚</li>
            <li>ä»…æœ€åmå’Œkè½´è½¬ç½®æƒ…å†µä¸‹æ”¯æŒ<a href="../../../docs/zh/context/éè¿ç»­çš„Tensor.md">éè¿ç»­çš„Tensor</a>ï¼Œå…¶ä»–è½´æ–¹å‘ä¸æ”¯æŒéè¿ç»­çš„Tensorã€‚</li>
          </ul>
        </td>
        <td>INT4<sup>1</sup>ã€INT8ã€INT32<sup>1</sup>ã€FLOAT8_E4M3FNã€FLOAT8_E5M2ã€HIFLOAT8ã€FLOAT4_E2M1ã€FLOAT4_E1M2</td>
        <td>ND</td>
        <td>2-6</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>x2(aclTensor*)</td>
        <td>è¾“å…¥</td>
        <td>å…¬å¼ä¸­çš„è¾“å…¥x2ã€‚</td>
        <td>
          <ul>
            <li>ä¸æ”¯æŒç©ºTensorã€‚ç‰¹æ®Šæƒ…å†µï¼š<term>Ascend 950PR/Ascend 950DT</term>ï¼šä»…åœ¨NDæ ¼å¼ä¸‹ï¼Œå¯¹n=0çš„ç©ºTensorè¾“å…¥ï¼Œè¿”å›ç©ºTensorä½œä¸ºè¾“å‡ºã€‚å…¶ä»–æƒ…å†µçš„ç©ºTensorä¸æ”¯æŒã€‚</li>
            <li>NZæ ¼å¼ä¸‹ï¼Œä¸æ”¯æŒç©ºTensorã€‚</li>
            <li>NZæ ¼å¼ä¸‹ï¼Œshapeæ”¯æŒ4-8ç»´ã€‚</li>
            <li>NDæ ¼å¼ä¸‹æ”¯æŒæœ€åä¸¤æ ¹è½´è½¬ç½®æƒ…å†µä¸‹çš„éè¿ç»­tensorï¼Œå…¶ä»–åœºæ™¯çš„<a href="../../../docs/zh/context/éè¿ç»­çš„Tensor.md">éè¿ç»­çš„Tensor</a>ä¸æ”¯æŒã€‚</li>
          </ul>
        </td>
        <td>INT4<sup>1</sup>ã€INT8ã€INT32<sup>1</sup>ã€FLOAT8_E4M3FNã€FLOAT8_E5M2ã€HIFLOAT8ã€FLOAT4_E2M1ã€FLOAT4_E1M2</td>
        <td>NDã€NZ</td>
        <td>2-8</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>x1Scale(aclTensor*)</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>å…¬å¼ä¸­çš„è¾“å…¥x1Scaleã€‚</td>
        <td>
        <ul>
            <li>ä¸æ”¯æŒç©ºTensorã€‚</li>
          </ul>
          </td>
        <td>FLOAT32ã€FLOAT8_E8M0ã€FLOAT8_E4M3FNã€FLOAT8_E5M2ã€HIFLOAT8</td>
        <td>ND</td>
        <td>1-6</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>x2Scale(aclTensor*)</td>
        <td>è¾“å…¥</td>
        <td>è¡¨ç¤ºé‡åŒ–å‚æ•°ï¼Œå…¬å¼ä¸­çš„è¾“å…¥x2Scaleã€‚</td>
        <td>
          <ul>
            <li>ä¸æ”¯æŒç©ºTensorã€‚</li>
          </ul>
        </td>
        <td>UINT64ã€INT64ã€FLOAT32ã€BFLOAT16ã€FLOAT8_E8M0</td>
        <td>ND</td>
        <td>1-6</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>yScale(aclTensor*)</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>è¾“å‡ºyçš„åé‡åŒ–scaleå‚æ•°ã€‚</td>
        <td>
        </td>
        <td>UINT64ã€INT64</td>
        <td>ND</td>
        <td>2</td>
        <td>-</td>
      </tr>
      <tr>
        <td>x1Offset(aclTensor*)</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>å…¬å¼ä¸­çš„è¾“å…¥x1Offsetã€‚</td>
        <td>
        <ul>
        <li>
        é¢„ç•™å‚æ•°ï¼Œå½“å‰ç‰ˆæœ¬ä¸æ”¯æŒï¼Œéœ€è¦ä¼ å…¥nullptrã€‚
        </li>
        </ul>
        </td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>x2Offset(aclTensor*)</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>å…¬å¼ä¸­çš„è¾“å…¥x2Offsetã€‚</td>
        <td>
          <ul>
            <li>ä¸æ”¯æŒç©ºTensorã€‚</li>
          </ul>
        </td>
        <td>FLOAT16ã€FLOAT32</td>
        <td>ND</td>
        <td>1-2</td>
        <td>-</td>
      </tr>
      <tr>
        <td>yOffset(aclTensor*)</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>å…¬å¼ä¸­çš„è¾“å…¥yOffsetã€‚</td>
        <td>
        </td>
        <td>FLOAT32</td>
        <td>ND</td>
        <td>1</td>
        <td>-</td>
      </tr>
      <tr>
        <td>bias(aclTensor*)</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>å…¬å¼ä¸­çš„è¾“å…¥biasã€‚</td>
        <td>
          <ul>
            <li>ä¸æ”¯æŒç©ºTensorã€‚</li>
          </ul>
        </td>
        <td>INT32ã€FLOAT32ã€BFLOAT16ã€FLOAT16</td>
        <td>ND</td>
        <td>1-3</td>
        <td>-</td>
      </tr>
      <tr>
        <td>transposeX1(bool)</td>
        <td>è¾“å…¥</td>
        <td>è¡¨ç¤ºx1çš„è¾“å…¥shapeæ˜¯å¦è½¬ç½®ã€‚</td>
        <td>-</td>
        <td>BOOL</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>transposeX2(bool)</td>
        <td>è¾“å…¥</td>
        <td>è¡¨ç¤ºx2çš„è¾“å…¥shapeæ˜¯å¦è½¬ç½®ã€‚</td>
        <td>-</td>
        <td>BOOL</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>groupSize(int64_t)</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>ç”¨äºè¾“å…¥mã€nã€kæ–¹å‘ä¸Šçš„é‡åŒ–åˆ†ç»„å¤§å°ã€‚</td>
        <td>
        <ul>
            <li>ç”±3ä¸ªæ–¹å‘çš„groupSizeMï¼ŒgroupSizeNï¼ŒgroupSizeK ä¸‰ä¸ªå€¼æ‹¼æ¥ç»„æˆï¼Œæ¯ä¸ªå€¼å 16ä½ï¼Œå…±å ç”¨int64_tç±»å‹groupSizeçš„ä½48ä½ï¼ˆgroupSizeä¸­çš„é«˜16ä½çš„æ•°å€¼æ— æ•ˆï¼‰ï¼Œè®¡ç®—å…¬å¼è§è¡¨æ ¼ä¸‹æ–¹<a href="#f1">å…¬å¼ä¸€</a>ã€‚</li>
          </ul>
        </td>
        <td>INT64</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>out(aclTensor)</td>
        <td>è¾“å‡º</td>
        <td>å…¬å¼ä¸­çš„è¾“å‡ºoutã€‚</td>
        <td>
          <ul>
            <li>ä¸æ”¯æŒç©ºTensorã€‚</li>
          </ul>
        </td>
        <td>FLOAT16ã€INT8ã€BFLOAT16ã€INT32ã€HIFLOAT8ã€FLOAT8_E4M3FN</td>
        <td>ND</td>
        <td>2</td>
        <td>âœ“</td>
      </tr>
      <tr>
        <td>workspaceSize(uint64_t)</td>
        <td>è¾“å‡º</td>
        <td>è¿”å›éœ€è¦åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ã€‚</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td style="white-space: nowrap">executor(aclOpExecutor)</td>
        <td>è¾“å‡º</td>
        <td>è¿”å›opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
  </tbody></table>

  - æ³¨ï¼šå¯é€‰è¾“å…¥æ˜¯æŒ‡å¯é€‰çš„é‡åŒ–å‚æ•°ï¼Œæ”¯æŒä¼ å…¥nullptrã€‚
  
  - <term>Ascend 950PR/Ascend 950DT</term>ï¼š

    - ä¸Šè¡¨æ•°æ®ç±»å‹åˆ—ä¸­çš„è§’æ ‡â€œ1â€ä»£è¡¨è¯¥ç³»åˆ—ä¸æ”¯æŒçš„æ•°æ®ç±»å‹ã€‚
    - è¾“å…¥å‚æ•°x1ã€x2å‡ä¸æ”¯æŒINT4ã€INT32ç±»å‹ã€‚

  - <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas A2 æ¨ç†ç³»åˆ—äº§å“</term>ã€<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>ï¼š

    - ä¸Šè¡¨æ•°æ®ç±»å‹åˆ—ä¸­çš„è§’æ ‡â€œ2â€ä»£è¡¨è¯¥ç³»åˆ—ä¸æ”¯æŒçš„æ•°æ®ç±»å‹ã€‚

  - <h3 id="f1">å…¬å¼ä¸€</h3>

    $$
    groupSize = groupSizeK | groupSizeN << 16 | groupSizeM << 32
    $$

- **è¿”å›å€¼**

  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

  ç¬¬ä¸€æ®µæ¥å£å®Œæˆå…¥å‚æ ¡éªŒï¼Œå‡ºç°ä»¥ä¸‹åœºæ™¯æ—¶æŠ¥é”™ï¼š

  <table style="undefined;table-layout: fixed; width: 1149px"><colgroup>
  <col style="width: 281px">
  <col style="width: 119px">
  <col style="width: 749px">
  </colgroup>
  <thead>
      <tr>
        <th>è¿”å›å€¼</th>
        <th>é”™è¯¯ç </th>
        <th>æè¿°</th>
      </tr></thead>
      <tbody>
      <tr>
        <td>ACLNN_ERR_PARAM_NULLPTR</td>
        <td>161001</td>
        <td>ä¼ å…¥çš„x1ã€x2ã€x1Scaleã€x2Scaleã€yOffsetæˆ–outæ˜¯ç©ºæŒ‡é’ˆã€‚</td>
      </tr>
      <tr>
        <td rowspan="5">ACLNN_ERR_PARAM_INVALID</td>
        <td rowspan="5">161002</td>
        <td>x1ã€x2ã€biasã€x2Scaleã€x2Offsetæˆ–outæ˜¯ç©ºtensorã€‚ç‰¹æ®Šæƒ…å†µï¼š<term>Ascend 950PR/Ascend 950DT</term>ï¼šè‹¥x2ä¸ºNDæ ¼å¼ï¼Œå¯¹äºmæˆ–n=0çš„ç©ºtensorï¼Œè¿”å›ç©ºtensorä½œä¸ºè¾“å‡ºï¼Œä¸ä¼šæŠ¥é”™ï¼›è‹¥x2ä¸ºFRACTAL_NZæ ¼å¼ï¼Œå¯¹äºm=0çš„ç©ºtensorï¼Œè¿”å›ç©ºtensorä½œä¸ºè¾“å‡ºï¼Œä¸ä¼šæŠ¥é”™ã€‚</td>
      </tr>
      <tr>
        <td>x1ã€x2ã€biasã€x1Scaleã€x2Scaleã€x2Offsetæˆ–outçš„æ•°æ®ç±»å‹å’Œæ•°æ®æ ¼å¼ä¸åœ¨æ”¯æŒçš„èŒƒå›´ä¹‹å†…ã€‚</td>
      </tr>
      <tr>
        <td>x1ã€x2ã€biasã€x1Scaleã€x2Scaleã€x2Offsetæˆ–outçš„shapeä¸æ»¡è¶³æ ¡éªŒæ¡ä»¶ã€‚</td>
      </tr>
      <tr>
        <td>ä¼ å…¥çš„groupSizeä¸æ»¡è¶³æ ¡éªŒæ¡ä»¶ï¼Œæˆ–ä¼ å…¥çš„groupSizeä¸º0æ—¶ï¼Œx1ã€x2ä¸x1Scaleï¼Œx2Scaleçš„shapeå…³ç³»æ— æ³•æ¨æ–­groupSizeã€‚</td>
      </tr>
    </tbody></table>


## aclnnQuantMatmulV5

- **å‚æ•°è¯´æ˜**

  <table style="undefined;table-layout: fixed; width: 1150px"><colgroup>
  <col style="width: 168px">
  <col style="width: 128px">
  <col style="width: 854px">
  </colgroup>
  <thead>
    <tr>
    <th>å‚æ•°å</th>
    <th>è¾“å…¥/è¾“å‡º</th>
    <th>æè¿°</th>
    </tr></thead>
  <tbody>
  <tr>
    <td>workspace</td>
    <td>è¾“å…¥</td>
    <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå†…å­˜åœ°å€ã€‚</td>
  </tr>
  <tr>
    <td>workspaceSize</td>
    <td>è¾“å…¥</td>
    <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ï¼Œç”±ç¬¬ä¸€æ®µæ¥å£aclnnQuantMatmulV5GetWorkspaceSizeè·å–ã€‚</td>
  </tr>
  <tr>
    <td>executor</td>
    <td>è¾“å…¥</td>
    <td>opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
  </tr>
  <tr>
    <td>stream</td>
    <td>è¾“å…¥</td>
    <td>æŒ‡å®šæ‰§è¡Œä»»åŠ¡çš„Streamã€‚</td>
  </tr>
</tbody></table>

- **è¿”å›å€¼**

  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

## çº¦æŸè¯´æ˜

- ç¡®å®šæ€§è®¡ç®—ï¼š
  - aclnnGroupedMatmulV5é»˜è®¤ç¡®å®šæ€§å®ç°ã€‚

<details>
<summary><term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ã€<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term></summary>

  - **è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆï¼š**
  <a id="è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆ1"></a>
    | x1                        | x2                        | x1Scale     | x2Scale         | x2Offset    | yScale   | bias         | yOffset    | out                                    |
    | ------------------------- | ------------------------- | ----------- | -----------     | ----------- | -------  | ------------ | -----------| -------------------------------------- |
    | INT8                      | INT32                     | FLOAT32     | UINT64          | null        | null     | null         | FLOAT32    | FLOAT16/BFLOAT16                       |
    | INT8                      | INT8                      | null        | UINT64/INT64    | null        | null     | null/INT32   | null       | FLOAT16                                |
    | INT8                      | INT8                      | null        | UINT64/INT64    | null/FLOAT32| null     | null/INT32   | null       | INT8                                   |
    | INT8                      | INT8                      | null/FLOAT32| FLOAT32/BFLOAT16| null        | null     | null/INT32/BFLOAT16/FLOAT32   | null       | BFLOAT16              |
    | INT8                      | INT8                      | FLOAT32     | FLOAT32         | null        | null     | null/INT32/FLOAT16/FLOAT32    | null       | FLOAT16               |
    | INT4/INT32                | INT4/INT32                | null        | UINT64/INT64    | null        | null     | null/INT32   | null       | FLOAT16                                  |
    | INT8                      | INT8                      | null        | FLOAT32/BFLOAT16| null        | null     | null/INT32   | null       | INT32                                |
    | INT8                      | INT8                      | FLOAT32        | FLOAT32| null        | null     | FLOAT32   | null       | BFLOAT16                                |
    | INT4/INT32                | INT4/INT32                | FLOAT32     | FLOAT32/BFLOAT16| null        | null     | null/INT32/BFLOAT16/FLOAT32   | null       | BFLOAT16              |
    | INT4/INT32                | INT4/INT32                | FLOAT32     | FLOAT32         | null        | null     | null/INT32/FLOAT16/FLOAT32    | null       | FLOAT16               |
    | INT4                | INT4                | FLOAT32     | FLOAT32         | FLOAT16        | null     | null    | null       | BFLOAT16               |
  
ä¸åŒçš„[é‡åŒ–æ¨¡å¼](../../../docs/zh/context/é‡åŒ–ä»‹ç».md)æ”¯æŒçš„x1ã€ x2ã€x1Scaleå’Œx2Scaleçš„è¾“å…¥dtypeç»„åˆï¼š
- <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ã€<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>ï¼š

  x1ã€x2ã€x1Scaleã€x2Scaleã€yOffsetå’ŒgroupSizeåœ¨ä¸åŒé‡åŒ–åœºæ™¯ä¸‹dtypeã€shapeçš„å–å€¼ç­‰æ–¹é¢ç›¸äº’å½±å“ï¼Œå…³ç³»å¦‚ä¸‹ï¼š
    | x1æ•°æ®ç±»å‹                 | x2æ•°æ®ç±»å‹                 | x1Scaleæ•°æ®ç±»å‹| x2Scaleæ•°æ®ç±»å‹| x1 shape | x2 shape| x1Scale shape| x2Scale shape| yOffset shape| [groupSizeMï¼ŒgroupSizeNï¼ŒgroupSizeK]å–å€¼|
    | ------------------------- | ------------------------- | -------------- | ------------- | -------- | ------- | ------------ | ------------ | ------------ | ------------ |
    | INT8                    |INT32                   |FLOAT32              |UINT64             | (m, k)|(k, n // 8)|(m, 1)|((k // 256)ï¼Œn)| (n) | [0, 0, 256]|
    | INT8                    |INT8                   |FLOAT32              |FLOAT32             | (m, k)|(n, k)|(m, k // 128)|((k // 128)ï¼Œ(n // 128))| null | [1, 128, 128]|
    | INT4                    |INT4                   |FLOAT32              |FLOAT32             | (m, k)|(n, k)|(m, 1)| (k // 256, n) | null | [0, 0, 256]|
è¡¨æ ¼ä¸­æœªåˆ—ä¸¾çš„è¾“å…¥ç»„åˆå±äºaclnnQuantMatmulV3ã€aclnnQuantMatmulV4æ¥å£çš„è¾“å…¥ç»„åˆï¼Œè¿™ä¸¤ä¸ªæ¥å£ä¸æ”¯æŒè¾“å…¥groupsizeï¼Œgroupsizeé»˜è®¤ä¸º0ã€‚
- <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ã€<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>ï¼š
  - x1æ•°æ®ç±»å‹æ”¯æŒINT8ã€INT32ã€INT4ã€‚
    - å½“æ•°æ®ç±»å‹ä¸ºINT32ã€INT4æ—¶ï¼Œä¸ºINT4é‡åŒ–åœºæ™¯ã€transposeX1ä¸ºfalseæƒ…å†µã€‚
    - å½“æ•°æ®ç±»å‹ä¸ºINT4æ—¶ï¼Œç»´åº¦ä¸ºï¼š(batchï¼Œmï¼Œk)ï¼Œè¦æ±‚kä¸ºå¶æ•°ã€‚
    - å½“æ•°æ®ç±»å‹ä¸ºINT32æ—¶ï¼Œæ¯ä¸ªINT32æ•°æ®å­˜æ”¾8ä¸ªINT4æ•°æ®ï¼Œå¯¹åº”ç»´åº¦è¡¨ç¤ºï¼š(batchï¼Œmï¼Œk // 8)ï¼Œè¦æ±‚kä¸º8çš„å€æ•°ã€‚
    - å¯ç”¨A8W8 perblockå¯¹ç§°é‡åŒ–æ—¶ï¼Œæ•°æ®ç±»å‹æ”¯æŒINT8ï¼Œç›®å‰néœ€ä¸256å¯¹é½, kä¸128å¯¹é½ä¸”ä¸º4 * 128çš„å€æ•°ï¼ŒtransposeX1ä¸ºfalseï¼Œå½¢çŠ¶ä¸º(m, k)ã€‚
    - å¯ç”¨A4W4 pergroupéå¯¹ç§°é‡åŒ–æ—¶ï¼Œæ•°æ®ç±»å‹æ”¯æŒINT4ï¼Œç›®å‰kéœ€ä¸1024å¯¹é½ï¼ŒtransposeX1ä¸ºfalseï¼Œå½¢çŠ¶ä¸º(m, k)ã€‚
    - åœ¨transposeX1ä¸ºfalseæƒ…å†µä¸‹ï¼Œå½¢çŠ¶ä¸º(batch, m, k)ã€‚
    - åœ¨transposeX1ä¸ºtrueæƒ…å†µä¸‹ï¼Œå½¢çŠ¶ä¸º(batch, k, m)ï¼Œå…¶ä¸­batchä»£è¡¨å‰0~4ç»´ï¼Œ0ç»´è¡¨ç¤ºbacthä¸å­˜åœ¨ã€‚
    - AIå¤„ç†å™¨äº²å’Œæ•°æ®æ’å¸ƒæ ¼å¼ä¸‹ï¼Œshapeæ”¯æŒ4~8ç»´ã€‚
    - transposeX2ä¸ºtrueæ—¶ç»´åº¦ä¸ºï¼š(batchï¼Œk1ï¼Œn1ï¼Œn0ï¼Œk0)ï¼Œbatchå¯ä¸å­˜åœ¨ï¼Œå…¶ä¸­k0 = 32ï¼Œn0 = 16ï¼Œx1 shapeä¸­çš„kå’Œx2 shapeä¸­çš„k1éœ€è¦æ»¡è¶³ä»¥ä¸‹å…³ç³»ï¼šceil(k / 32) = k1ã€‚
    - transposeX2ä¸ºfalseæ—¶ç»´åº¦ä¸ºï¼š(batchï¼Œn1ï¼Œk1ï¼Œk0ï¼Œn0)ï¼Œbatchå¯ä¸å­˜åœ¨ï¼Œå…¶ä¸­k0 = 16ï¼Œn0 = 32ï¼Œx1 shapeä¸­çš„kå’Œx2 shapeä¸­çš„k1éœ€è¦æ»¡è¶³ä»¥ä¸‹å…³ç³»ï¼šceil(k / 16) = k1ã€‚
    - å¯ä½¿ç”¨aclnnCalculateMatmulWeightSizeV2æ¥å£ä»¥åŠaclnnTransMatmulWeightæ¥å£å®Œæˆè¾“å…¥Formatä»NDåˆ°AIå¤„ç†å™¨äº²å’Œæ•°æ®æ’å¸ƒæ ¼å¼çš„è½¬æ¢ã€‚
  - x2æ•°æ®ç±»å‹æ”¯æŒINT8ã€INT32ã€INT4ã€‚
    - å½“æ•°æ®ç±»å‹ä¸ºINT32ã€INT4æ—¶ï¼Œä¸ºINT4é‡åŒ–åœºæ™¯ï¼Œå½“å‰ä»…æ”¯æŒ2ç»´NDæ ¼å¼ã€‚NDæ ¼å¼ä¸‹ï¼Œshapeæ”¯æŒ2~6ç»´ï¼Œ
      - transposeX2ä¸ºfalseæƒ…å†µä¸‹å„ä¸ªç»´åº¦è¡¨ç¤ºï¼š(batchï¼Œkï¼Œn)ã€‚
      - transposeX2ä¸ºtrueæƒ…å†µä¸‹å„ä¸ªç»´åº¦è¡¨ç¤ºï¼š(batchï¼Œnï¼Œk)ã€‚
      - batchå¯ä¸å­˜åœ¨ï¼Œå…¶ä¸­kä¸x1çš„shapeä¸­çš„kä¸€è‡´ã€‚
    - æ•°æ®ç±»å‹ä¸ºINT4æ—¶ï¼š
      - transposeX2ä¸ºtrueæ—¶ç»´åº¦ä¸ºï¼š(nï¼Œk)ï¼Œè¦æ±‚kä¸ºå¶æ•°ã€‚
      - transposeX2ä¸ºfalseæ—¶ç»´åº¦ä¸ºï¼š(kï¼Œn)ï¼Œè¦æ±‚nä¸ºå¶æ•°ã€‚
    - æ•°æ®ç±»å‹ä¸ºINT32æ—¶ï¼Œæ¯ä¸ªINT32æ•°æ®å­˜æ”¾8ä¸ªINT4æ•°æ®ï¼Œ
      - transposeX2ä¸ºtrueæ—¶ç»´åº¦ä¸ºï¼š(nï¼Œk // 8)ï¼Œè¦æ±‚kä¸º8çš„å€æ•°ã€‚
      - transposeX2ä¸ºfalseæ—¶ç»´åº¦ä¸ºï¼š(kï¼Œn // 8)ï¼Œè¦æ±‚nä¸º8çš„å€æ•°ã€‚
    - å¯ä½¿ç”¨aclnnConvertWeightToINT4Packæ¥å£å®Œæˆx2ä»INT32ï¼ˆ1ä¸ªint32åœ¨0~3bitä½å­˜å‚¨1ä¸ªint4ï¼‰åˆ°INT32ï¼ˆ1ä¸ªint32å­˜å‚¨8ä¸ªint4ï¼‰æˆ–INT4ï¼ˆ1ä¸ªint4è¡¨ç¤º1ä¸ªint4ï¼‰çš„æ•°æ®æ ¼å¼è½¬æ¢ï¼Œå…·ä½“å‚è§[aclnnConvertWeightToINT4Packæ¥å£](../../convert_weight_to_int4_pack/docs/aclnnConvertWeightToINT4Pack.md)ã€‚
    - å¯ç”¨A8W8 perblockå¯¹ç§°é‡åŒ–æ—¶ï¼Œæ•°æ®ç±»å‹æ”¯æŒINT8ï¼ŒtransposeX2ä¸ºtrueï¼Œå½¢çŠ¶ä¸º(n, k)ï¼Œç›®å‰néœ€ä¸256å¯¹é½ï¼Œkä¸128å¯¹é½ä¸”ä¸º4 * 128çš„å€æ•°ã€‚
    - å¯ç”¨A4W4 pergroupéå¯¹ç§°é‡åŒ–æ—¶ï¼Œæ•°æ®ç±»å‹æ”¯æŒINT4ï¼ŒtransposeX2ä¸ºtrueï¼Œå½¢çŠ¶ä¸º(n, k)ï¼Œç›®å‰kéœ€ä¸1024å¯¹ç§°ï¼Œç›®å‰néœ€ä¸256å¯¹é½ã€‚
  - x1Scaleçº¦æŸå¦‚ä¸‹ï¼š
    - shapeæ”¯æŒ2ç»´ï¼Œå½¢çŠ¶ä¸º(mï¼Œ1)ã€‚æ•°æ®ç±»å‹æ”¯æŒFLOAT32ã€‚
    - å¯ç”¨A8W8 perblockå¯¹ç§°é‡åŒ–æ—¶ï¼Œæ•°æ®ç±»å‹ä¸ºfloat32, å½¢çŠ¶ä¸º(m, ceil(k / 128))ã€‚
    - å¯ç”¨A4W4 pergroupéå¯¹ç§°é‡åŒ–æ—¶ï¼Œæ•°æ®ç±»å‹ä¸ºfloat32, å½¢çŠ¶ä¸º(m, 1)ã€‚
  - x2Scaleçš„çº¦æŸå¦‚ä¸‹ï¼š
    - shapeæ”¯æŒ2ç»´ï¼Œå½¢çŠ¶ä¸º(k / groupSizeï¼Œn)å…¶ä¸­nä¸x2çš„nä¸€è‡´ã€‚
    - æ•°æ®ç±»å‹æ”¯æŒUINT64ã€INT64ã€FLOAT32ã€BFLOAT16ã€‚
    - å½“åŸå§‹è¾“å…¥ç±»å‹ä¸æ»¡è¶³[çº¦æŸè¯´æ˜](#çº¦æŸè¯´æ˜)ä¸­ç±»å‹ç»„åˆæ—¶ï¼Œç”±äºTransQuantParamV2åªæ”¯æŒ1ç»´ï¼Œéœ€è¦å°†x2_scale viewæˆä¸€ç»´(k / groupSize * n)ï¼Œå†è°ƒç”¨TransQuantParamV2ç®—å­çš„aclnnæ¥å£æ¥å°†x2Scaleè½¬æˆUINT64æ•°æ®ç±»å‹ï¼Œå†å°†è¾“å‡ºviewæˆäºŒç»´(k / groupSize, n)ã€‚
    - å¯ç”¨A8W8 perblockå¯¹ç§°é‡åŒ–æ—¶ï¼Œæ•°æ®ç±»å‹ä¸ºfloat32, å½“x2çš„transposeä¸ºtrueæ—¶ï¼Œå½¢çŠ¶ä¸º(ceil(n / 128), ceil(k / 128))ï¼Œå½“x2çš„transposeä¸ºfalseæ—¶ï¼Œå½¢çŠ¶ä¸º(ceil(k / 128), ceil(n / 128))ã€‚
    - å¯ç”¨A4W4 pergroupéå¯¹ç§°é‡åŒ–æ—¶ï¼Œæ•°æ®ç±»å‹ä¸ºfloat32ï¼Œå½“x2çš„transposeä¸ºfalseæ—¶ï¼Œå½¢çŠ¶ä¸º(ceil(k / 256), n)ã€‚
  - å½“å‰ç‰ˆæœ¬ä¸æ”¯æŒyScaleï¼Œéœ€è¦ä¼ å…¥nullptrã€‚
  - x2Offsetçš„çº¦æŸå¦‚ä¸‹ï¼š
    - å¯é€‰é‡åŒ–å‚æ•°ï¼Œæ•°æ®ç±»å‹æ”¯æŒFLOAT32ã€‚
    - å½“outæ•°æ®ç±»å‹ä¸ºINT8æ—¶ï¼Œoffsetå¯ä»¥å­˜åœ¨ï¼Œå…¶ä»–è¾“å…¥ç±»å‹éœ€è¦ä¼ å…¥nullptrã€‚
    - A4W4 pergroupéå¯¹ç§°é‡åŒ–æ—¶ï¼š æ”¯æŒè¾“å…¥ç±»å‹ä¸ºFLOAT16ï¼Œå½¢çŠ¶ä¸º(ceil(k, 256)ï¼Œn)ã€‚
  - biasçš„çº¦æŸå¦‚ä¸‹ï¼š
    - A8W8 perblockå¯¹ç§°é‡åŒ–æ—¶ï¼Œæ•°æ®ç±»å‹æ”¯æŒfloat32ï¼Œshapeæ”¯æŒä¸€ç»´(n, )ã€‚
    - A4W4 pergroupå½“å‰ä¸æ”¯æŒï¼Œéœ€è¦ä¼ å…¥nullptrã€‚
  - transposeX1ï¼šx1å’Œx2ä¸ºINT32ã€INT4æ—¶ï¼ŒtransposeX1ä»…æ”¯æŒfalseï¼Œå„ä¸ªç»´åº¦è¡¨ç¤ºï¼š(m, k)ã€‚
  - transposeX2çš„çº¦æŸå¦‚ä¸‹ï¼š
    - NDæ ¼å¼ä¸‹ï¼Œä¸ºfalseæ—¶ç»´åº¦ä¸ºï¼š(batchï¼Œkï¼Œn)ï¼Œä¸ºtrueæ—¶ç»´åº¦ä¸ºï¼š(batchï¼Œnï¼Œk)ï¼Œbatchå¯ä¸å­˜åœ¨ï¼Œå…¶ä¸­kä¸x1çš„shapeä¸­çš„kä¸€è‡´ã€‚
    - AIå¤„ç†å™¨äº²å’Œæ•°æ®æ’å¸ƒæ ¼å¼ä¸‹ï¼š
      - ä¸ºtrueæ—¶ç»´åº¦ä¸ºï¼š(batchï¼Œk1ï¼Œn1ï¼Œn0ï¼Œk0)ï¼Œbatchå¯ä¸å­˜åœ¨ï¼Œå…¶ä¸­k0 = 32ï¼Œn0 = 16ï¼Œx1 shapeä¸­çš„kå’Œx2 shapeä¸­çš„k1éœ€è¦æ»¡è¶³ä»¥ä¸‹å…³ç³»ï¼šceil(k / 32) = k1ã€‚
      - ä¸ºfalseæ—¶ç»´åº¦ä¸ºï¼š(batchï¼Œn1ï¼Œk1ï¼Œk0ï¼Œn0)ï¼Œbatchå¯ä¸å­˜åœ¨ï¼Œå…¶ä¸­k0 = 16ï¼Œn0 = 32ï¼Œx1 shapeä¸­çš„kå’Œx2 shapeä¸­çš„k1éœ€è¦æ»¡è¶³ä»¥ä¸‹å…³ç³»ï¼šceil(k / 16) = k1ã€‚
  - groupSizeçš„çº¦æŸå¦‚ä¸‹ï¼š
    - å¸¸è§„æƒ…å†µä¸‹ä»¥åŠA4W4 pergroupéå¯¹ç§°é‡åŒ–æ¨¡å¼æ—¶ï¼Œ[groupSizeMï¼ŒgroupSizeNï¼ŒgroupSizeK]å–å€¼ç»„åˆä»…æ”¯æŒä»…æ”¯æŒ[0, 0, 256]ï¼Œå³groupSizeKä»…æ”¯æŒ256ã€‚
    - åœ¨A8W8 perblockå¯¹ç§°é‡åŒ–æ¨¡å¼æ—¶ï¼Œ[groupSizeMï¼ŒgroupSizeNï¼ŒgroupSizeK]å–å€¼ç»„åˆä»…æ”¯æŒ[1, 128, 128]ã€‚
  - outçš„çº¦æŸå¦‚ä¸‹ï¼š
    - shapeæ”¯æŒ2ç»´ï¼Œ(mï¼Œn)ã€‚æ•°æ®ç±»å‹æ”¯æŒFLOAT16ã€INT8ã€BFLOAT16ã€INT32ã€‚
    - A8W8 perblockå¯¹ç§°é‡åŒ–æ¨¡å¼æ—¶ï¼Œç›®å‰è¾“å‡ºæ”¯æŒbfloat16ã€‚
    - A4W4 pergroupéå¯¹ç§°é‡åŒ–æ¨¡å¼æ—¶ï¼Œç›®å‰è¾“å‡ºæ”¯æŒbfloat16ã€‚

</details>
<details>
<summary><term>Ascend 950PR/Ascend 950DT</term></summary>
  
  - **å…¬å…±çº¦æŸï¼š**
  <a id="å…¬å…±çº¦æŸ2"></a>
    - transposeX1ä¸ºfalseæ—¶x1çš„shapeï¼š(batch, m, k)ã€‚transposeX1ä¸ºtrueæ—¶x1çš„shapeï¼š(batch, k, m)ã€‚å…¶ä¸­batchä»£è¡¨å‰0~4ç»´ï¼Œ0ç»´è¡¨ç¤ºbacthä¸å­˜åœ¨ã€‚
    - transposeX2ä¸ºfalseæ—¶x2çš„shapeï¼š(batch, k, n)ã€‚transposeX2ä¸ºtrueæ—¶x2çš„shapeï¼š(batch, n, k)ã€‚å…¶ä¸­batchä»£è¡¨å‰0~4ç»´ï¼Œ0ç»´è¡¨ç¤ºbacthä¸å­˜åœ¨ã€‚kä¸x1çš„shapeä¸­çš„kä¸€è‡´ã€‚
    - å½“x2Scaleçš„åŸå§‹è¾“å…¥ç±»å‹ä¸æ»¡è¶³é‡åŒ–åœºæ™¯çº¦æŸä¸­ç»„åˆæ—¶ï¼Œéœ€æå‰è°ƒç”¨aclnnTransQuantParamV2æ¥å£æ¥å°†scaleè½¬æˆINT64ã€UINT64æ•°æ®ç±»å‹ã€‚
    - yScaleä»…å½“x1ä¸ºFLOAT8_E4M3FNï¼Œx2ä¸ºFLOAT4_E2M1æ—¶æ”¯æŒï¼Œå…¶ä»–åœºæ™¯æš‚ä¸æ”¯æŒã€‚shapeæ˜¯2ç»´(1, n)ï¼Œå…¶ä¸­nä¸x2çš„nä¸€è‡´ã€‚
    - x2Offsetä»…å½“x1ï¼Œx2æ•°æ®ç±»å‹ä¸ºINT8ï¼Œä¸”outæ•°æ®ç±»å‹ä¸ºINT8æ—¶æ”¯æŒï¼Œå…¶ä»–è¾“å…¥ç±»å‹éœ€è¦ä¼ å…¥nullptrã€‚shapeæ˜¯1ç»´(t, )ï¼Œt = 1æˆ–nï¼Œå…¶ä¸­nä¸x2çš„nä¸€è‡´ã€‚
    - yOffsetä¸ºé¢„ç•™å‚æ•°ï¼Œå½“å‰ç‰ˆæœ¬ä¸æ”¯æŒï¼Œéœ€è¦ä¼ å…¥nullptræˆ–ç©ºtensorã€‚
    - biasç›¸å…³çº¦æŸï¼š
      - å¯é€‰å‚æ•°ï¼Œæ”¯æŒä¼ å…¥nullptrã€‚
      - å½“outçš„shapeä¸º2ã€4ã€5ã€6ç»´æ—¶ï¼Œbiasçš„shapeæ”¯æŒ1ç»´(n,)ã€‚
      - å½“outçš„shapeä¸º3ç»´æ—¶ï¼Œbiasçš„shapeæ”¯æŒ1ç»´(n,)æˆ–3ç»´(batch, 1, n)ã€‚
    - groupSizeç›¸å…³çº¦æŸï¼š
      - ä»…åœ¨mxã€G-Bã€B-Bã€T-CG[é‡åŒ–æ¨¡å¼](../../../docs/zh/context/é‡åŒ–ä»‹ç».md)ä¸­ç”Ÿæ•ˆã€‚
      - åªæœ‰å½“x1Scaleå’Œx2Scaleè¾“å…¥éƒ½æ˜¯2ç»´åŠä»¥ä¸Šæ•°æ®æ—¶ï¼ŒgroupSizeå–å€¼æœ‰æ•ˆï¼Œå…¶ä»–åœºæ™¯éœ€ä¼ å…¥0ã€‚
      - ä¼ å…¥çš„groupSizeå†…éƒ¨ä¼šæŒ‰<a href="#f1">å…¬å¼</a>åˆ†è§£å¾—åˆ°groupSizeMã€groupSizeNã€groupSizeKï¼Œå½“å…¶ä¸­æœ‰1ä¸ªæˆ–å¤šä¸ªä¸º0ï¼Œä¼šæ ¹æ®x1/x2/x1Scale/x2Scaleè¾“å…¥shapeé‡æ–°è®¾ç½®groupSizeMã€groupSizeNã€groupSizeKç”¨äºè®¡ç®—ã€‚åŸç†ï¼šå‡è®¾groupSizeM=0ï¼Œè¡¨ç¤ºmæ–¹å‘é‡åŒ–åˆ†ç»„å€¼ç”±æ¥å£æ¨æ–­ï¼Œæ¨æ–­å…¬å¼ä¸ºgroupSizeM = m / scaleMï¼ˆéœ€ä¿è¯mèƒ½è¢«scaleMæ•´é™¤ï¼‰ï¼Œå…¶ä¸­mä¸x1 shapeä¸­çš„mä¸€è‡´ï¼ŒscaleMä¸x1Scale shapeä¸­çš„mä¸€è‡´ã€‚
    - outçš„shapeæ”¯æŒ2~6ç»´ï¼Œ(batch, m, n)ï¼Œbatchå¯ä¸å­˜åœ¨ï¼Œæ”¯æŒx1ä¸x2çš„batchç»´åº¦broadcastï¼Œè¾“å‡ºbatchä¸broadcastä¹‹åçš„batchä¸€è‡´ï¼Œmä¸x1çš„mä¸€è‡´ï¼Œnä¸x2çš„nä¸€è‡´ã€‚


  - **T-Cé‡åŒ– && T-Té‡åŒ–åœºæ™¯çº¦æŸï¼š**
  <a id="T-Cé‡åŒ– && T-Té‡åŒ–"></a>
    - è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆï¼š
  <a id="è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆTC/TT"></a>
      | x1                        | x2                        | x1Scale     |   x2Scale     | x2Offset | yScale | bias    |   out                                    |
      | ------------------------- | ------------------------- | ----------- |   ----------- | -------- | -------| ------- |   -------------------------------------- |
      | INT8                      | INT8                      | null        | UINT64/ INT64      | null     | null     | null/INT32   | FLOAT16/ BFLOAT16                       |
      | INT8                      | INT8                      | null        | UINT64/ INT64      | null/FLOAT32  | null     | null/INT32   |   INT8                              |
      | INT8                      | INT8                      | null        | FLOAT32/  BFLOAT16  | null     | null     | null/INT32/FLOAT32/ BFLOAT16   |   BFLOAT16              |
      | INT8                      | INT8                      | null        | FLOAT32/  BFLOAT16| null        | null     | null/INT32   |   INT32                                |
      | FLOAT8_E4M3FN/ FLOAT8_E5M2 | FLOAT8_E4M3FN/ FLOAT8_E5M2 | null        | UINT64/ INT64      | null     | null     | null/FLOAT32 | FLOAT16/BFLOAT16/FLOAT32 |
      | HIFLOAT8                  | HIFLOAT8                  | null        | UINT64/ INT64      | null     | null     | null/FLOAT32 | FLOAT16/BFLOAT16/ FLOAT32      |
      | FLOAT8_E4M3FN/FLOAT8_E5M2 | FLOAT8_E4M3FN/FLOAT8_E5M2 | FLOAT32     |   FLOAT32           | null     | null     | null/FLOAT32 | FLOAT16/BFLOAT16/  FLOAT32               |
      | HIFLOAT8                  | HIFLOAT8                  | FLOAT32     | FLOAT32           | null     | null     | null/FLOAT32 | FLOAT16/BFLOAT16/FLOAT32               |

    - T-Té‡åŒ–åœºæ™¯ä¸‹ï¼Œx1Scaleçš„shapeä¸º(1,)æˆ–nullptrï¼Œx2Scaleçš„shapeä¸º(1,)ã€‚
    - T-Cé‡åŒ–åœºæ™¯ä¸‹ï¼Œx1Scaleçš„shapeä¸º(1,)æˆ–nullptrï¼Œx2Scaleçš„shapeä¸º(n,)ï¼Œå…¶ä¸­nä¸x2çš„nä¸€è‡´ã€‚
    - x1/x2çš„æ•°æ®ç±»å‹ä¸ºFLOAT8_E4M3FN/FLOAT8_E5M2/HIFLOAT8æ—¶ï¼ŒåŒºåˆ†é™æ€é‡åŒ–å’ŒåŠ¨æ€é‡åŒ–ã€‚é™æ€é‡åŒ–æ—¶x2Scaleæ•°æ®ç±»å‹ä¸ºUINT64/ INT64ï¼ŒåŠ¨æ€é‡åŒ–æ—¶x2Scaleæ•°æ®ç±»å‹ä¸ºFLOAT32ï¼›x1/x2æ•°æ®ç±»å‹ä¸ºINT8æ—¶ï¼Œä¸æ”¯æŒåŠ¨æ€T-Cæˆ–åŠ¨æ€T-Té‡åŒ–ã€‚
    - åŠ¨æ€T-Cé‡åŒ–åœºæ™¯ä¸‹ï¼Œä¸æ”¯æŒbiasã€‚

  - **K-Cé‡åŒ– && K-Té‡åŒ–åœºæ™¯çº¦æŸï¼š**
  <a id="K-Cé‡åŒ– && K-Té‡åŒ–"></a>
    - è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆï¼š
  <a id="è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆKC/KT"></a>
      | x1                        | x2                        | x1Scale     | x2Scale     | x2Offset | yScale |   bias    | out                                    |
      | ------------------------- | ------------------------- | ----------- | ----------- | -------- | -------|   ------- | -------------------------------------- |
      | INT8                      | INT8                      | FLOAT32| FLOAT32/BFLOAT16  | null     | null     |  null/INT32/FLOAT32/BFLOAT16   | BFLOAT16              |
      | INT8                      | INT8                      | FLOAT32     | FLOAT32           | null     |  null     | null/INT32/FLOAT32/FLOAT16  | FLOAT16                 |
      | FLOAT8_E4M3FN/FLOAT8_E5M2 | FLOAT8_E4M3FN/FLOAT8_E5M2 | FLOAT32     | FLOAT32           | null     |  null     | null/FLOAT32 | FLOAT16/BFLOAT16/FLOAT32               |
      | HIFLOAT8                  | HIFLOAT8                  | FLOAT32     | FLOAT32           | null     |  null     | null/FLOAT32 | FLOAT16/BFLOAT16/FLOAT32               |

    - K-Cé‡åŒ–åœºæ™¯ä¸‹ï¼Œx1Scaleçš„shapeä¸º(m,)ï¼Œx2Scaleçš„shapeä¸º(n,)ï¼Œå…¶ä¸­mä¸x1çš„mä¸€è‡´ï¼Œnä¸x2çš„nä¸€è‡´;
    - K-Té‡åŒ–åœºæ™¯ä¸‹ï¼Œx1Scaleçš„shapeä¸º(m,)ï¼Œx2Scaleçš„shapeä¸º(1,)ï¼Œå…¶ä¸­mä¸x1çš„mä¸€è‡´ã€‚
  
  - **G-Bé‡åŒ– && B-Bé‡åŒ–åœºæ™¯çº¦æŸï¼š**
  <a id="G-Bé‡åŒ– && B-Bé‡åŒ–"></a>
    - è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆï¼š
  <a id="è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆGB/BB"></a>
      | x1                        | x2                        | x1Scale     | x2Scale     |   x2Offset | yScale | bias    | out                                    |
      | ------------------------- | ------------------------- | ----------- | ----------- |   -------- | -------| ------- | -------------------------------------- |
      | FLOAT8_E4M3FN/ FLOAT8_E5M2 | FLOAT8_E4M3FN/ FLOAT8_E5M2 | FLOAT32     |   FLOAT32           | null     | null     | null | FLOAT16/BFLOAT16/  FLOAT32               |
      | HIFLOAT8                  | HIFLOAT8                  | FLOAT32     |   FLOAT32           | null     | null     | null | FLOAT16/BFLOAT16/  FLOAT32               |
      | INT8                      |INT8                       | FLOAT32     |   FLOAT32           | null     | FLOAT32     | null |BFLOAT16       |
    - x1ã€x2ã€x1Scaleã€x2Scaleå’ŒgroupSizeçš„å–å€¼å…³ç³»ï¼š
      |é‡åŒ–ç±»å‹|x1 shape|x2 shape|x1Scale shape|x2Scale shape|yScale shape|[gsMï¼ŒgsNï¼ŒgsK]|groupSize|
      |-------|--------|--------|-------------|-------------|------------|---|---|
      |B-Bé‡åŒ–|<li>éè½¬ç½®ï¼š(batch, m, k)</li><li>è½¬ç½®ï¼š(batch, k, m)</li>|<li>éè½¬ç½®ï¼š(batch, k, n)</li><li>è½¬ç½®ï¼š(batch, n, k)</li>|<li>éè½¬ç½®ï¼š(batch, ceil(m / 128), ceil(k / 128))</li><li>è½¬ç½®ï¼š(batch, ceil(k / 128), ceil(m / 128))</li>|<li>éè½¬ç½®ï¼š(batch, ceil(k / 128), ceil(n / 128))</li><li>è½¬ç½®ï¼š(batch, ceil(n / 128), ceil(k / 128))</li>|null|[128, 128, 128]|549764202624|
      |G-Bé‡åŒ–|<li>éè½¬ç½®ï¼š(batch, m, k)</li><li>è½¬ç½®ï¼š(batch, k, m)</li>|<li>éè½¬ç½®ï¼š(batch, k, n)</li><li>è½¬ç½®ï¼š(batch, n, k)</li>|<li>éè½¬ç½®ï¼š(batch, m, ceil(k / 128))</li><li>è½¬ç½®ï¼š(batch, ceil(k / 128), m)</li>|<li>éè½¬ç½®ï¼š(batch, ceil(k / 128), ceil(n / 128))</li><li>è½¬ç½®ï¼š(batch, ceil(n / 128), ceil(k / 128))</li>|null|[1, 128, 128]|4303356032|
    - æ³¨ï¼šä¸Šè¡¨ä¸­gsMã€gsKå’ŒgsNåˆ†åˆ«è¡¨ç¤ºgroupSizeMã€groupSizeKå’ŒgroupSizeNã€‚
    - G-Bé‡åŒ–å’ŒB-Bé‡åŒ–åœºæ™¯ä¸‹ï¼Œx1å’Œx1Scaleçš„è½¬ç½®å±æ€§éœ€è¦ä¿æŒä¸€è‡´ï¼Œx2å’Œx2Scaleçš„è½¬ç½®å±æ€§éœ€è¦ä¿æŒä¸€è‡´ã€‚
    - G-Bé‡åŒ–ä¸‹ï¼ŒINT8 é‡åŒ–åœºæ™¯æ”¯æŒå¯é€‰biasï¼Œå…¶ä½™åœºæ™¯ä¸æ”¯æŒã€‚
    - B-Bé‡åŒ–åœºæ™¯ä¸‹ï¼Œä¸æ”¯æŒbiasã€‚
  - **mxé‡åŒ–åœºæ™¯çº¦æŸï¼š**
  <a id="mxé‡åŒ–"></a>
    - è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆï¼š
  <a id="è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆmx"></a>
      |é‡åŒ–ç±»å‹| x1                        | x2                        | x1Scale     | x2Scale     |   x2Offset | yScale | bias    | out                                    |
      |-------| ------------------------- | ------------------------- | ----------- | ----------- |   -------- | -------| ------- | -------------------------------------- |
      |mx å…¨é‡åŒ–| FLOAT8_E4M3FN/ FLOAT8_E5M2 | FLOAT8_E4M3FN/ FLOAT8_E5M2 | FLOAT8_E8M0 |   FLOAT8_E8M0       | null     | null     | null/FLOAT32 | FLOAT16/BFLOAT16/FLOAT32               |
      |mx å…¨é‡åŒ–| FLOAT4_E2M1/ FLOAT4_E1M2 | FLOAT4_E2M1/ FLOAT4_E1M2 | FLOAT8_E8M0 |   FLOAT8_E8M0       | null     | null     | null/FLOAT32 | FLOAT16/BFLOAT16/FLOAT32               |
      |mx ä¼ªé‡åŒ–| FLOAT8_E4M3FN             | FLOAT4_E2M1               | FLOAT8_E8M0 |   FLOAT8_E8M0       | null     | null     | null/BFLOAT16|  BFLOAT16                               |
    - x1æ•°æ®ç±»å‹ã€x2æ•°æ®ç±»å‹ã€x1ã€x2ã€x1Scaleã€x2Scaleå’ŒgroupSizeçš„å–å€¼å…³ç³»ï¼š
      |é‡åŒ–ç±»å‹|x1æ•°æ®ç±»å‹|x2æ•°æ®ç±»å‹|x1 shape|x2 shape|x1Scale shape|x2Scale shape|bias shape|yScale shape|[gsMï¼ŒgsNï¼ŒgsK]|groupSize|
      |-------|--------|--------|--------|--------|-------------|-------------|------------|---------------------------------------|--|--|
      |mx å…¨é‡åŒ–|FLOAT8_E4M3FN/ FLOAT8_E5M2|FLOAT8_E4M3FN/ FLOAT8_E5M2|<li>éè½¬ç½®ï¼š(batch, m, k)</li><li>è½¬ç½®ï¼š(batch, k, m)</li>|<li>éè½¬ç½®ï¼š(batch, k, n)</li><li>è½¬ç½®ï¼š(batch, n, k)</li>|<li>éè½¬ç½®ï¼š(m, ceil(k / 64), 2)</li><li>è½¬ç½®ï¼š(ceil(k / 64), m, 2)</li>|<li>éè½¬ç½®ï¼š(ceil(k / 64), n, 2)</li><li>è½¬ç½®ï¼š(n, ceil(k / 64), 2)</li>|(n,)æˆ–(batch, 1, n)|null|[1, 1, 32]|4295032864|
      |mx å…¨é‡åŒ–|FLOAT4_E2M1/ FLOAT4_E1M2|FLOAT4_E2M1/ FLOAT4_E1M2|(batch, m, k)|(batch, n, k)|(m, ceil(k / 64), 2)|(n, ceil(k / 64), 2)|(n,)æˆ–(batch, 1, n)|null|[1, 1, 32]|4295032864|
      |mx ä¼ªé‡åŒ–|FLOAT8_E4M3FN|FLOAT4_E2M1|(m, k)|(n, k)|(m, ceil(k / 32))|(n, ceil(k / 32))|(1ï¼Œn)|null|[1, 1, 32]|4295032864|

    - mxå…¨é‡åŒ–åœºæ™¯ä¸‹ï¼Œå½“x2æ•°æ®ç±»å‹ä¸ºFLOAT8_E4M3FN/FLOAT8_E5M2æ—¶ï¼Œx1å’Œx1Scaleçš„è½¬ç½®å±æ€§éœ€è¦ä¿æŒä¸€è‡´ï¼Œx2å’Œx2Scaleçš„è½¬ç½®å±æ€§éœ€è¦ä¿æŒä¸€è‡´ã€‚
    - mxå…¨é‡åŒ–åœºæ™¯ä¸‹ï¼Œå½“x2æ•°æ®ç±»å‹ä¸ºFLOAT4_E2M1/FLOAT4_E1M2æ—¶ï¼Œä»…æ”¯æŒtransposeX1ä¸ºfalseä¸”transposeX2ä¸ºtrueï¼Œè¦æ±‚kä¸ºå¶æ•°ä¸”ceil(k / 32)ä¸ºå¶æ•°ã€‚
    - mxä¼ªé‡åŒ–åœºæ™¯ä¸‹ï¼Œå½“x2æ•°æ®ç±»å‹ä¸ºFLOAT4_E2M1æ—¶ï¼Œä»…æ”¯æŒkæ˜¯64çš„å€æ•°ï¼ŒtransposeX1ä¸ºfalseï¼Œä¸æ”¯æŒbatchè½´ã€‚æ•°æ®æ ¼å¼æ”¯æŒNDå’ŒAIå¤„ç†å™¨äº²å’Œæ•°æ®æ’å¸ƒæ ¼å¼ã€‚å½“æ•°æ®æ ¼å¼ä¸ºAIå¤„ç†å™¨äº²å’Œæ•°æ®æ’å¸ƒæ ¼å¼æ—¶, è¦æ±‚k, néƒ½æ˜¯64çš„å€æ•°ã€‚
    - mxä¼ªé‡åŒ–åœºæ™¯ä¸‹ï¼Œbiasä¸ºå¯é€‰å‚æ•°ã€‚æ•°æ®ç±»å‹æ”¯æŒBFLOAT16, æ•°æ®æ ¼å¼æ”¯æŒNDï¼Œshapeæ”¯æŒ2ç»´ï¼Œshapeè¡¨ç¤º(1ï¼Œn)ã€‚å¦‚ä¸éœ€è¦ä½¿ç”¨è¯¥å‚æ•°ï¼Œä¼ å…¥nullptrã€‚

  - **T-CGé‡åŒ–åœºæ™¯çº¦æŸï¼š**
  <a id="T-CGé‡åŒ–"></a>
    - è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆï¼š
  <a id="è¾“å…¥å’Œè¾“å‡ºæ”¯æŒä»¥ä¸‹æ•°æ®ç±»å‹ç»„åˆTCG"></a>
      | x1                        | x2                        | x1Scale     | x2Scale     |     x2Offset | yScale | bias    | out                                    |
      | ------------------------- | ------------------------- | ----------- | ----------- |     -------- | -------| ------- | -------------------------------------- |
      | FLOAT8_E4M3FN             | FLOAT4_E2M1               | null        |     BFLOAT16          | null     | INT64/UINT64    | null         |     BFLOAT16                               |
    - x1ã€x2ã€x1Scaleã€x2Scaleå’ŒgroupSizeçš„å–å€¼å…³ç³»ï¼š
      |é‡åŒ–ç±»å‹|x1 shape|x2 shape|x1Scale shape|x2Scale shape|yScale shape|[gsMï¼ŒgsNï¼ŒgsK]|groupSize|
      |-------|--------|--------|-------------|-------------|------------|---------------------------------------|--|
      |T-CGé‡åŒ–|(m, k)|(n, k)/(k, n)|(m, ceil(k / 32))|(n, ceil(k / 32))/(ceil(k / 32), n)|(1, n)|[1, 1, 32]|4295032864|
    - T-CGé‡åŒ–æ¨¡å¼ä¸‹ï¼Œæ•°æ®ç±»å‹æ”¯æŒINT64å’ŒUINT64ï¼Œæ•°æ®æ ¼å¼æ”¯æŒNDï¼Œshapeæ”¯æŒ2ç»´ï¼Œshapeè¡¨ç¤ºä¸º(1, n)ã€‚å½“åŸå§‹è¾“å…¥ç±»å‹ä¸æ»¡è¶³çº¦æŸå’Œé™åˆ¶ä¸­çš„æ•°æ®ç±»å‹ç»„åˆæ—¶ï¼Œéœ€è¦æå‰è°ƒç”¨TransQuantParamV2ç®—å­çš„aclnnæ¥å£æ¥å°†å…¶è½¬æˆUINT64æ•°æ®ç±»å‹ã€‚å½“è¾“å…¥æ•°æ®ç±»å‹æ˜¯INT64æ—¶ï¼Œå†…éƒ¨ä¼šæŠŠINT64å½“æˆUINT64å¤„ç†ã€‚
    - T-CGé‡åŒ–æ¨¡å¼ä¸‹ï¼Œbiasæ˜¯é¢„ç•™å‚æ•°ï¼Œå½“å‰ç‰ˆæœ¬ä¸æ”¯æŒï¼Œéœ€è¦ä¼ å…¥nullptrã€‚

</details>

## è°ƒç”¨ç¤ºä¾‹

ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼Œä»…ä¾›å‚è€ƒï¼Œå…·ä½“ç¼–è¯‘å’Œæ‰§è¡Œè¿‡ç¨‹è¯·å‚è€ƒ[ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹](../../../docs/zh/context/ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹.md)ã€‚

- <term>Ascend 950PR/Ascend 950DT</term>ï¼š

  ```cpp
  #include <iostream>
  #include <memory>
  #include <vector>

  #include "acl/acl.h"
  #include "aclnnop/aclnn_quant_matmul_v5.h"

  #define CHECK_RET(cond, return_expr) \
      do {                             \
          if (!(cond)) {               \
              return_expr;             \
          }                            \
      } while (0)

  #define CHECK_FREE_RET(cond, return_expr) \
      do {                                  \
          if (!(cond)) {                    \
              Finalize(deviceId, stream);   \
              return_expr;                  \
          }                                 \
      } while (0)

  #define LOG_PRINT(message, ...)         \
      do {                                \
          printf(message, ##__VA_ARGS__); \
      } while (0)

      int64_t
      GetShapeSize(const std::vector<int64_t> &shape)
  {
      int64_t shapeSize = 1;
      for (auto i : shape) {
          shapeSize *= i;
      }
      return shapeSize;
  }

  int Init(int32_t deviceId, aclrtStream *stream)
  {
      // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
      auto ret = aclInit(nullptr);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
      ret = aclrtSetDevice(deviceId);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
      ret = aclrtCreateStream(stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
      return 0;
  }

  template <typename T>
  int CreateAclTensor(const std::vector<T> &hostData, const std::vector<int64_t> &shape, void **deviceAddr,
                      aclDataType dataType, aclTensor **tensor)
  {
      auto size = GetShapeSize(shape) * sizeof(T);
      // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
      auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);
      // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®æ‹·è´åˆ°deviceä¾§å†…å­˜ä¸Š
      ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);

      // è®¡ç®—è¿ç»­tensorçš„strides
      std::vector<int64_t> strides(shape.size(), 1);
      for (int64_t i = shape.size() - 2; i >= 0; i--) {
          strides[i] = shape[i + 1] * strides[i + 1];
      }

      // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
      *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_ND,
                                shape.data(), shape.size(), *deviceAddr);
      return 0;
  }

  void Finalize(int32_t deviceId, aclrtStream stream)
  {
      aclrtDestroyStream(stream);
      aclrtResetDevice(deviceId);
      aclFinalize();
  }

  int aclnnQuantMatmulV5Test(int32_t deviceId, aclrtStream &stream)
  {
      auto ret = Init(deviceId, &stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);

      // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
      std::vector<int64_t> x1Shape = {5, 16};
      std::vector<int64_t> x2Shape = {16, 8};
      std::vector<int64_t> biasShape = {8};
      std::vector<int64_t> x2OffsetShape = {8};
      std::vector<int64_t> x1ScaleShape = {5};
      std::vector<int64_t> x2ScaleShape = {8};
      std::vector<int64_t> outShape = {5, 8};
      void *x1DeviceAddr = nullptr;
      void *x2DeviceAddr = nullptr;
      void *x2ScaleDeviceAddr = nullptr;
      void *x2OffsetDeviceAddr = nullptr;
      void *x1ScaleDeviceAddr = nullptr;
      void *biasDeviceAddr = nullptr;
      void *outDeviceAddr = nullptr;
      aclTensor *x1 = nullptr;
      aclTensor *x2 = nullptr;
      aclTensor *bias = nullptr;
      aclTensor *x2Scale = nullptr;
      aclTensor *x2Offset = nullptr;
      aclTensor *x1Scale = nullptr;
      aclTensor *out = nullptr;
      std::vector<int8_t> x1HostData(80, 1);
      std::vector<int8_t> x2HostData(128, 1);
      std::vector<int32_t> biasHostData(8, 1);
      std::vector<float> x2ScaleHostData(8, 1);
      std::vector<float> x2OffsetHostData(8, 1);
      std::vector<float> x1ScaleHostData(5, 1);
      std::vector<uint16_t> outHostData(40, 1);  // å®é™…ä¸Šæ˜¯float16åŠç²¾åº¦æ–¹å¼
      // åˆ›å»ºx1 aclTensor
      ret = CreateAclTensor(x1HostData, x1Shape, &x1DeviceAddr, aclDataType::ACL_INT8, &x1);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> x1TensorPtr(x1, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x1DeviceAddrPtr(x1DeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºx2 aclTensor
      ret = CreateAclTensor(x2HostData, x2Shape, &x2DeviceAddr, aclDataType::ACL_INT8, &x2);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> x2TensorPtr(x2, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x2DeviceAddrPtr(x2DeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºx1Scale aclTensor
      ret = CreateAclTensor(x1ScaleHostData, x1ScaleShape, &x1ScaleDeviceAddr,
                            aclDataType::ACL_FLOAT, &x1Scale);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> x1ScaleTensorPtr(x1Scale,
                                                                                            aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x1ScaleDeviceAddrPtr(x1ScaleDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºx2Scale aclTensor
      ret = CreateAclTensor(x2ScaleHostData, x2ScaleShape, &x2ScaleDeviceAddr, aclDataType::ACL_FLOAT, &x2Scale);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> scaleTensorPtr(x2Scale, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x2ScaleDeviceAddrPtr(x2ScaleDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºbias aclTensor
      ret = CreateAclTensor(biasHostData, biasShape, &biasDeviceAddr, aclDataType::ACL_INT32, &bias);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> biasTensorPtr(bias, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> biasDeviceAddrPtr(biasDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºout aclTensor
      ret = CreateAclTensor(outHostData, outShape, &outDeviceAddr, aclDataType::ACL_FLOAT16, &out);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> outTensorPtr(out, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> outDeviceAddrPtr(outDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      bool transposeX1 = false;
      bool transposeX2 = false;

      // 3. è°ƒç”¨CANNç®—å­åº“APIï¼Œéœ€è¦ä¿®æ”¹ä¸ºå…·ä½“çš„Apiåç§°
      uint64_t workspaceSize = 0;
      aclOpExecutor *executor = nullptr;
      // è°ƒç”¨aclnnQuantMatmulV5ç¬¬ä¸€æ®µæ¥å£
      ret = aclnnQuantMatmulV5GetWorkspaceSize(x1, x2, x1Scale, x2Scale, nullptr, nullptr, nullptr, nullptr, bias,
                                               transposeX1, transposeX2, 0, out, &workspaceSize, &executor);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnQuantMatmulV5GetWorkspaceSize failed. ERROR: %d\n", ret);
                return ret);
      // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
      void *workspaceAddr = nullptr;
      std::unique_ptr<void, aclError (*)(void *)> workspaceAddrPtr(nullptr, aclrtFree);
      if (workspaceSize > 0) {
          ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
          CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret);
          workspaceAddrPtr.reset(workspaceAddr);
      }
      // è°ƒç”¨aclnnQuantMatmulV5ç¬¬äºŒæ®µæ¥å£
      ret = aclnnQuantMatmulV5(workspaceAddr, workspaceSize, executor, stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnQuantMatmulV5 failed. ERROR: %d\n", ret); return ret);

      // 4.ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
      ret = aclrtSynchronizeStream(stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);

      // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
      auto size = GetShapeSize(outShape);
      std::vector<uint16_t> resultData(
          size, 0);  // Cè¯­è¨€ä¸­æ— æ³•ç›´æ¥æ‰“å°fp16çš„æ•°æ®ï¼Œéœ€è¦ç”¨uint16è¯»å‡ºæ¥ï¼Œè‡ªè¡Œé€šè¿‡äºŒè¿›åˆ¶è½¬æˆfp16
      ret = aclrtMemcpy(resultData.data(), resultData.size() * sizeof(resultData[0]), outDeviceAddr,
                        size * sizeof(resultData[0]), ACL_MEMCPY_DEVICE_TO_HOST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret);
                return ret);
      for (int64_t i = 0; i < size; i++) {
          LOG_PRINT("result[%ld] is: %u\n", i, resultData[i]);
      }
      return ACL_SUCCESS;
  }

  int main()
  {
      // 1.ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–ï¼Œå‚è€ƒacl APIæ‰‹å†Œ
      // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
      int32_t deviceId = 0;
      aclrtStream stream;
      auto ret = aclnnQuantMatmulV5Test(deviceId, stream);
      CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnQuantMatmulV5Test failed. ERROR: %d\n", ret); return ret);

      Finalize(deviceId, stream);
      return 0;
  }
  ```

- <term>Ascend 950PR/Ascend 950DT</term>ï¼š
x1ï¼Œx2ä¸ºFLOAT8_E4M3FNï¼Œx1Scaleä¸ºFLOAT32ï¼Œx2Scaleä¸ºFLOAT32ï¼Œæ— x2Offsetï¼Œbiasä¸ºFLOAT32ã€‚

  ```cpp
  #include <iostream>
  #include <memory>
  #include <vector>

  #include "acl/acl.h"
  #include "aclnnop/aclnn_quant_matmul_v5.h"

  #define CHECK_RET(cond, return_expr) \
      do {                             \
          if (!(cond)) {               \
              return_expr;             \
          }                            \
      } while (0)

  #define CHECK_FREE_RET(cond, return_expr) \
      do {                                  \
          if (!(cond)) {                    \
              Finalize(deviceId, stream);   \
              return_expr;                  \
          }                                 \
      } while (0)

  #define LOG_PRINT(message, ...)         \
      do {                                \
          printf(message, ##__VA_ARGS__); \
      } while (0)

      int64_t
      GetShapeSize(const std::vector<int64_t> &shape)
  {
      int64_t shapeSize = 1;
      for (auto i : shape) {
          shapeSize *= i;
      }
      return shapeSize;
  }

  int Init(int32_t deviceId, aclrtStream *stream)
  {
      // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
      auto ret = aclInit(nullptr);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
      ret = aclrtSetDevice(deviceId);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
      ret = aclrtCreateStream(stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
      return 0;
  }

  template <typename T>
  int CreateAclTensor(const std::vector<T> &hostData, const std::vector<int64_t> &shape, void **deviceAddr,
                      aclDataType dataType, aclTensor **tensor)
  {
      auto size = GetShapeSize(shape) * sizeof(T);
      // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
      auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);
      // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®æ‹·è´åˆ°deviceä¾§å†…å­˜ä¸Š
      ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);

      // è®¡ç®—è¿ç»­tensorçš„strides
      std::vector<int64_t> strides(shape.size(), 1);
      for (int64_t i = shape.size() - 2; i >= 0; i--) {
          strides[i] = shape[i + 1] * strides[i + 1];
      }

      // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
      *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_ND,
                                shape.data(), shape.size(), *deviceAddr);
      return 0;
  }

  void Finalize(int32_t deviceId, aclrtStream stream)
  {
      aclrtDestroyStream(stream);
      aclrtResetDevice(deviceId);
      aclFinalize();
  }

  int aclnnQuantMatmulV5Test(int32_t deviceId, aclrtStream &stream)
  {
      auto ret = Init(deviceId, &stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);

      // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
      std::vector<int64_t> x1Shape = {16, 16};
      std::vector<int64_t> x2Shape = {16, 16};
      std::vector<int64_t> biasShape = {16};
      std::vector<int64_t> x2OffsetShape = {16};
      std::vector<int64_t> x1ScaleShape = {1};
      std::vector<int64_t> x2ScaleShape = {1};
      std::vector<int64_t> outShape = {16, 16};
      void *x1DeviceAddr = nullptr;
      void *x2DeviceAddr = nullptr;
      void *x2ScaleDeviceAddr = nullptr;
      void *x2OffsetDeviceAddr = nullptr;
      void *x1ScaleDeviceAddr = nullptr;
      void *biasDeviceAddr = nullptr;
      void *outDeviceAddr = nullptr;
      aclTensor *x1 = nullptr;
      aclTensor *x2 = nullptr;
      aclTensor *bias = nullptr;
      aclTensor *x2Scale = nullptr;
      aclTensor *x2Offset = nullptr;
      aclTensor *x1Scale = nullptr;
      aclTensor *out = nullptr;
      std::vector<int8_t> x1HostData(256, 1);
      std::vector<int8_t> x2HostData(256, 1);
      std::vector<int32_t> biasHostData(16, 1);
      std::vector<float> x2ScaleHostData(1, 1);
      std::vector<float> x2OffsetHostData(16, 1);
      std::vector<float> x1ScaleHostData(1, 1);
      std::vector<uint16_t> outHostData(256, 1);  // å®é™…ä¸Šæ˜¯float16åŠç²¾åº¦æ–¹å¼

      // åˆ›å»ºx1 aclTensor
      ret = CreateAclTensor(x1HostData, x1Shape, &x1DeviceAddr, aclDataType::ACL_FLOAT8_E4M3FN, &x1);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> x1TensorPtr(x1, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x1DeviceAddrPtr(x1DeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºx2 aclTensor
      ret = CreateAclTensor(x2HostData, x2Shape, &x2DeviceAddr, aclDataType::ACL_FLOAT8_E4M3FN, &x2);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> x2TensorPtr(x2, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x2DeviceAddrPtr(x2DeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºx2Scale aclTensor
      ret = CreateAclTensor(x2ScaleHostData, x2ScaleShape, &x2ScaleDeviceAddr, aclDataType::ACL_FLOAT, &x2Scale);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> scaleTensorPtr(x2Scale, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x2ScaleDeviceAddrPtr(x2ScaleDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºx1Scale aclTensor
      ret = CreateAclTensor(x1ScaleHostData, x1ScaleShape, &x1ScaleDeviceAddr,
                            aclDataType::ACL_FLOAT, &x1Scale);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> x1ScaleTensorPtr(x1Scale,
                                                                                            aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x1ScaleDeviceAddrPtr(x1ScaleDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºbias aclTensor
      ret = CreateAclTensor(biasHostData, biasShape, &biasDeviceAddr, aclDataType::ACL_FLOAT, &bias);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> biasTensorPtr(bias, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> biasDeviceAddrPtr(biasDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºout aclTensor
      ret = CreateAclTensor(outHostData, outShape, &outDeviceAddr, aclDataType::ACL_FLOAT16, &out);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> outTensorPtr(out, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> outDeviceAddrPtr(outDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      bool transposeX1 = false;
      bool transposeX2 = false;

      // 3. è°ƒç”¨CANNç®—å­åº“APIï¼Œéœ€è¦ä¿®æ”¹ä¸ºå…·ä½“çš„Apiåç§°
      uint64_t workspaceSize = 0;
      aclOpExecutor *executor = nullptr;
      // è°ƒç”¨aclnnQuantMatmulV5ç¬¬ä¸€æ®µæ¥å£
      ret = aclnnQuantMatmulV5GetWorkspaceSize(x1, x2, x1Scale, x2Scale, nullptr, nullptr, x2Offset, nullptr, bias,
                                               transposeX1, transposeX2, 0, out, &workspaceSize, &executor);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnQuantMatmulV5GetWorkspaceSize failed. ERROR: %d\n", ret);
                return ret);
      // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
      void *workspaceAddr = nullptr;
      std::unique_ptr<void, aclError (*)(void *)> workspaceAddrPtr(nullptr, aclrtFree);
      if (workspaceSize > 0) {
          ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
          CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret);
          workspaceAddrPtr.reset(workspaceAddr);
      }
      // è°ƒç”¨aclnnQuantMatmulV5ç¬¬äºŒæ®µæ¥å£
      ret = aclnnQuantMatmulV5(workspaceAddr, workspaceSize, executor, stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnQuantMatmulV5 failed. ERROR: %d\n", ret); return ret);

      // 4.ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
      ret = aclrtSynchronizeStream(stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);

      // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
      auto size = GetShapeSize(outShape);
      std::vector<uint16_t> resultData(
          size, 0);  // Cè¯­è¨€ä¸­æ— æ³•ç›´æ¥æ‰“å°fp16çš„æ•°æ®ï¼Œéœ€è¦ç”¨uint16è¯»å‡ºæ¥ï¼Œè‡ªè¡Œé€šè¿‡äºŒè¿›åˆ¶è½¬æˆfp16
      ret = aclrtMemcpy(resultData.data(), resultData.size() * sizeof(resultData[0]), outDeviceAddr,
                        size * sizeof(resultData[0]), ACL_MEMCPY_DEVICE_TO_HOST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret);
                return ret);
      for (int64_t i = 0; i < size; i++) {
          LOG_PRINT("result[%ld] is: %u\n", i, resultData[i]);
      }
      return ACL_SUCCESS;
  }

  int main()
  {
      // 1.ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–ï¼Œå‚è€ƒacl APIæ‰‹å†Œ
      // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
      int32_t deviceId = 0;
      aclrtStream stream;
      auto ret = aclnnQuantMatmulV5Test(deviceId, stream);
      CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnQuantMatmulV5Test failed. ERROR: %d\n", ret); return ret);

      Finalize(deviceId, stream);
      return 0;
  }
  ```

- <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ã€<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>ï¼š
x1ä¸ºINT8ï¼Œx2ä¸ºINT32ï¼Œx1Scaleä¸ºFLOAT32ï¼Œx2Scaleä¸ºUINT64ã€‚

  ```cpp
  #include <iostream>
  #include <memory>
  #include <vector>

  #include "acl/acl.h"
  #include "aclnnop/aclnn_quant_matmul_v5.h"

  #define CHECK_RET(cond, return_expr) \
      do {                             \
          if (!(cond)) {               \
              return_expr;             \
          }                            \
      } while (0)

  #define CHECK_FREE_RET(cond, return_expr) \
      do {                                  \
          if (!(cond)) {                    \
              Finalize(deviceId, stream);   \
              return_expr;                  \
          }                                 \
      } while (0)

  #define LOG_PRINT(message, ...)         \
      do {                                \
          printf(message, ##__VA_ARGS__); \
      } while (0)

  int64_t GetShapeSize(const std::vector<int64_t> &shape)
  {
      int64_t shapeSize = 1;
      for (auto i : shape) {
          shapeSize *= i;
      }
      return shapeSize;
  }

  int Init(int32_t deviceId, aclrtStream *stream)
  {
      // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
      auto ret = aclInit(nullptr);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
      ret = aclrtSetDevice(deviceId);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
      ret = aclrtCreateStream(stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
      return 0;
  }

  template <typename T>
  int CreateAclTensor(const std::vector<T> &hostData, const std::vector<int64_t> &shape, void **deviceAddr,
                      aclDataType dataType, aclTensor **tensor)
  {
      auto size = GetShapeSize(shape) * sizeof(T);
      // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
      auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);
      // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®æ‹·è´åˆ°deviceä¾§å†…å­˜ä¸Š
      ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);

      // è®¡ç®—è¿ç»­tensorçš„strides
      std::vector<int64_t> strides(shape.size(), 1);
      for (int64_t i = shape.size() - 2; i >= 0; i--) {
          strides[i] = shape[i + 1] * strides[i + 1];
      }

      // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
      *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_ND,
                              shape.data(), shape.size(), *deviceAddr);
      return 0;
  }

  void Finalize(int32_t deviceId, aclrtStream stream)
  {
      aclrtDestroyStream(stream);
      aclrtResetDevice(deviceId);
      aclFinalize();
  }

  int aclnnQuantMatmulV5Test(int32_t deviceId, aclrtStream &stream)
  {
      auto ret = Init(deviceId, &stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);

      // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
      std::vector<int64_t> x1Shape = {1, 8192};     // (m,k)
      std::vector<int64_t> x2Shape = {8192, 128};  // (k,n)
      std::vector<int64_t> yoffsetShape = {1024};

      std::vector<int64_t> x1ScaleShape = {1,1};
      std::vector<int64_t> x2ScaleShape = {32, 1024}; // x2ScaleShape = [KShape / groupsize, N]
      std::vector<int64_t> outShape = {1, 1024};

      void *x1DeviceAddr = nullptr;
      void *x2DeviceAddr = nullptr;
      void *x2ScaleDeviceAddr = nullptr;
      void *x1ScaleDeviceAddr = nullptr;
      void *yoffsetDeviceAddr = nullptr;
      void *outDeviceAddr = nullptr;
      aclTensor *x1 = nullptr;
      aclTensor *x2 = nullptr;
      aclTensor *yoffset = nullptr;
      aclTensor *x2Scale = nullptr;
      aclTensor *x2Offset = nullptr;
      aclTensor *x1Scale = nullptr;
      aclTensor *out = nullptr;
      std::vector<int8_t> x1HostData(GetShapeSize(x1Shape), 1);
      std::vector<int32_t> x2HostData(GetShapeSize(x2Shape), 1);
      std::vector<int32_t> yoffsetHostData(GetShapeSize(yoffsetShape), 1);
      std::vector<int32_t> x1ScaleHostData(GetShapeSize(x1ScaleShape), 1);
      float tmp = 1;
      uint64_t ans = static_cast<uint64_t>(*reinterpret_cast<int32_t*>(&tmp));
      std::vector<int64_t> x2ScaleHostData(GetShapeSize(x2ScaleShape), ans);
      std::vector<uint16_t> outHostData(GetShapeSize(outShape), 1);  // å®é™…ä¸Šæ˜¯float16åŠç²¾åº¦æ–¹å¼

      // åˆ›å»ºx1 aclTensor
      ret = CreateAclTensor(x1HostData, x1Shape, &x1DeviceAddr, aclDataType::ACL_INT8, &x1);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> x1TensorPtr(x1, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x1DeviceAddrPtr(x1DeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºx2 aclTensor
      ret = CreateAclTensor(x2HostData, x2Shape, &x2DeviceAddr, aclDataType::ACL_INT32, &x2);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> x2TensorPtr(x2, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x2DeviceAddrPtr(x2DeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºx1Scale aclTensor
      ret = CreateAclTensor(x1ScaleHostData, x1ScaleShape, &x1ScaleDeviceAddr, aclDataType::ACL_FLOAT, &x1Scale);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> x1ScaleTensorPtr(x1Scale, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x1ScaleDeviceAddrPtr(x1ScaleDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºx2Scale aclTensor
      ret = CreateAclTensor(x2ScaleHostData, x2ScaleShape, &x2ScaleDeviceAddr, aclDataType::ACL_UINT64, &x2Scale);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> scaleTensorPtr(x2Scale, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> x2ScaleDeviceAddrPtr(x2ScaleDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºyoffset aclTensor
      ret = CreateAclTensor(yoffsetHostData, yoffsetShape, &yoffsetDeviceAddr, aclDataType::ACL_FLOAT, &yoffset);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> yoffsetTensorPtr(yoffset, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> yoffsetDeviceAddrPtr(yoffsetDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      // åˆ›å»ºout aclTensor
      ret = CreateAclTensor(outHostData, outShape, &outDeviceAddr, aclDataType::ACL_FLOAT16, &out);
      std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> outTensorPtr(out, aclDestroyTensor);
      std::unique_ptr<void, aclError (*)(void *)> outDeviceAddrPtr(outDeviceAddr, aclrtFree);
      CHECK_RET(ret == ACL_SUCCESS, return ret);
      bool transposeX1 = false;
      bool transposeX2 = false;
      int64_t groupSize = 256;

      // 3. è°ƒç”¨CANNç®—å­åº“APIï¼Œéœ€è¦ä¿®æ”¹ä¸ºå…·ä½“çš„Apiåç§°
      uint64_t workspaceSize = 0;
      aclOpExecutor *executor = nullptr;

      ret = aclnnQuantMatmulV5GetWorkspaceSize(x1, x2, x1Scale, x2Scale, nullptr, nullptr, nullptr, yoffset, nullptr,
                                              transposeX1, transposeX2, groupSize, out, &workspaceSize, &executor);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnQuantMatmulV5GetWorkspaceSize failed. ERROR: %d\n", ret); return ret);
      // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
      void *workspaceAddr = nullptr;
      std::unique_ptr<void, aclError (*)(void *)> workspaceAddrPtr(nullptr, aclrtFree);
      if (workspaceSize > 0) {
          ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
          CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret);
          workspaceAddrPtr.reset(workspaceAddr);
      }
      // è°ƒç”¨aclnnQuantMatmulV5ç¬¬äºŒæ®µæ¥å£
      ret = aclnnQuantMatmulV5(workspaceAddr, workspaceSize, executor, stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnQuantMatmulV5 failed. ERROR: %d\n", ret); return ret);

      // 4.ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
      ret = aclrtSynchronizeStream(stream);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);

      // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
      auto size = GetShapeSize(outShape);
      std::vector<uint16_t> resultData(size, 0);  // Cè¯­è¨€ä¸­æ— æ³•ç›´æ¥æ‰“å°fp16çš„æ•°æ®ï¼Œéœ€è¦ç”¨uint16è¯»å‡ºæ¥ï¼Œè‡ªè¡Œé€šè¿‡äºŒè¿›åˆ¶è½¬æˆfp16
      ret = aclrtMemcpy(resultData.data(), resultData.size() * sizeof(resultData[0]), outDeviceAddr,
                      size * sizeof(resultData[0]), ACL_MEMCPY_DEVICE_TO_HOST);
      CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret);
              return ret);
      for (int64_t i = 0; i < size; i++) {
          LOG_PRINT("result[%ld] is: %u\n", i, resultData[i]);
      }
      return ACL_SUCCESS;
  }

  int main()
  {
      // 1.ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–ï¼Œå‚è€ƒacl APIæ‰‹å†Œ
      // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
      int32_t deviceId = 1;
      aclrtStream stream;
      auto ret = aclnnQuantMatmulV5Test(deviceId, stream);
      CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnQuantMatmulV5Test failed. ERROR: %d\n", ret); return ret);
      Finalize(deviceId, stream);
      return 0;
  }
  ```