# aclnnConvolutionBackward

[ğŸ“„ æŸ¥çœ‹æºç ](https://gitcode.com/cann/ops-nn/tree/master/conv/convolution_backward)

## äº§å“æ”¯æŒæƒ…å†µ

| äº§å“                                                         | æ˜¯å¦æ”¯æŒ |
| :----------------------------------------------------------- | :------: |
| <term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term>                             |    âˆš     |
| <term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>     |    âˆš     |
| <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term> |    âˆš     |
| <term>Atlas 200I/500 A2 æ¨ç†äº§å“</term>                      |    Ã—     |
| <term>Atlas æ¨ç†ç³»åˆ—äº§å“ </term>                             |    âˆš     |
| <term>Atlas è®­ç»ƒç³»åˆ—äº§å“</term>                              |    âˆš     |
| <term>Atlas 200/300/500 æ¨ç†äº§å“</term>                      |    Ã—     |

## åŠŸèƒ½è¯´æ˜

- æ¥å£åŠŸèƒ½ï¼šå·ç§¯çš„åå‘ä¼ æ’­ã€‚æ ¹æ®è¾“å‡ºæ©ç è®¾ç½®è®¡ç®—è¾“å…¥ã€æƒé‡å’Œåå·®çš„æ¢¯åº¦ã€‚æ­¤å‡½æ•°æ”¯æŒ1Dã€2Då’Œ3Då·ç§¯ã€‚   

- è®¡ç®—å…¬å¼ï¼š

  è¾“å…¥input($N,C_{in},D_{in},H_{in},W_{in}$)ã€è¾“å‡ºout($N,C_{out},D_{out},H_{out},W_{out}$)å’Œå·ç§¯æ­¥é•¿($stride$)ã€å·ç§¯æ ¸å¤§å°($kernelSizeï¼ŒkD,kH,kW$)ã€è†¨èƒ€å‚æ•°($dilation$)çš„å…³ç³»æ˜¯ï¼š

  $$
    D_{out}=\lfloor \frac{D_{in}+2*padding[0]-dilation[0] * (kernelSize[0] - 1) - 1}{stride[0]}+1 \rfloor
  $$

  $$
    H_{out}=\lfloor \frac{H_{in}+2*padding[1]-dilation[1] * (kernelSize[1] - 1) - 1}{stride[1]}+1 \rfloor
  $$

  $$
    W_{out}=\lfloor \frac{W_{in}+2*padding[2]-dilation[2] * (kernelSize[2] -1) -1}{stride[2]}+1 \rfloor
  $$
  
  å·ç§¯åå‘ä¼ æ’­éœ€è¦è®¡ç®—å¯¹å·ç§¯æ­£å‘çš„è¾“å…¥å¼ é‡ $x$ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„inputï¼‰ã€å·ç§¯æ ¸æƒé‡å¼ é‡ $w$ ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„weightï¼‰å’Œåç½® $b$ çš„æ¢¯åº¦ã€‚  
  - å¯¹äº $x$ çš„æ¢¯åº¦ $\frac{\partial L}{\partial x}$ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„gradInputå‚æ•°ï¼‰ï¼š
  
    $$
    \frac{\partial L}{\partial x_{n, c_{in}, i, j}} = \sum_{c_{out}=1}^{C_{out}} \sum_{p=1}^{k_H} \sum_{q=1}^{k_W} \frac{\partial L}{\partial y_{n, c_{out}, i-p, j-q}}\cdot w_{c_{out}, c_{in}, p, q}
    $$
  
    å…¶ä¸­ï¼Œ$L$ ä¸ºæŸå¤±å‡½æ•°ï¼Œ$\frac{\partial L}{\partial y}$ ä¸ºè¾“å‡ºå¼ é‡ $y$ å¯¹ $L$ çš„æ¢¯åº¦ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„gradOutputå‚æ•°ï¼‰ã€‚  
  
  - å¯¹äº $w$ çš„æ¢¯åº¦ $\frac{\partial L}{\partial w}$ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„gradWeightå‚æ•°ï¼‰ï¼š
  
    $$
    \frac{\partial L}{\partial w_{c_{out}, c_{in}, p, q}} = \sum_{n=1}^{N} \sum_{i=1}^{H_{out}} \sum_{j=1}^{W_{out}} x_{n, c_{in}, i \cdot s_H + p, j \cdot s_W + q} \cdot \frac{\partial L}{\partial y_{n, c_{out}, i, j}}
    $$
  
  - å¯¹äº $b$ çš„æ¢¯åº¦ $\frac{\partial L}{\partial b}$ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„gradBiaså‚æ•°ï¼‰ï¼š
  
    $$
    \frac{\partial L}{\partial b_{c_{out}}} = \sum_{n=1}^{N}       \sum_{i=1}^{H_{out}} \sum_{j=1}^{W_{out}} \frac{\partial L}{\partial y_{n, c_{out}, i, j}}
    $$

## å‡½æ•°åŸå‹

æ¯ä¸ªç®—å­åˆ†ä¸º[ä¸¤æ®µå¼æ¥å£](../../../docs/zh/context/ä¸¤æ®µå¼æ¥å£.md)ï¼Œå¿…é¡»å…ˆè°ƒç”¨â€œaclnnConvolutionBackwardGetWorkspaceSizeâ€æ¥å£è·å–è®¡ç®—æ‰€éœ€workspaceå¤§å°ä»¥åŠåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹çš„æ‰§è¡Œå™¨ï¼Œå†è°ƒç”¨â€œaclnnConvolutionBackwardâ€æ¥å£æ‰§è¡Œè®¡ç®—ã€‚

```cpp
aclnnStatus aclnnConvolutionBackwardGetWorkspaceSize(  
    const aclTensor     *gradOutput,
    const aclTensor     *input,
    const aclTensor     *weight,
    const aclIntArray   *biasSizes,
    const aclIntArray   *stride,
    const aclIntArray   *padding,
    const aclIntArray   *dilation,
    bool                 transposed,
    const aclIntArray   *outputPadding,
    int                  groups,
    const aclBoolArray  *outputMask,
    int8_t               cubeMathType,
    aclTensor           *gradInput,
    aclTensor           *gradWeight,
    aclTensor           *gradBias,
    uint64_t            *workspaceSize,
    aclOpExecutor      **executor)
```

```cpp
aclnnStatus aclnnConvolutionBackward(   
    void                *workspace,   
    uint64_t             workspaceSize,  
    aclOpExecutor       *executor,  
    const aclrtStream    stream)
```

## aclnnConvolutionBackwardGetWorkspaceSize

- **å‚æ•°è¯´æ˜ï¼š**

  <table style="undefined;table-layout: fixed; width: 1567px"><colgroup>
    <col style="width:170px">
    <col style="width:120px">
    <col style="width:300px">
    <col style="width:330px">
    <col style="width:212px">
    <col style="width:100px">
    <col style="width:190px">
    <col style="width:145px">
    </colgroup>
    <thead>
    <tr>
      <th>å‚æ•°å</th>
      <th>è¾“å…¥/è¾“å‡º</th>
      <th>æè¿°</th>
      <th>ä½¿ç”¨è¯´æ˜</th>
      <th>æ•°æ®ç±»å‹</th>
      <th>æ•°æ®æ ¼å¼</th>
      <th>ç»´åº¦(shape)</th>
      <th>éè¿ç»­Tensor</th>
      </tr></thead>
  <tbody>
    <tr>
      <td>gradOutput</td>
      <td>è¾“å…¥</td>
      <td>è¾“å‡ºå¼ é‡yå¯¹Lçš„æ¢¯åº¦ã€‚</a></td>
      <td>  
       <ul><li>æ”¯æŒç©ºTensorã€‚</li>
       <li>æ•°æ®ç±»å‹ä¸inputã€weightæ»¡è¶³æ•°æ®ç±»å‹æ¨å¯¼è§„åˆ™ï¼ˆå‚è§<a href="../../../docs/zh/context/äº’æ¨å¯¼å…³ç³».md" target="_blank">äº’æ¨å…³ç³»</a>å’Œ<a href="#çº¦æŸè¯´æ˜" target="_blank">çº¦æŸè¯´æ˜</a>ï¼‰ã€‚</li>
       <li>shapeä¸æ”¯æŒbroadcastï¼Œè¦æ±‚å’Œinputã€weightæ»¡è¶³å·ç§¯è¾“å…¥è¾“å‡ºshapeçš„æ¨å¯¼å…³ç³»ã€‚</li>
       <li>æ•°æ®æ ¼å¼éœ€è¦ä¸inputã€gradInputä¸€è‡´ã€‚</li>
      </td>
      <td>FLOATã€FLOAT16ã€BFLOAT16</td>
      <td>NCLã€NCHWã€NCDHW</td>
      <td>å‚è§<a href="#çº¦æŸè¯´æ˜" target="_blank">çº¦æŸè¯´æ˜ã€‚</a></td>
      <td>âˆš</td>
    </tr>
    <tr>
      <td>input</td>
      <td>è¾“å…¥</td>
      <td>å…¬å¼ä¸­çš„xã€‚</td>
      <td>
       <ul><li>æ”¯æŒç©ºTensorã€‚</li>
       <li>æ•°æ®ç±»å‹ä¸gradOutputã€weightæ»¡è¶³æ•°æ®ç±»å‹æ¨å¯¼è§„åˆ™ï¼ˆå‚è§<a href="../../../docs/zh/context/äº’æ¨å¯¼å…³ç³».md" target="_blank">äº’æ¨å…³ç³»</a>å’Œ<a href="#çº¦æŸè¯´æ˜" target="_blank">çº¦æŸè¯´æ˜</a>ï¼‰ã€‚</li>
       <li>shapeä¸æ”¯æŒbroadcastï¼Œè¦æ±‚å’ŒgradOutputã€weightæ»¡è¶³å·ç§¯è¾“å…¥è¾“å‡ºshapeçš„æ¨å¯¼å…³ç³»ã€‚</li>
       <li>æ•°æ®æ ¼å¼éœ€è¦ä¸gradOutputã€gradInputä¸€è‡´ã€‚</li>
      </td>
      <td>FLOATã€FLOAT16ã€BFLOAT16</td>
      <td>NCLã€NCHWã€NCDHW</td>
      <td>å‚è§<a href="#çº¦æŸè¯´æ˜" target="_blank">çº¦æŸè¯´æ˜ã€‚</a></td>
      <td>âˆš</td>
    </tr>
    <tr>
      <td>weight</td>
      <td>è¾“å…¥</td>
      <td>å…¬å¼ä¸­çš„wã€‚</td>
      <td>
       <ul><li>æ”¯æŒç©ºTensorã€‚</li>
       <li>æ•°æ®ç±»å‹ä¸gradOutputã€inputæ»¡è¶³æ•°æ®ç±»å‹æ¨å¯¼è§„åˆ™ï¼ˆå‚è§<a href="../../../docs/zh/context/äº’æ¨å¯¼å…³ç³».md" target="_blank">äº’æ¨å…³ç³»</a>å’Œ<a href="#çº¦æŸè¯´æ˜" target="_blank">çº¦æŸè¯´æ˜</a>ï¼‰ã€‚</li>
       <li>shapeä¸æ”¯æŒbroadcastï¼Œè¦æ±‚å’ŒgradOutputã€inputæ»¡è¶³å·ç§¯è¾“å…¥è¾“å‡ºshapeçš„æ¨å¯¼å…³ç³»ã€‚</li>
       <li>æ•°æ®æ ¼å¼éœ€è¦ä¸gradWeightä¸€è‡´ã€‚</li>
      </td>
      <td>FLOATã€FLOAT16ã€BFLOAT16</td>
      <td>NCLã€NCHWã€NCDHW</td>
      <td>å‚è§<a href="#çº¦æŸè¯´æ˜" target="_blank">çº¦æŸè¯´æ˜ã€‚</a></td>
      <td>âˆš</td>
    </tr>
    <tr>
      <td>biasSizes</td>
      <td>è¾“å…¥</td>
      <td>å·ç§¯æ­£å‘è¿‡ç¨‹ä¸­åå·®(bias)çš„shapeã€‚</td>
      <td>
       <ul><li>æ•°ç»„é•¿åº¦æ˜¯1ã€‚</li>
       <li>åœ¨æ™®é€šå·ç§¯ä¸­ç­‰äº[weight.shape[0]]ï¼Œåœ¨è½¬ç½®å·ç§¯ä¸­ç­‰äº[weight.shape[1] * groups]ã€‚</li>
       <li>ç©ºTensoråœºæ™¯ä¸‹ï¼Œå½“outputMaskæŒ‡å®šåå·®çš„æ¢¯åº¦éœ€è¦è®¡ç®—æ—¶ï¼ŒbiasSizesä¸èƒ½ä¸ºnullptrã€‚</li>
      </td>
      <td>INT64</td>
      <td>-</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>stride</td>
      <td>è¾“å…¥</td>
      <td>åå‘ä¼ æ’­è¿‡ç¨‹ä¸­å·ç§¯æ ¸åœ¨è¾“å…¥ä¸Šç§»åŠ¨çš„æ­¥é•¿ã€‚</td>
      <td>
       <ul><li>å¯¹äºä¸€ç»´å·ç§¯åå‘ï¼Œæ•°ç»„é•¿åº¦å¿…é¡»ä¸º1ã€‚</li>
       <li>æ•°ç»„é•¿åº¦ä¸ºweightç»´åº¦å‡2ï¼Œæ•°å€¼å¿…é¡»å¤§äº0ã€‚</li>
      </td>
      <td>INT64</td>
      <td>-</td>
      <td>å‚è§<a href="#çº¦æŸè¯´æ˜" target="_blank">çº¦æŸè¯´æ˜ã€‚</a></td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>padding</td>
      <td>è¾“å…¥</td>
      <td>åå‘ä¼ æ’­è¿‡ç¨‹ä¸­å¯¹äºè¾“å…¥å¡«å……ã€‚</td>
      <td>
       <ul><li>å¯¹äºä¸€ç»´å·ç§¯åå‘ï¼Œæ•°ç»„é•¿åº¦å¿…é¡»ä¸º1ã€‚</li>
       <li>æ•°ç»„é•¿åº¦å¯ä»¥ä¸ºweightç»´åº¦å‡2ï¼Œåœ¨2dåœºæ™¯ä¸‹æ•°ç»„é•¿åº¦å¯ä»¥ä¸º4ã€‚</li>
       <li>æ•°å€¼å¿…é¡»å¤§äºç­‰äº0ã€‚</li>
      </td>
      <td>INT64</td>
      <td>-</td>
      <td>å‚è§<a href="#çº¦æŸè¯´æ˜" target="_blank">çº¦æŸè¯´æ˜ã€‚</a></td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>dilation</td>
      <td>è¾“å…¥</td>
      <td>åå‘ä¼ æ’­è¿‡ç¨‹ä¸­çš„è†¨èƒ€å‚æ•°ã€‚</td>
      <td>
       <ul><li>å¯¹äºä¸€ç»´å·ç§¯åå‘ï¼Œæ•°ç»„é•¿åº¦å¿…é¡»ä¸º1ã€‚</li>
       <li>æ•°ç»„é•¿åº¦å¯ä»¥ä¸ºweightç»´åº¦å‡2ã€‚</li>
       <li>æ•°å€¼å¿…é¡»å¤§äº0ã€‚</li>
      </td>
      <td>INT64</td>
      <td>-</td>
      <td>å‚è§<a href="#çº¦æŸè¯´æ˜" target="_blank">çº¦æŸè¯´æ˜ã€‚</a></td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>transposed</td>
      <td>è¾“å…¥</td>
      <td>è½¬ç½®å·ç§¯ä½¿èƒ½æ ‡å¿—ä½, å½“å…¶å€¼ä¸ºTrueæ—¶ä½¿èƒ½è½¬ç½®å·ç§¯ã€‚</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>outputPadding</td>
      <td>è¾“å…¥</td>
      <td>åå‘ä¼ æ’­è¿‡ç¨‹ä¸­å¯¹äºè¾“å‡ºå¡«å……ã€‚</td>
      <td>
       <ul><li>æ•°ç»„é•¿åº¦å¯ä»¥ä¸ºweightç»´åº¦å‡2ï¼Œå„ç»´åº¦çš„æ•°å€¼èŒƒå›´æ»¡è¶³[0,strideå¯¹åº”ç»´åº¦æ•°å€¼)ã€‚</li>
       <li>transposedä¸ºFalseåœºæ™¯ä¸‹ï¼Œè¦æ±‚æ¯ä¸ªå…ƒç´ å€¼ä¸º0ã€‚</li>
      </td>
      <td>INT64</td>
      <td>-</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>groups</td>
      <td>è¾“å…¥</td>
      <td>åå‘ä¼ æ’­è¿‡ç¨‹ä¸­è¾“å…¥é€šé“çš„åˆ†ç»„æ•°ã€‚</td>
      <td>
       éœ€æ»¡è¶³groups*weightçš„Cç»´åº¦=inputçš„Cç»´åº¦ï¼Œgroupså–å€¼èŒƒå›´ä¸º[1,65535]ã€‚
      </td>
      <td>INT32</td>
      <td>-</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>outputMask</td>
      <td>è¾“å…¥</td>
      <td>
       <ul><li>è¾“å‡ºæ©ç å‚æ•°, æŒ‡å®šè¾“å‡ºä¸­æ˜¯å¦åŒ…å«è¾“å…¥ã€æƒé‡ã€åå·®çš„æ¢¯åº¦ã€‚</li>
       <li>åå‘ä¼ æ’­è¿‡ç¨‹è¾“å‡ºæ©ç å‚æ•°ä¸ºTrueå¯¹åº”ä½ç½®çš„æ¢¯åº¦ã€‚</li>
      </td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>cubeMathType</td>
      <td>è¾“å…¥</td>
      <td>ç”¨äºåˆ¤æ–­Cubeå•å…ƒåº”è¯¥ä½¿ç”¨å“ªç§è®¡ç®—é€»è¾‘è¿›è¡Œè¿ç®—ã€‚</td>
      <td>
       <ul><li>å¦‚æœè¾“å…¥çš„æ•°æ®ç±»å‹å­˜åœ¨<a href="../../../docs/zh/context/äº’æ¨å¯¼å…³ç³».md" target="_blank">äº’æ¨å¯¼å…³ç³»</a>ï¼Œè¯¥å‚æ•°é»˜è®¤å¯¹äº’æ¨å¯¼åçš„æ•°æ®ç±»å‹è¿›è¡Œå¤„ç†ã€‚</li>
       <li>æ”¯æŒçš„æšä¸¾å€¼å¦‚ä¸‹ï¼š</li>
       <ul><li>0ï¼šKEEP_DTYPEï¼Œä¿æŒè¾“å…¥çš„æ•°æ®ç±»å‹è¿›è¡Œè®¡ç®—ã€‚</li>
       <li>1ï¼šALLOW_FP32_DOWN_PRECISIONï¼Œå…è®¸å°†è¾“å…¥æ•°æ®é™ç²¾åº¦è®¡ç®—ã€‚</li>
       <li>2ï¼šUSE_FP16ï¼Œå…è®¸è½¬æ¢ä¸ºæ•°æ®ç±»å‹FLOAT16è¿›è¡Œè®¡ç®—ã€‚å½“è¾“å…¥æ•°æ®ç±»å‹æ˜¯FLOATï¼Œè½¬æ¢ä¸ºFLOAT16è®¡ç®—ã€‚</li>
       <li>3ï¼šUSE_HF32ï¼Œå…è®¸è½¬æ¢ä¸ºæ•°æ®ç±»å‹HFLOAT32è®¡ç®—ã€‚å½“è¾“å…¥æ˜¯FLOAT16ï¼Œä»ä½¿ç”¨FLOAT16è®¡ç®—ã€‚</li>
      </td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>gradInput</td>
      <td>è¾“å‡º</td>
      <td>è¾“å…¥å¼ é‡xå¯¹Lçš„æ¢¯åº¦ã€‚</td>
      <td>
       <ul><li>æ”¯æŒç©ºTensorã€‚</li>
       <li>æ•°æ®ç±»å‹ä¸inputä¿æŒä¸€è‡´ã€‚</li>
       <li>æ•°æ®æ ¼å¼éœ€è¦ä¸inputã€gradOutputä¸€è‡´ã€‚</li>
      </td>
      <td>FLOATã€FLOAT16ã€BFLOAT16</td>
      <td>NCLã€NCHWã€NCDHW</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>gradWeight</td>
      <td>è¾“å‡º</td>
      <td>å·ç§¯æ ¸æƒé‡å¼ é‡wå¯¹Lçš„æ¢¯åº¦ã€‚</td>
      <td>
       <ul><li>æ”¯æŒç©ºTensorã€‚</li>
       <li>æ•°æ®æ ¼å¼éœ€è¦ä¸weightä¸€è‡´ã€‚</li>
      </td>
      <td>FLOATã€FLOAT16ã€BFLOAT16ã€</td>
      <td>NCLã€NCHWã€NCDHW</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>gradBias</td>
      <td>è¾“å‡º</td>
      <td>åç½®bå¯¹Lçš„æ¢¯åº¦ã€‚</td>
      <td>
       <ul><li>æ”¯æŒç©ºTensorã€‚</li>
       <li>æ•°æ®ç±»å‹ä¸gradOutputä¸€è‡´ã€‚</li>
      </td>
      <td>FLOATã€FLOAT16ã€BFLOAT16</td>
      <td>ND</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>workspaceSize</td>
      <td>è¾“å‡º</td>
      <td>è¿”å›éœ€è¦åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ã€‚</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
    <tr>
      <td>executor</td>
      <td>è¾“å‡º</td>
      <td>è¿”å›opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>Ã—</td>
    </tr>
   </tbody>
  </table>  

- **è¿”å›å€¼ï¼š**

  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚  

  ç¬¬ä¸€æ®µæ¥å£å®Œæˆå…¥å‚æ ¡éªŒï¼Œå‡ºç°ä»¥ä¸‹åœºæ™¯æ—¶æŠ¥é”™ï¼š

  <table style="undefined;table-layout: fixed; width: 1430px"><colgroup>
    <col style="width:250px">
    <col style="width:130px">
    <col style="width:1050px">
    </colgroup>
   <thead>
    <tr>
     <th>è¿”å›å€¼</th>
     <th>é”™è¯¯ç </th>
     <th>æè¿°</th>
   </tr>
   </thead>
   <tbody>

   <tr>
     <td rowspan="2">ACLNN_ERR_PARAM_NULLPTR</td>
     <td rowspan="2">161001</td>
     <td>ä¼ å…¥çš„gradOutputã€inputã€weightã€biasSizesã€strideã€paddingã€dilationã€outputPaddingã€outputMaskã€gradInputã€gradWeightæ˜¯ç©ºæŒ‡é’ˆã€‚</td>
   </tr>
   <tr>
     <td>è¾“å‡ºä¸­åŒ…å«åå·®çš„æ¢¯åº¦æ—¶ï¼Œä¼ å…¥çš„gradBiasæ˜¯ç©ºæŒ‡é’ˆã€‚</td>
   </tr>
   <tr>
     <td rowspan="7">ACLNN_ERR_PARAM_INVALID</td>
     <td rowspan="7">161002</td>
   </tr>
   <tr>
     <td>gradOutputã€inputã€weightçš„æ•°æ®ç±»å‹ä¸åœ¨æ”¯æŒçš„èŒƒå›´ä¹‹å†…ã€‚</td>
   </tr>
   <tr>
     <td>gradOutputã€inputã€weightçš„æ•°æ®æ ¼å¼ä¸åœ¨æ”¯æŒçš„èŒƒå›´ä¹‹å†…ã€‚</td>
   </tr>
   <tr>
     <td>gradOutputã€inputã€weightçš„shapeä¸ç¬¦åˆçº¦æŸã€‚</td>
   </tr>
   <tr>
     <td>biasSizesã€strideã€paddingã€dilationã€outputPaddingçš„shapeä¸ç¬¦åˆçº¦æŸã€‚</td>
   </tr>
   <tr>
     <td>ä¸ç¬¦åˆgroups*weightçš„Cç»´åº¦=inputçš„Cç»´åº¦ã€‚</td>
   </tr>
   <tr>
     <td>å½“å‰å¤„ç†å™¨ä¸æ”¯æŒå·ç§¯åå‘ä¼ æ’­ã€‚</td>
   </tr>
   <tr>
     <td>ACLNN_ERR_INNER_NULLPTR</td>
     <td>561103</td>
     <td>APIå†…éƒ¨æ ¡éªŒé”™è¯¯ï¼Œé€šå¸¸ç”±äºè¾“å…¥æ•°æ®æˆ–å±æ€§çš„è§„æ ¼ä¸åœ¨æ”¯æŒçš„èŒƒå›´ä¹‹å†…å¯¼è‡´ã€‚</td>
   </tr>
   </tbody>

   </table>


## aclnnConvolutionBackward

- **å‚æ•°è¯´æ˜ï¼š**

  <table style="undefined;table-layout: fixed; width: 1400px"><colgroup>
       <col style="width:100px">
       <col style="width:100px">
       <col style="width:950px">
       </colgroup>
    <thead>
       <tr><th>å‚æ•°å</th><th>è¾“å…¥/è¾“å‡º</th><th>æè¿°</th></tr>
    </thead>
    <tbody>
       <tr>
       <td>workspace</td>
       <td>è¾“å…¥</td>
       <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå†…å­˜åœ°å€ã€‚</td>
       </tr>
       <tr>
       <td>workspaceSize</td>
       <td>è¾“å…¥</td>
       <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ï¼Œç”±ç¬¬ä¸€æ®µæ¥å£aclnnConvolutionBackwardGetWorkspaceSizeè·å–ã€‚</td>
       </tr>
       <tr>
       <td>executor</td>
       <td>è¾“å…¥</td>
       <td>opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
       </tr>       
       <tr>
       <td>stream</td>
       <td>è¾“å…¥</td>
       <td>æŒ‡å®šæ‰§è¡Œä»»åŠ¡çš„Streamã€‚</td>
       </tr> 
    </tbody>
  </table>


- **è¿”å›å€¼ï¼š**

    aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

## çº¦æŸè¯´æ˜
  
- ç¡®å®šæ€§è®¡ç®—
  - aclnnConvolutionBackwardé»˜è®¤éç¡®å®šæ€§å®ç°ï¼Œæ”¯æŒé€šè¿‡aclrtCtxSetSysParamOptå¼€å¯ç¡®å®šæ€§ã€‚

  <table style="undefined;table-layout: fixed; width: 1396px"><colgroup>
  <col style="width: 168px">
  <col style="width: 404px">
  <col style="width: 429px">
  <col style="width: 395px">
  </colgroup>
   <thead>
    <tr>
     <th><term>çº¦æŸç±»å‹</term></th>
     <th><term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term></th>
     <th><term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ã€<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term></th>
     <th><term>Atlas æ¨ç†ç³»åˆ—äº§å“</term>ã€<term>Atlas è®­ç»ƒç³»åˆ—äº§å“</term></th>
   </tr>
   </thead>
   <tbody>

   <tr>
     <th scope="row">ç©ºTensorçº¦æŸ</th>
     <td colspan="2">
        <ul><li>inputçš„ç»´åº¦å¿…é¡»æ˜¯2ç»´ä»¥ä¸Šã€‚strideã€paddingã€dilationã€outputPaddingçš„ç»´åº¦å¿…é¡»ç­‰äºinputç»´åº¦-2ï¼Œå…¶ä¸­paddingåœ¨2Dçš„æ—¶å€™å¯ä»¥æ˜¯4ç»´ã€‚</li>
        <li>transposed=falseæ—¶ï¼ŒDã€Hã€Wç»´åº¦çº¦æŸæ»¡è¶³å…¬å¼ä¸€ï¼ˆè§è¡¨æ ¼ä¸‹æ–¹è¯´æ˜ï¼‰ã€‚</li>
        <li>transposed=trueæ—¶ï¼š</li>
          <ul><li>weightçš„Nè½´å¿…é¡»å¤§äº0ã€‚</li>
          <li>weightçš„Nè½´å¿…é¡»å’Œinputçš„Cè½´ç›¸ç­‰ã€‚</li></ul>
        </ul>
     </td>
     <td>-</td>
   </tr>
   <tr>
     <th scope="row">gradOutputçº¦æŸ</th>
     <td>-</td>
     <td>
        <ul>1dã€2då’Œ3d transposed=falseåœºæ™¯ï¼Œå„ä¸ªç»´åº¦çš„å¤§å°åº”è¯¥å¤§äºç­‰äº1, å½“inputä¸ºç©ºTensoræ—¶ï¼Œæ”¯æŒNã€Cã€Dã€Hã€Wç»´åº¦ä¸º0ã€‚</ul>
     </td>
     <td>
        <ul>ä¸æ”¯æŒç©ºTensorã€‚</ul>
     </td>
   </tr>
   <tr>
     <th scope="row">inputçº¦æŸ</th>
     <td>
        <ul><li>transposed=trueï¼šæ”¯æŒNç»´åº¦ä¸º0çš„ç©ºTensorã€‚å½“Nç»´åº¦ä¸º0ä¸”æ»¡è¶³ç©ºTensorçº¦æŸæ—¶ï¼Œè¿˜æ”¯æŒDHWç»´åº¦ä¸º0ã€‚</li>
        <li>transposed=falseï¼šæ”¯æŒNã€Cç»´åº¦ä¸º0çš„ç©ºTensorï¼ˆCç»´åº¦ä¸º0æ—¶è¦æ±‚weightçš„Cç»´åº¦ä¹Ÿä¸º0ï¼‰ã€‚å½“Næˆ–Cç»´åº¦ä¸º0ä¸”æ»¡è¶³ç©ºTensorçº¦æŸæ—¶ï¼Œè¿˜æ”¯æŒDHWç»´åº¦ä¸º0ã€‚</li></ul>
     </td>
     <td>
        <ul>1dã€2då’Œ3d transposed=falseåœºæ™¯ï¼Œå„ä¸ªç»´åº¦çš„å¤§å°åº”è¯¥å¤§äºç­‰äº1ã€‚
          <ul><li>transposed=trueï¼šæ”¯æŒNç»´åº¦ä¸º0çš„ç©ºTensorã€‚å½“Nç»´åº¦ä¸º0ä¸”æ»¡è¶³ç©ºTensorçº¦æŸæ—¶ï¼Œè¿˜æ”¯æŒDHWç»´åº¦ä¸º0ã€‚</li>
          <li>transposed=falseï¼šæ”¯æŒNã€Cç»´åº¦ä¸º0çš„ç©ºTensorï¼ˆCç»´åº¦ä¸º0æ—¶è¦æ±‚weightçš„Cç»´åº¦ä¹Ÿä¸º0ï¼‰ã€‚å½“Næˆ–Cç»´åº¦ä¸º0ä¸”æ»¡è¶³ç©ºTensorçº¦æŸæ—¶ï¼Œè¿˜æ”¯æŒDHWç»´åº¦ä¸º0ã€‚</li></ul>
         </ul>
     </td>
     <td>-</td>
   </tr>
   <tr>
     <th scope="row">weightçº¦æŸ</th>
     <td>
        <ul><li>transposed=trueï¼šHã€Wçš„å¤§å°åº”è¯¥åœ¨[1,255]çš„èŒƒå›´å†…ï¼Œå…¶ä»–ç»´åº¦çš„å¤§å°åº”è¯¥å¤§äºç­‰äº1ã€‚å½“inputä¸ºç©ºTensorä¸”æ»¡è¶³ç©ºTensorçº¦æŸæ—¶ï¼Œæ­¤æ—¶æ”¯æŒCã€Dã€Hã€Wè½´ä¸º0ã€‚</li>
        <li>transposed=falseï¼šæ”¯æŒCç»´åº¦ç­‰äº0ï¼ˆCä¸º0æ—¶è¦æ±‚input Cç»´åº¦ä¹Ÿä¸º0ï¼‰ï¼Œæ‰€æœ‰ç»´åº¦çš„å¤§å°åº”è¯¥å¤§äºç­‰äº1ã€‚å½“inputä¸ºç©ºTensorä¸”æ»¡è¶³ç©ºTensorçº¦æŸæ—¶ï¼Œæ­¤æ—¶æ”¯æŒDã€Hã€Wè½´ä¸º0ã€‚</li></ul>
     </td>
     <td>
        <ul>2då’Œ3d transposed=falseåœºæ™¯ï¼ŒHã€Wçš„å¤§å°åº”è¯¥åœ¨[1,255]çš„èŒƒå›´å†…ï¼Œå…¶ä»–ç»´åº¦çš„å¤§å°åº”è¯¥å¤§äºç­‰äº1ã€‚1d transposed=falseåœºæ™¯ï¼ŒLçš„å¤§å°åº”è¯¥åœ¨[1,255]çš„èŒƒå›´å†…ï¼Œå…¶ä»–ç»´åº¦çš„å¤§å°åº”è¯¥å¤§äºç­‰äº1ã€‚
           <ul><li>transposed=true: å½“inputä¸ºç©ºTensorä¸”æ»¡è¶³ç©ºTensorçº¦æŸæ—¶ï¼Œæ­¤æ—¶æ”¯æŒCã€Dã€Hã€Wè½´ä¸º0ã€‚</li>
           <li>transposed=falseï¼šæ”¯æŒCç»´åº¦ç­‰äº0ï¼ˆCä¸º0æ—¶è¦æ±‚input Cç»´åº¦ä¹Ÿä¸º0ï¼‰ï¼Œå½“inputä¸ºç©ºTensorä¸”æ»¡è¶³ç©ºTensorçº¦æŸæ—¶ï¼Œæ­¤æ—¶æ”¯æŒDã€Hã€Wè½´ä¸º0ã€‚</li></ul>
        </ul>
     </td>
     <td>
        <ul>ä¸æ”¯æŒç©ºTensorã€‚</ul>
     </td>
   </tr>
   <tr>
     <th scope="row">strideçº¦æŸ</th>
     <td>
        <ul>1dã€2då’Œ3d transposed=falseåœºæ™¯ï¼Œå„ä¸ªå€¼éƒ½åº”è¯¥å¤§äºç­‰äº1ã€‚1dã€2då’Œ3d transposed=trueåœºæ™¯ï¼ŒstrideDåº”è¯¥åœ¨[1,1000000]çš„èŒƒå›´å†…ï¼ŒstrideHã€strideWåº”è¯¥åœ¨[1,63]çš„èŒƒå›´å†…ã€‚</ul>
     </td>
     <td>
        <ul>3d transposed=falseåœºæ™¯ï¼ŒstrideDåº”è¯¥å¤§äºç­‰äº1ï¼ŒstrideHã€strideWåº”è¯¥åœ¨[1,63]çš„èŒƒå›´å†…ã€‚1då’Œ2d transposed=falseåœºæ™¯ï¼Œå„ä¸ªå€¼éƒ½åº”è¯¥å¤§äºç­‰äº1ã€‚</ul>
     </td>
     <td>-</td>
   </tr>
   <tr>
     <th scope="row">paddingçº¦æŸ</th>
     <td>
        <ul>1dã€2då’Œ3d transposed=falseåœºæ™¯ï¼Œå„ä¸ªå€¼éƒ½åº”è¯¥å¤§äºç­‰äº0ã€‚1dã€2då’Œ3d transposed=trueåœºæ™¯ï¼ŒpaddingDåº”è¯¥åœ¨[0,1000000]çš„èŒƒå›´å†…ï¼ŒpaddingHã€paddingWåº”è¯¥åœ¨[0,255]çš„èŒƒå›´å†…ã€‚</ul>
     </td>
     <td>
        <ul>3d transposed=falseåœºæ™¯ï¼ŒpaddingDåº”è¯¥å¤§äºç­‰äº0ï¼ŒpaddingHã€paddingWåº”è¯¥åœ¨[0,255]çš„èŒƒå›´å†…ã€‚1då’Œ2d transposed=falseåœºæ™¯ï¼Œå„ä¸ªå€¼éƒ½åº”è¯¥åœ¨[0,255]çš„èŒƒå›´å†…ã€‚</ul>
     </td>
     <td>-</td>
   </tr>
   <tr>
     <th scope="row">dilationçº¦æŸ</th>
     <td>
        <ul>1dã€2då’Œ3d transposed=falseåœºæ™¯ï¼Œå„ä¸ªå€¼éƒ½åº”è¯¥å¤§äºç­‰äº1ã€‚1dã€2då’Œ3d transposed=trueåœºæ™¯ï¼ŒdilationDåº”è¯¥åœ¨[1,1000000]çš„èŒƒå›´å†…ï¼ŒdilationHã€dilationWåº”è¯¥åœ¨[1,255]çš„èŒƒå›´å†…ã€‚</ul>
     </td>
     <td>
        <ul>1dã€2då’Œ3d transposed=falseåœºæ™¯ï¼Œå„ä¸ªå€¼éƒ½åº”è¯¥åœ¨[1,255]çš„èŒƒå›´å†…ã€‚</ul>
     </td>
     <td>-</td>
   </tr>
   <tr>
     <th scope="row">dtypeçº¦æŸ</th>
     <td>
        <ul>åªæœ‰åœ¨transposed=trueä¸”output_mask[0]=trueæ—¶ï¼Œæ•°æ®ç±»å‹æ‰æ”¯æŒHIFLOAT8ã€FLOAT8_E4M3FNã€‚
        </ul>
     </td>
     <td>
        <ul>ä¸æ”¯æŒHIFLOAT8ã€FLOAT8_E4M3FNã€‚</ul>
     </td>
     <td>
        <ul>ä¸æ”¯æŒBFLOAT16ã€HIFLOAT8ã€FLOAT8_E4M3FNã€‚</ul>
     </td>
   </tr>
   <tr>
     <th scope="row">cubeMathTypeè¯´æ˜</th>
     <td colspan="2">
        <ul><li>æšä¸¾å€¼ä¸º0ï¼šæš‚æ— è¯´æ˜ã€‚</li>
        <li>æšä¸¾å€¼ä¸º1ï¼šå½“è¾“å…¥æ˜¯FLOATï¼Œè½¬æ¢ä¸ºHFLOAT32è®¡ç®—ã€‚å½“è¾“å…¥ä¸ºå…¶ä»–æ•°æ®ç±»å‹æ—¶ä¸åšå¤„ç†ã€‚</li>
        <li>æšä¸¾å€¼ä¸º2ï¼šå½“è¾“å…¥æ˜¯BFLOAT16æ—¶ä¸æ”¯æŒè¯¥é€‰é¡¹ã€‚å½“è¾“å…¥ä¸ºå…¶ä»–æ•°æ®ç±»å‹æ—¶ä¸åšå¤„ç†ã€‚</li>
        <li>æšä¸¾å€¼ä¸º3ï¼šå½“è¾“å…¥æ˜¯FLOATï¼Œè½¬æ¢ä¸ºHFLOAT32è®¡ç®—ã€‚å½“è¾“å…¥ä¸ºå…¶ä»–æ•°æ®ç±»å‹æ—¶ä¸åšå¤„ç†ã€‚</li>
        </ul>
     </td>
     <td>
        <ul><li>æšä¸¾å€¼ä¸º0ï¼šå½“è¾“å…¥æ˜¯FLOATï¼ŒCubeè®¡ç®—å•å…ƒæš‚ä¸æ”¯æŒï¼Œå–0æ—¶ä¼šæŠ¥é”™ã€‚</li>
        <li>æšä¸¾å€¼ä¸º1ï¼šå½“è¾“å…¥æ˜¯FLOATï¼Œè½¬æ¢ä¸ºFLOAT16è®¡ç®—ã€‚å½“è¾“å…¥ä¸ºå…¶ä»–æ•°æ®ç±»å‹æ—¶ä¸åšå¤„ç†ã€‚</li>
        <li>æšä¸¾å€¼ä¸º2ï¼šæš‚æ— è¯´æ˜ã€‚</li>
        <li>æšä¸¾å€¼ä¸º3ï¼šå½“è¾“å…¥æ˜¯FLOATï¼ŒCubeè®¡ç®—å•å…ƒæš‚ä¸æ”¯æŒã€‚</li>
        </ul>
     </td>
   </tr>
   <tr>
     <th scope="row">å…¶ä»–çº¦æŸ</th>
     <td>-</td>
     <td>-</td>
     <td>
        <ul>å½“å‰ä»…æ”¯æŒ1Då’Œ2Då·ç§¯çš„åå‘ä¼ æ’­ï¼Œæš‚ä¸æ”¯æŒ3Då·ç§¯çš„åå‘ä¼ æ’­ã€‚</ul>
     </td>
   </tr>
   </tbody>
  </table>
    
  - å…¬å¼ä¸€ï¼š
    $$
        (input_{dim} + pad_{dim} \times 2) \ge ((weight_{dim}  - 1) \times dilation_{dim} + 1)
    $$

ç”±äºç¡¬ä»¶èµ„æºé™åˆ¶ï¼Œç®—å­åœ¨éƒ¨åˆ†å‚æ•°å–å€¼ç»„åˆåœºæ™¯ä¸‹ä¼šæ‰§è¡Œå¤±è´¥ï¼Œè¯·æ ¹æ®æ—¥å¿—ä¿¡æ¯æç¤ºåˆ†æå¹¶æ’æŸ¥é—®é¢˜ã€‚è‹¥æ— æ³•è§£å†³ï¼Œè¯·å•å‡»[Link](https://www.hiascend.com/support)è·å–æŠ€æœ¯æ”¯æŒã€‚


## è°ƒç”¨ç¤ºä¾‹

ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼Œä»…ä¾›å‚è€ƒï¼Œå…·ä½“ç¼–è¯‘å’Œæ‰§è¡Œè¿‡ç¨‹è¯·å‚è€ƒ[ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹](../../../docs/zh/context/ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹.md)ã€‚

```Cpp
#include <iostream>
#include <memory>
#include <vector>

#include "acl/acl.h"
#include "aclnnop/aclnn_convolution_backward.h"

#define CHECK_RET(cond, return_expr) \
    do {                             \
        if (!(cond)) {               \
            return_expr;             \
        }                            \
    } while (0)

#define CHECK_FREE_RET(cond, return_expr)        \
    do {                                         \
        if (!(cond)) {                           \
            Finalize(deviceId, stream); \
            return_expr;                         \
        }                                        \
    } while (0)

#define LOG_PRINT(message, ...)         \
    do {                                \
        printf(message, ##__VA_ARGS__); \
    } while (0)

int64_t GetShapeSize(const std::vector<int64_t> &shape)
{
    int64_t shapeSize = 1;
    for (auto i : shape) {
        shapeSize *= i;
    }
    return shapeSize;
}

int Init(int32_t deviceId, aclrtStream *stream)
{
    // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
    auto ret = aclInit(nullptr);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
    ret = aclrtSetDevice(deviceId);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
    ret = aclrtCreateStream(stream);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
    return 0;
}

template <typename T>
int CreateAclTensor(const std::vector<T> &hostData, const std::vector<int64_t> &shape, void **DeviceAddr,
                    aclDataType dataType, aclTensor **tensor)
{
    auto size = GetShapeSize(shape) * sizeof(T);
    // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
    auto ret = aclrtMalloc(DeviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);
    // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®æ‹·è´åˆ°deviceä¾§å†…å­˜ä¸Š
    ret = aclrtMemcpy(*DeviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);

    // è®¡ç®—è¿ç»­tensorçš„strides
    std::vector<int64_t> strides(shape.size(), 1);
    for (int64_t i = shape.size() - 2; i >= 0; i--) {
        strides[i] = shape[i + 1] * strides[i + 1];
    }

    // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
    if (shape.size() == 4) {
        *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_NCHW,
                                  shape.data(), shape.size(), *DeviceAddr);
    } else {
        *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_ND,
                                  shape.data(), shape.size(), *DeviceAddr);
    }

    return 0;
}

void Finalize(int32_t deviceId, aclrtStream stream)
{
    aclrtDestroyStream(stream);
    aclrtResetDevice(deviceId);
    aclFinalize();
}

int aclnnConvolutionBackwardTest(int32_t deviceId, aclrtStream &stream)
{
    // 1. åˆå§‹åŒ–
    auto ret = Init(deviceId, &stream);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);
    // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
    std::vector<int64_t> gradOutputShape = {2, 2, 7, 7};
    std::vector<int64_t> inputShape = {2, 2, 7, 7};
    std::vector<int64_t> weightShape = {2, 2, 1, 1};
    std::vector<int64_t> biasSize = {2};
    std::vector<int64_t> stride = {1, 1};
    std::vector<int64_t> padding = {0, 0};
    std::vector<int64_t> dilation = {1, 1};
    bool transposed = false;
    std::vector<int64_t> outputPadding = {0, 0};
    int groups = 1;
    bool outputMask[3] = {true, true, true};
    int8_t cubeMathType = 1;

    std::vector<int64_t> gradInputShape = {2, 2, 7, 7};
    std::vector<int64_t> gradWeightShape = {2, 2, 1, 1};
    std::vector<int64_t> gradBiasShape = {2};

    // åˆ›å»ºgradOutput aclTensor
    std::vector<float> gradOutputData(GetShapeSize(gradOutputShape), 1);
    aclTensor *gradOutput = nullptr;
    void *gradOutputDeviceAddr = nullptr;
    ret = CreateAclTensor(gradOutputData, gradOutputShape, &gradOutputDeviceAddr, aclDataType::ACL_FLOAT, &gradOutput);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> gradOutputTensorPtr(gradOutput, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> gradOutputDeviceAddrPtr(gradOutputDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºinput aclTensor
    std::vector<float> inputData(GetShapeSize(inputShape), 1);
    aclTensor *input = nullptr;
    void *inputDeviceAddr = nullptr;
    ret = CreateAclTensor(inputData, inputShape, &inputDeviceAddr, aclDataType::ACL_FLOAT, &input);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> inputTensorPtr(input, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> inputDeviceAddrPtr(inputDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºweight aclTensor
    std::vector<float> weightData(GetShapeSize(weightShape), 1);
    aclTensor *weight = nullptr;
    void *weightDeviceAddr = nullptr;
    ret = CreateAclTensor(weightData, weightShape, &weightDeviceAddr, aclDataType::ACL_FLOAT, &weight);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> weightTensorPtr(weight, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> weightDeviceAddrPtr(weightDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºgradInput aclTensor
    std::vector<float> gradInputData(GetShapeSize(inputShape), 1);
    aclTensor *gradInput = nullptr;
    void *gradInputDeviceAddr = nullptr;
    ret = CreateAclTensor(gradInputData, inputShape, &gradInputDeviceAddr, aclDataType::ACL_FLOAT, &gradInput);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> gradInputTensorPtr(gradInput, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> gradInputDeviceAddrPtr(gradInputDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºgradWeight aclTensor
    std::vector<float> gradWeightData(GetShapeSize(weightShape), 1);
    aclTensor *gradWeight = nullptr;
    void *gradWeightDeviceAddr = nullptr;
    ret = CreateAclTensor(gradWeightData, weightShape, &gradWeightDeviceAddr, aclDataType::ACL_FLOAT, &gradWeight);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> gradWeightTensorPtr(gradWeight, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> gradWeightDeviceAddrPtr(gradWeightDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºgradBias aclTensor
    std::vector<float> gradBiasData(GetShapeSize(biasSize), 1);
    aclTensor *gradBias = nullptr;
    void *gradBiasDeviceAddr = nullptr;
    ret = CreateAclTensor(gradBiasData, biasSize, &gradBiasDeviceAddr, aclDataType::ACL_FLOAT, &gradBias);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> gradBiasTensorPtr(gradBias, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> gradBiasDeviceAddrPtr(gradBiasDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºbiasSizes aclIntArray
    aclIntArray *biasSizes = aclCreateIntArray(biasSize.data(), 1);
    std::unique_ptr<aclIntArray, aclnnStatus (*)(const aclIntArray *)> biasSizesPtr(biasSizes, aclDestroyIntArray);
    CHECK_FREE_RET(biasSizes != nullptr, return ACL_ERROR_INTERNAL_ERROR);

    // åˆ›å»ºstrides aclIntArray
    aclIntArray *strides = aclCreateIntArray(stride.data(), 2);
    std::unique_ptr<aclIntArray, aclnnStatus (*)(const aclIntArray *)> stridesPtr(strides, aclDestroyIntArray);
    CHECK_FREE_RET(strides != nullptr, return ACL_ERROR_INTERNAL_ERROR);

    // åˆ›å»ºpads aclIntArray
    aclIntArray *pads = aclCreateIntArray(padding.data(), 2);
    std::unique_ptr<aclIntArray, aclnnStatus (*)(const aclIntArray *)> padsPtr(pads, aclDestroyIntArray);
    CHECK_FREE_RET(pads != nullptr, return ACL_ERROR_INTERNAL_ERROR);

    // åˆ›å»ºdilations aclIntArray
    aclIntArray *dilations = aclCreateIntArray(dilation.data(), 2);
    std::unique_ptr<aclIntArray, aclnnStatus (*)(const aclIntArray *)> dilationsPtr(dilations, aclDestroyIntArray);
    CHECK_FREE_RET(dilations != nullptr, return ACL_ERROR_INTERNAL_ERROR);

    // åˆ›å»ºoutputPads aclIntArray
    aclIntArray *outputPads = aclCreateIntArray(outputPadding.data(), 2);
    std::unique_ptr<aclIntArray, aclnnStatus (*)(const aclIntArray *)> outputPadsPtr(outputPads, aclDestroyIntArray);
    CHECK_FREE_RET(outputPads != nullptr, return ACL_ERROR_INTERNAL_ERROR);

    // åˆ›å»ºoutMask aclBoolArray
    aclBoolArray *outMask = aclCreateBoolArray(outputMask, 3);
    std::unique_ptr<aclBoolArray, aclnnStatus (*)(const aclBoolArray *)> outMaskPtr(outMask, aclDestroyBoolArray);
    CHECK_FREE_RET(outMask != nullptr, return ACL_ERROR_INTERNAL_ERROR);

    // 3. è°ƒç”¨CANNç®—å­åº“APIï¼Œéœ€è¦ä¿®æ”¹ä¸ºå…·ä½“çš„Apiåç§°
    uint64_t workspaceSize = 0;
    aclOpExecutor *executor;
    // è°ƒç”¨aclnnConvolutionBackwardGetWorkspaceSizeç¬¬ä¸€æ®µæ¥å£
    ret = aclnnConvolutionBackwardGetWorkspaceSize(gradOutput, input, weight, biasSizes, strides, pads, dilations,
                                                   transposed, outputPads, groups, outMask, cubeMathType, gradInput,
                                                   gradWeight, gradBias, &workspaceSize, &executor);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnConvolutionBackwardGetWorkspaceSize failed. ERROR: %d\n", ret);
                   return ret);
    // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
    void *workspaceAddr = nullptr;
    std::unique_ptr<void, aclError (*)(void *)> workspaceAddrPtr(nullptr, aclrtFree);
    if (workspaceSize > 0) {
        ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
        CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret);
        workspaceAddrPtr.reset(workspaceAddr);
    }
    // è°ƒç”¨aclnnConvolutionBackwardç¬¬äºŒæ®µæ¥å£
    ret = aclnnConvolutionBackward(workspaceAddr, workspaceSize, executor, stream);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnConvolutionBackward failed. ERROR: %d\n", ret); return ret);
    // 4. ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
    ret = aclrtSynchronizeStream(stream);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);
    // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
    auto size = GetShapeSize(gradInputShape);
    std::vector<float> gradInputResult(size, 0);
    ret = aclrtMemcpy(gradInputResult.data(), gradInputResult.size() * sizeof(gradInputResult[0]), gradInputDeviceAddr,
                      size * sizeof(gradInputResult[0]), ACL_MEMCPY_DEVICE_TO_HOST);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret);
                   return ret);
    for (int64_t i = 0; i < size; i++) {
        LOG_PRINT("gradInputResult[%ld] is: %f\n", i, gradInputResult[i]);
    }

    size = GetShapeSize(gradWeightShape);
    std::vector<float> gradWeightResult(size, 0);
    ret = aclrtMemcpy(gradWeightResult.data(), gradWeightResult.size() * sizeof(gradWeightResult[0]), gradWeightDeviceAddr,
                      size * sizeof(gradWeightResult[0]), ACL_MEMCPY_DEVICE_TO_HOST);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret);
                   return ret);
    for (int64_t i = 0; i < size; i++) {
        LOG_PRINT("gradWeightResult[%ld] is: %f\n", i, gradWeightResult[i]);
    }

    size = GetShapeSize(gradBiasShape);
    std::vector<float> gradBiasResult(size, 0);
    ret = aclrtMemcpy(gradBiasResult.data(), gradBiasResult.size() * sizeof(gradBiasResult[0]), gradBiasDeviceAddr,
                      size * sizeof(gradBiasResult[0]), ACL_MEMCPY_DEVICE_TO_HOST);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret);
                   return ret);
    for (int64_t i = 0; i < size; i++) {
        LOG_PRINT("gradBiasResult[%ld] is: %f\n", i, gradBiasResult[i]);
    }
    return ACL_SUCCESS;
}

int main()
{
    // 1. ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–
    // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
    int32_t deviceId = 0;
    aclrtStream stream;
    auto ret = aclnnConvolutionBackwardTest(deviceId, stream);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnConvolutionBackwardTest failed. ERROR: %d\n", ret); return ret);

    Finalize(deviceId, stream);
    return 0;
}
```
