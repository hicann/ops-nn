# aclnnConvTbcBackward

[ğŸ“„ æŸ¥çœ‹æºç ](https://gitcode.com/cann/ops-nn/tree/master/conv/convolution_backward)

## äº§å“æ”¯æŒæƒ…å†µ

| äº§å“                                                                | æ˜¯å¦æ”¯æŒ |
|:------------------------------------------------------------------|:----:|
| <term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term>                                       |  âˆš   |
| <term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>                      |  âˆš   |
| <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term> |  âˆš   |
| <term>Atlas 200I/500 A2 æ¨ç†äº§å“</term>                               |  Ã—   |
| <term>Atlas æ¨ç†ç³»åˆ—äº§å“ </term>                                        |  Ã—   |
| <term>Atlas è®­ç»ƒç³»åˆ—äº§å“</term>                                         |  âˆš   |
| <term>Atlas 200/300/500 æ¨ç†äº§å“</term>                               |  Ã—   |

## åŠŸèƒ½è¯´æ˜

- æ¥å£åŠŸèƒ½ï¼šå®ç°è¾“å…¥è¾“å‡ºç»´åº¦ä¸º**T**ï¼ˆæ—¶é—´æˆ–ç©ºé—´ç»´åº¦ï¼‰ã€**B**ï¼ˆæ‰¹æ¬¡ï¼‰ã€**C**ï¼ˆé€šé“ï¼‰çš„ä¸€ç»´å·ç§¯çš„åå‘ä¼ æ’­ã€‚

- è®¡ç®—å…¬å¼ï¼š å‡å®šè¾“å…¥Conv_tbcæ­£å‘çš„è¾“å…¥$input$çš„shapeæ˜¯$(H_{\text{in}},N,C_{\text{in}})$ï¼Œè¾“å‡ºæ¢¯åº¦$gradOutput$
  çš„shapeæ˜¯$(H_{\text{out}},N,C_{\text{out}})$ï¼Œå·ç§¯æ ¸$weight$çš„shapeæ˜¯$(K,C_{\text{in}},C_{\text{out}})$ï¼Œåç½®$bias$
  çš„shapeä¸º$(C_{\text{out}})$ï¼Œåå‘ä¼ æ’­è¿‡ç¨‹ä¸­å¯¹äºè¾“å…¥çš„å¡«å……ä¸º $pad$ï¼Œä¸Šè¿°å‚æ•°çš„å…³ç³»æ˜¯ï¼š

  $$
  H_{out} = {H_{in} + 2 \cdot pad - K} + 1
  $$

  å·ç§¯åå‘ä¼ æ’­éœ€è¦è®¡ç®—å¯¹å·ç§¯æ­£å‘çš„è¾“å…¥å¼ é‡ $x$ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„inputï¼‰ã€å·ç§¯æ ¸æƒé‡å¼ é‡ $w$
  ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„weightï¼‰å’Œåç½® $b$ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„biasï¼‰çš„æ¢¯åº¦ã€‚

    - å¯¹äº $x$ çš„æ¢¯åº¦ $\frac{\partial L}{\partial x}$ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„gradInputå‚æ•°ï¼‰ï¼š

      $$
      \frac{\partial L}{\partial x_{t,b,c_{in}}} = \sum_{k=0}^{K-1} \sum_{c_{out}=0}^{C_{out}-1} \frac{\partial L}{\partial y_{t-k,b,c_{out}}} \cdot w_{k,c_{in},c_{out}}
      $$

      å…¶ä¸­ï¼Œ$N$ è¡¨ç¤ºæ‰¹æ¬¡å¤§å°ï¼ˆbatch sizeï¼‰ï¼Œ$C$ è¡¨ç¤ºé€šé“æ•°ï¼Œ$H$ è¡¨ç¤ºæ—¶é—´æˆ–ç©ºé—´ç»´åº¦ï¼Œ$L$
      è¡¨ç¤ºæŸå¤±å‡½æ•°ï¼Œ$\frac{\partial L}{\partial y}$ ä»£è¡¨è¾“å‡ºå¼ é‡ $y$ å¯¹ $L$ çš„æ¢¯åº¦ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„selfå‚æ•°ï¼‰ã€‚

    - å¯¹äº $w$ çš„æ¢¯åº¦ $\frac{\partial L}{\partial w}$ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„gradWeightå‚æ•°ï¼‰ï¼š

      $$
      \frac{\partial L}{\partial w_{k,c_{in},c_{out}}} = \sum_{b=0}^{N-1} \sum_{t=0}^{H_{out}-1} x_{t+k,b,c_{in}} \cdot \frac{\partial L}{\partial y_{t,b,c_{out}}}
      $$

    - å¯¹äº $b$ çš„æ¢¯åº¦ $\frac{\partial L}{\partial b}$ï¼ˆå¯¹åº”å‡½æ•°åŸå‹ä¸­çš„gradBiaså‚æ•°ï¼‰ï¼š

      $$
      \frac{\partial L}{\partial b_{c_{out}}} = \sum_{b=0}^{N-1}\sum_{t=0}^{H_{\text{out}}-1} \frac{\partial L}{\partial y_{t,b,c_{out}}}
      $$

## å‡½æ•°åŸå‹

æ¯ä¸ªç®—å­åˆ†ä¸º[ä¸¤æ®µå¼æ¥å£](../../../docs/zh/context/ä¸¤æ®µå¼æ¥å£.md)
ï¼Œå¿…é¡»å…ˆè°ƒç”¨â€œaclnnConvTbcBackwardGetWorkspaceSizeâ€æ¥å£è·å–è®¡ç®—æ‰€éœ€workspaceå¤§å°ä»¥åŠåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹çš„æ‰§è¡Œå™¨ï¼Œå†è°ƒç”¨â€œaclnnConvTbcBackwardâ€æ¥å£æ‰§è¡Œè®¡ç®—ã€‚

```cpp
aclnnStatus aclnnConvTbcBackwardGetWorkspaceSize(
    const aclTensor *self, 
    const aclTensor *input, 
    const aclTensor *weight, 
    const aclTensor *bias, 
    int64_t          pad, 
    int8_t           cubeMathType, 
    aclTensor       *gradInput, 
    aclTensor       *gradWeight, 
    aclTensor       *gradBias, 
    uint64_t        *workspaceSize, 
    aclOpExecutor  **executor)
```

```cpp
aclnnStatus aclnnConvTbcBackward(
    void                *workspace, 
    uint64_t             workspaceSize, 
    aclOpExecutor       *executor, 
    const aclrtStream    stream)
```

## aclnnConvTbcBackwardGetWorkspaceSize

- **å‚æ•°è¯´æ˜ï¼š**

  <table style="undefined;table-layout: fixed; width: 1567px"><colgroup>
    <col style="width:170px">
    <col style="width:120px">
    <col style="width:300px">
    <col style="width:330px">
    <col style="width:212px">
    <col style="width:100px">
    <col style="width:190px">
    <col style="width:145px">
    </colgroup>
    <thead>
    <tr>
     <th>å‚æ•°å</th>
     <th>è¾“å…¥/è¾“å‡º</th>
     <th>æè¿°</th>
     <th>ä½¿ç”¨è¯´æ˜</th>
     <th>æ•°æ®ç±»å‹</th>
     <th>æ•°æ®æ ¼å¼</th>
     <th>ç»´åº¦(shape)</th>
     <th>éè¿ç»­Tensor</th>
    </tr>
    </thead>
    <tbody>
    <tr>
     <td>self</td>
     <td>è¾“å…¥</td>
     <td>å…¬å¼ä¸­çš„è¾“å‡ºå¼ é‡yå¯¹Lçš„æ¢¯åº¦ï¼Œè¡¨ç¤ºå·ç§¯åå‘çš„è¾“å…¥ã€‚</td>
     <td>
       <ul><li>æ”¯æŒç©ºTensorã€‚</li><li>shapeä¸º(N,C<sub>out</sub>,H<sub>out</sub>)ã€‚</li><li>æ•°æ®ç±»å‹ä¸ weight çš„æ•°æ®ç±»å‹éœ€æ»¡è¶³æ•°æ®ç±»å‹æ¨å¯¼è§„åˆ™ï¼ˆå‚è§<a href="../../../docs/zh/context/äº’æ¨å¯¼å…³ç³».md">äº’æ¨å¯¼å…³ç³»</a>)ã€‚</li></ul>
     </td>
     <td>FLOATã€FLOAT16ã€BFLOAT16</td>
     <td>NDã€NCL</td>
     <td>3</td>
     <td>âˆš</td>
    </tr>
    <tr>
     <td>input</td>
     <td>è¾“å…¥</td>
     <td>å…¬å¼ä¸­çš„xï¼Œè¡¨ç¤ºå·ç§¯æ­£å‘è¾“å…¥ã€‚</td>
     <td>
       <ul>
        <li>æ”¯æŒç©ºTensorã€‚</li>
        <li>shapeä¸º(N,C<sub>in</sub>,H<sub>in</sub>)ã€‚</li>
        <li>æ•°æ®ç±»å‹ä¸ weight çš„æ•°æ®ç±»å‹éœ€æ»¡è¶³æ•°æ®ç±»å‹æ¨å¯¼è§„åˆ™ï¼ˆå‚è§<a href="../../../docs/zh/context/äº’æ¨å¯¼å…³ç³».md">äº’æ¨å¯¼å…³ç³»</a>)ã€‚</li></ul>
     </td>
     <td>FLOATã€FLOAT16ã€BFLOAT16</td>
     <td>NDã€NCL</td>
     <td>3</td>
     <td>âˆš</td>
    </tr>
    <tr>
     <td>weight</td>
     <td>è¾“å…¥</td>
     <td>å…¬å¼ä¸­çš„wï¼Œè¡¨ç¤ºå·ç§¯æƒé‡ã€‚</td>
     <td>
       <ul>
        <li>æ”¯æŒç©ºTensorã€‚</li>
        <li>shapeä¸º(C<sub>out</sub>,C<sub>in</sub>,K)ã€‚</li>
        <li>æ•°æ®ç±»å‹ä¸ inputã€self çš„æ•°æ®ç±»å‹éœ€æ»¡è¶³æ•°æ®ç±»å‹æ¨å¯¼è§„åˆ™ï¼ˆå‚è§<a href="../../../docs/zh/context/äº’æ¨å¯¼å…³ç³».md">äº’æ¨å¯¼å…³ç³»</a>)ã€‚</li>
      </ul>
     </td>
     <td>FLOATã€FLOAT16ã€BFLOAT16</td>
     <td>NDã€NCL</td>
     <td>3</td>
     <td>âˆš</td>
    </tr>
    <tr>
     <td>bias</td>
     <td>è¾“å…¥</td>
     <td>å…¬å¼ä¸­çš„bï¼Œè¡¨ç¤ºå·ç§¯åç½®ã€‚</td>
     <td>
       <ul>
        <li>shapeä¸º(C<sub>out</sub>)ã€‚</li>
        <li>ä¸€ç»´ä¸”ä¸ weight ç¬¬ä¸€ç»´ç›¸ç­‰ï¼Œä¸å…è®¸ä¼ å…¥ç©ºæŒ‡é’ˆã€‚</li>
        <li>æ•°æ®ç±»å‹ä¸selfã€weightä¸€è‡´ã€‚</li></ul>
     </td>
     <td>FLOATã€FLOAT16ã€BFLOAT16</td>
     <td>NDã€NCL</td>
     <td>1</td>
     <td>âˆš</td>
    </tr>
    <tr>
     <td>pad</td>
     <td>è¾“å…¥</td>
     <td>åå‘ä¼ æ’­è¿‡ç¨‹ä¸­åœ¨è¾“å…¥çš„Hç»´åº¦ä¸Šå·¦å³å¡«å……çš„ä¸ªæ•°ã€‚</td>
     <td>
       <ul><li>å¤§å°åº”è¯¥åœ¨[0,255]çš„èŒƒå›´å†…ã€‚</li></ul>
     </td>
     <td>INT64</td>
     <td>-</td>
     <td>-</td>
     <td>Ã—</td>
    </tr>
    <tr>
     <td>cubeMathType</td>
     <td>è¾“å…¥</td>
     <td>ç”¨äºåˆ¤æ–­Cubeå•å…ƒåº”è¯¥ä½¿ç”¨å“ªç§è®¡ç®—é€»è¾‘è¿›è¡Œè¿ç®—ã€‚</td>
     <td>
       æ”¯æŒçš„æšä¸¾å€¼å¦‚ä¸‹ï¼š
       <ul>
       <li>0ï¼šKEEP_DTYPEï¼Œä¿æŒè¾“å…¥çš„æ•°æ®ç±»å‹è¿›è¡Œè®¡ç®—ã€‚</li>
       <li>1ï¼šALLOW_FP32_DOWN_PRECISIONï¼Œå…è®¸å°†è¾“å…¥æ•°æ®é™ç²¾åº¦è®¡ç®—ã€‚</li>
       <li>2ï¼šUSE_FP16ï¼Œå…è®¸è½¬æ¢ä¸ºæ•°æ®ç±»å‹FLOAT16è¿›è¡Œè®¡ç®—ã€‚</li>
       <li>3ï¼šUSE_HF32ï¼Œå…è®¸è½¬æ¢ä¸ºæ•°æ®ç±»å‹HFLOAT32è®¡ç®—ã€‚</li>
       </ul>
     </td>
     <td>-</td>
     <td>-</td>
     <td>-</td>
     <td>Ã—</td>
    </tr>
    <tr>
     <td>gradInput</td>
     <td>è¾“å‡º</td>
     <td>å…¬å¼ä¸­çš„è¾“å…¥å¼ é‡xå¯¹Lçš„æ¢¯åº¦ã€‚</td>
     <td>
       <ul>
        <li>æ”¯æŒç©ºTensorã€‚</li>
        <li>æ•°æ®ç±»å‹ä¸inputç±»å‹ä¸€è‡´ã€‚</li>
        <li>shapeä¸º(N,C<sub>in</sub>,H<sub>in</sub>)ã€‚</li></ul>
     </td>
     <td>FLOATã€FLOAT16ã€BFLOAT16</td>
     <td>NDã€NCL</td>
     <td>-</td>
     <td>Ã—</td>
    </tr>
    <tr>
     <td>gradWeight</td>
     <td>è¾“å‡º</td>
     <td>å·ç§¯æ ¸æƒé‡å¼ é‡wå¯¹Lçš„æ¢¯åº¦ã€‚</td>
     <td>
       <ul><li>æ”¯æŒç©ºTensorã€‚</li>
       <li>æ•°æ®ç±»å‹ä¸weightç±»å‹ä¸€è‡´ã€‚</li>
       <li>shapeä¸º(C<sub>out</sub>,C<sub>in</sub>,K)ã€‚</li></ul>
     </td>
     <td>FLOATã€FLOAT16ã€BFLOAT16ã€HIFLOAT8ã€FLOAT8_E4M3FN</td>
     <td>NDã€NCL</td>
     <td>-</td>
     <td>Ã—</td>
    </tr>
    <tr>
     <td>gradBias</td>
     <td>è¾“å‡º</td>
     <td>åç½®bå¯¹Lçš„æ¢¯åº¦ã€‚</td>
     <td>
      <ul><li>æ”¯æŒç©ºTensorã€‚</li>
      <li>æ•°æ®ç±»å‹ä¸biasç±»å‹ä¸€è‡´ã€‚</li>
      <li>shapeä¸º(C<sub>out</sub>)ã€‚</li>
    </td>
     <td>FLOATã€FLOAT16ã€BFLOAT16</td>
     <td>NDã€NCL</td>
     <td>-</td>
     <td>Ã—</td>
    </tr>
    <tr>
     <td>workspaceSize</td>
     <td>è¾“å‡º</td>
     <td>è¿”å›éœ€è¦åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ã€‚</td>
     <td>-</td>
     <td>-</td>
     <td>-</td>
     <td>-</td>
     <td>Ã—</td>
    </tr>
    <tr>
     <td>executor</td>
     <td>è¾“å‡º</td>
     <td>è¿”å›opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
     <td>-</td>
     <td>-</td>
     <td>-</td>
     <td>-</td>
     <td>Ã—</td>
    </tr>
    </tbody>
  </table>

- **è¿”å›å€¼ï¼š**

  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

  ç¬¬ä¸€æ®µæ¥å£å®Œæˆå…¥å‚æ ¡éªŒï¼Œå‡ºç°ä»¥ä¸‹åœºæ™¯æ—¶æŠ¥é”™ï¼š

  <table style="undefined;table-layout: fixed; width: 1430px"><colgroup>
    <col style="width:250px">
    <col style="width:130px">
    <col style="width:1050px">
    </colgroup>
    <thead>
     <tr>
       <th>è¿”å›å€¼</th>
       <th>é”™è¯¯ç </th>
       <th>æè¿°</th>
     </tr>
    </thead>
    <tbody>
    <tr>
      <td>ACLNN_ERR_PARAM_NULLPTR</td>
      <td>161001</td>
      <td>ä¼ å…¥æŒ‡é’ˆç±»å‹å…¥å‚æ˜¯ç©ºæŒ‡é’ˆã€‚</td>
    </tr>
    <tr>
      <td rowspan="9">ACLNN_ERR_PARAM_INVALID</td>
      <td rowspan="9">161002</td>
      <td>selfï¼Œinputï¼Œweightï¼Œbiasï¼ŒgradInputï¼ŒgradWeightï¼ŒgradBiasçš„æ•°æ®ç±»å‹å’Œæ•°æ®æ ¼å¼ä¸åœ¨æ”¯æŒçš„èŒƒå›´ä¹‹å†…ã€‚</td>
    </tr>
    <tr>
      <td>selfï¼Œinputï¼Œweightï¼Œbiasæ•°æ®ç±»å‹ä¸ä¸€è‡´ã€‚</td>
    </tr>
    <tr>
      <td>gradInputï¼ŒgradWeightï¼ŒgradBiasçš„shapeä¸æ»¡è¶³infershapeç»“æœã€‚</td>
    </tr>
    <tr>
      <td>gradInputï¼ŒgradWeightï¼ŒgradBiasçš„shapeä¸­å­˜åœ¨å°äº0çš„å€¼ã€‚</td>
    </tr>
    <tr>
      <td>selfï¼Œinputï¼Œweightçš„dimä¸ä¸º3ã€‚</td>
    </tr>
    <tr>
      <td>biasçš„dimä¸ä¸º1ã€‚</td>
    </tr>
    <tr>
      <td>inputçš„ç¬¬ä¸‰ä¸ªç»´åº¦å€¼ä¸ç­‰äºweightçš„ç¬¬2ä¸ªç»´åº¦å€¼ã€‚</td>
    </tr>
    <tr>
      <td>biasçš„å€¼ä¸ç­‰äºweightçš„ç¬¬ä¸‰ä¸ªç»´åº¦å€¼ã€‚</td>
    </tr>
    <tr>
      <td>padå€¼ä¸æ»¡è¶³è¦æ±‚ã€‚</td>
    </tr>
    <tr>
      <td>ACLNN_ERR_INNER_NULLPTR</td>
      <td>561103</td>
      <td>APIå†…éƒ¨æ ¡éªŒé”™è¯¯ï¼Œé€šå¸¸ç”±äºè¾“å…¥æ•°æ®æˆ–å±æ€§çš„è§„æ ¼ä¸åœ¨æ”¯æŒçš„èŒƒå›´ä¹‹å†…å¯¼è‡´ã€‚</td>
      </tr>
      </tbody>
  </table>

## aclnnConvTbcBackward

- **å‚æ•°è¯´æ˜ï¼š**

  <table style="undefined;table-layout: fixed; width: 1400px"><colgroup>
       <col style="width:100px">
       <col style="width:100px">
       <col style="width:950px">
       </colgroup>
    <thead>
     <tr>
       <th>å‚æ•°å</th>
       <th>è¾“å…¥/è¾“å‡º</th>
       <th>æè¿°</th>
     </tr>
    </thead>
    <tbody>
     <tr>
       <td>workspace</td>
       <td>è¾“å…¥</td>
       <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå†…å­˜åœ°å€ã€‚</td>
     </tr>
     <tr>
       <td>workspaceSize</td>
       <td>è¾“å…¥</td>
       <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ï¼Œç”±ç¬¬ä¸€æ®µæ¥å£aclnnConvTbcBackwardGetWorkspaceSizeè·å–ã€‚</td>
     </tr>
     <tr>
       <td>executor</td>
       <td>è¾“å…¥</td>
       <td>opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
     </tr>
     <tr>
       <td>stream</td>
       <td>è¾“å…¥</td>
       <td>æŒ‡å®šæ‰§è¡Œä»»åŠ¡çš„Streamã€‚</td>
     </tr>
    </tbody>
  </table>


- **è¿”å›å€¼ï¼š**

  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

## çº¦æŸè¯´æ˜

- ç¡®å®šæ€§è®¡ç®—
  - aclnnConvTbcBackwardé»˜è®¤éç¡®å®šæ€§å®ç°ï¼Œæ”¯æŒé€šè¿‡aclrtCtxSetSysParamOptå¼€å¯ç¡®å®šæ€§ã€‚

  <table style="undefined;table-layout: fixed; width: 1396px"><colgroup>
  <col style="width: 168px">
  <col style="width: 404px">
  <col style="width: 429px">
  <col style="width: 395px">
    </colgroup>
   <thead>
    <tr>
     <th>çº¦æŸç±»å‹</th>
     <th><term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term></th>
     <th><term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ã€<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term></th>
     <th><term>Atlas è®­ç»ƒç³»åˆ—äº§å“</term></th>
   </tr>
   </thead>
   <tbody>
   <tr>
     <th scope="row">selfçº¦æŸ</th>
     <td>
      <ul>
        <li>æ”¯æŒ N ç»´åº¦å¤§äºç­‰äº 0ï¼Œæ”¯æŒ C ç»´åº¦å¤§äºç­‰äº 0ï¼ˆç­‰äº 0 çš„åœºæ™¯ä»…åœ¨ weight çš„ N ç»´åº¦ç­‰äº 0 æ—¶æ”¯æŒï¼‰ã€‚</li>
        <li>æ”¯æŒ L ç»´åº¦å¤§äºç­‰äº 0ï¼ˆç­‰äº 0 çš„åœºæ™¯ä»…åœ¨ self çš„ L ç»´åº¦ç­‰äº 0 æ—¶æ”¯æŒï¼‰ã€‚</li>
      </ul>
     </td>   
     <td colspan="2">
        <ul>æ”¯æŒ Nã€Cã€L ç»´åº¦å¤§äºç­‰äº 0ï¼ˆç­‰äº 0 çš„åœºæ™¯ä»…åœ¨ self çš„ N æˆ– C æˆ– L ç»´åº¦ç­‰äº 0 æ—¶æ”¯æŒï¼‰ã€‚</ul>
     </td>
   </tr>
   <tr>
     <th scope="row">inputçº¦æŸ</th>
     <td>
      <ul>input æ”¯æŒ Nã€C ç»´åº¦å¤§äºç­‰äº 0ï¼Œæ”¯æŒ L ç»´åº¦å¤§äºç­‰äº 0ï¼ˆç­‰äº 0 çš„åœºæ™¯ä»…åœ¨ out æ¨å¯¼çš„ L ç»´åº¦ä¹Ÿç­‰äº 0 æ—¶æ”¯æŒï¼‰ã€‚</ul>
      </td>   
     <td>
        <ul>input æ•°æ®ç±»å‹ä¸æ”¯æŒ HIFLOAT8ã€‚æ”¯æŒ Nã€Cã€L ç»´åº¦å¤§äºç­‰äº 0ã€‚</ul>
     </td>
     <td>
        <ul>input æ•°æ®ç±»å‹ä¸æ”¯æŒ BFLOAT16ã€HIFLOAT8ã€‚æ”¯æŒ Nã€Cã€L ç»´åº¦å¤§äºç­‰äº 0ã€‚</ul>
     </td>
   </tr>
   <tr>
     <th scope="row">weightçº¦æŸ</th>
     <td>
        <ul>
          <li>weight æ”¯æŒ Nã€C ç»´åº¦å¤§äºç­‰äº 0ï¼Œæ”¯æŒ L ç»´åº¦å¤§äºç­‰äº 0ï¼ˆç­‰äº 0 çš„åœºæ™¯ä»…åœ¨ out æ¨å¯¼çš„ L ç»´åº¦ä¹Ÿç­‰äº 0 æ—¶æ”¯æŒï¼‰ã€‚</li>
          <li>weight æ”¯æŒ N ç»´åº¦å¤§äºç­‰äº 0ï¼ˆç­‰äº 0 çš„åœºæ™¯ä»…åœ¨ bias çš„ N ç»´åº¦å’Œ out çš„ C ç»´åº¦ä¹Ÿç­‰äº 0 æ—¶æ”¯æŒï¼‰ï¼ŒC ç»´åº¦å¤§å°çš„æ”¯æŒæƒ…å†µä¸ self çš„ C ç»´åº¦ä¸€è‡´ï¼ŒL ç»´åº¦çš„å¤§å°åº”è¯¥åœ¨ [1,255] çš„èŒƒå›´å†…ã€‚</li>
        </ul>
     </td>   
     <td>
        <ul>
          weight æ•°æ®ç±»å‹ä¸æ”¯æŒ HIFLOAT8ã€‚æ”¯æŒ Nã€Cã€L ç»´åº¦å¤§äºç­‰äº 0ã€‚
        </ul>
     </td>
     <td>
        <ul>
          weight æ•°æ®ç±»å‹ä¸æ”¯æŒ BFLOAT16ã€HIFLOAT8ã€‚æ”¯æŒ Nã€Cã€L ç»´åº¦å¤§äºç­‰äº 0ã€‚
        </ul>
     </td>
   </tr>
   <tr>
     <th scope="row">dtypeçº¦æŸ</th>
     <td>
        <ul>åªæœ‰åœ¨gradWeightå‚æ•°ä¸­ï¼Œæ‰æ”¯æŒHIFLOAT8ã€FLOAT8_E4M3FNï¼Œåœ¨å…¶ä»–å‚æ•°ä¸­ä¸æ”¯æŒHIFLOAT8ã€FLOAT8_E4M3FNã€‚</ul>
     </td>   
     <td>
        <ul>ä¸æ”¯æŒHIFLOAT8ã€FLOAT8_E4M3FNã€‚</ul>
     </td>
     <td>
        <ul>ä¸æ”¯æŒBFLOAT16ã€HIFLOAT8ã€FLOAT8_E4M3FNã€‚</ul>
     </td>
   </tr>
   <tr>
     <th scope="row">cubeMathTypeè¯´æ˜</th>
     <td>
        <ul>
        <li>æšä¸¾å€¼ä¸º1ï¼šå½“è¾“å…¥æ˜¯FLOATï¼Œå¤„ç†å™¨è½¬æ¢ä¸ºHFLOAT32è®¡ç®—ã€‚å½“è¾“å…¥ä¸ºå…¶ä»–æ•°æ®ç±»å‹æ—¶ä¸åšå¤„ç†ã€‚</li>
        <li>æšä¸¾å€¼ä¸º2ï¼šå½“è¾“å…¥æ˜¯BFLOAT16æ—¶ä¸æ”¯æŒè¯¥é€‰é¡¹ã€‚</li>
        <li>æšä¸¾å€¼ä¸º3ï¼šå½“è¾“å…¥æ˜¯FLOATï¼Œè½¬æ¢ä¸ºHFLOAT32è®¡ç®—ã€‚å½“è¾“å…¥ä¸ºå…¶ä»–æ•°æ®ç±»å‹æ—¶ä¸æ”¯æŒè¯¥é€‰é¡¹ã€‚</li>
        </ul>
     </td>
     <td>
        <ul><li>æšä¸¾å€¼ä¸º0ï¼šå½“è¾“å…¥æ˜¯FLOATï¼ŒCubeè®¡ç®—å•å…ƒæš‚ä¸æ”¯æŒï¼Œå–0æ—¶ä¼šæŠ¥é”™ã€‚</li>
        <li>æšä¸¾å€¼ä¸º1ï¼šå½“è¾“å…¥æ˜¯FLOATï¼Œè½¬æ¢ä¸ºHFLOAT32 è®¡ç®—ã€‚å½“è¾“å…¥ä¸ºå…¶ä»–æ•°æ®ç±»å‹æ—¶ä¸åšå¤„ç†ã€‚</li>
        <li>æšä¸¾å€¼ä¸º2ï¼šå½“è¾“å…¥æ˜¯ BFLOAT16 ä¸æ”¯æŒè¯¥é€‰é¡¹ã€‚</li>
        <li>æšä¸¾å€¼ä¸º3ï¼šå½“è¾“å…¥æ˜¯FLOATï¼ŒCubeè®¡ç®—å•å…ƒæš‚ä¸æ”¯æŒï¼Œå–3æ—¶ä¼šæŠ¥é”™ã€‚</li>
        </ul>
     </td>
     <td>
        <ul><li>æšä¸¾å€¼ä¸º0ï¼šå½“è¾“å…¥æ˜¯FLOATï¼ŒCubeè®¡ç®—å•å…ƒæš‚ä¸æ”¯æŒï¼Œå–0æ—¶ä¼šæŠ¥é”™ã€‚</li>
        <li>æšä¸¾å€¼ä¸º1ï¼šå½“è¾“å…¥æ˜¯FLOATï¼Œè½¬æ¢ä¸ºFLOAT16è®¡ç®—ã€‚å½“è¾“å…¥ä¸ºå…¶ä»–æ•°æ®ç±»å‹æ—¶ä¸åšå¤„ç†ã€‚</li>
        <li>æšä¸¾å€¼ä¸º2ï¼šå½“è¾“å…¥æ˜¯ BFLOAT16 ä¸æ”¯æŒè¯¥é€‰é¡¹ã€‚</li>
        <li>æšä¸¾å€¼ä¸º3ï¼šæš‚æ—¶ä¸æ”¯æŒã€‚</li>
        </ul>
     </td>
   </tr>
   </tbody>
</table>

## è°ƒç”¨ç¤ºä¾‹

ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼Œä»…ä¾›å‚è€ƒï¼Œå…·ä½“ç¼–è¯‘å’Œæ‰§è¡Œè¿‡ç¨‹è¯·å‚è€ƒ[ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹](../../../docs/zh/context/ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹.md)ã€‚

```Cpp
#include <iostream>
#include <memory>
#include <vector>

#include "acl/acl.h"
#include "aclnnop/aclnn_convolution_backward.h"

#define CHECK_RET(cond, return_expr) \
    do {                             \
        if (!(cond)) {               \
            return_expr;             \
        }                            \
    } while (0)

#define CHECK_FREE_RET(cond, return_expr)        \
    do {                                         \
        if (!(cond)) {                           \
            Finalize(deviceId, stream); \
            return_expr;                         \
        }                                        \
    } while (0)

#define LOG_PRINT(message, ...)         \
    do {                                \
        printf(message, ##__VA_ARGS__); \
    } while (0)

int64_t GetShapeSize(const std::vector<int64_t> &shape)
{
    int64_t shapeSize = 1;
    for (auto i : shape) {
        shapeSize *= i;
    }
    return shapeSize;
}

int Init(int32_t deviceId, aclrtStream *stream)
{
    // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
    auto ret = aclInit(nullptr);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
    ret = aclrtSetDevice(deviceId);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
    ret = aclrtCreateStream(stream);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
    return 0;
}

template <typename T>
int CreateAclTensor(const std::vector<T> &hostData, const std::vector<int64_t> &shape, void **deviceAddr,
                    aclDataType dataType, aclTensor **tensor)
{
    auto size = GetShapeSize(shape) * sizeof(T);
    // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
    auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);
    // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®æ‹·è´åˆ°deviceä¾§å†…å­˜ä¸Š
    ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);

    // è®¡ç®—è¿ç»­tensorçš„strides
    std::vector<int64_t> strides(shape.size(), 1);
    for (int64_t i = shape.size() - 2; i >= 0; i--) {
        strides[i] = shape[i + 1] * strides[i + 1];
    }

    // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
    if (shape.size() == 4) {
        *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_NCHW,
                                  shape.data(), shape.size(), *deviceAddr);
    } else {
        *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_ND,
                                  shape.data(), shape.size(), *deviceAddr);
    }

    return 0;
}

void Finalize(int32_t deviceId, aclrtStream stream)
{
    aclrtDestroyStream(stream);
    aclrtResetDevice(deviceId);
    aclFinalize();
}

int aclnnConvTbcBackwardTest(int32_t deviceId, aclrtStream &stream)
{
    // 1. åˆå§‹åŒ–
    auto ret = Init(deviceId, &stream);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);
    // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
    std::vector<int64_t> selfShape = {5, 1, 2};
    std::vector<int64_t> inputShape = {5, 1, 2};
    std::vector<int64_t> weightShape = {1, 2, 2};
    std::vector<int64_t> biasShape = {2};
    const int64_t pad = 0;
    int8_t cubeMathType = 1;

    std::vector<int64_t> gradInputShape = {5, 1, 2};
    std::vector<int64_t> gradWeightShape = {1, 2, 2};
    std::vector<int64_t> gradBiasShape = {2};

    // åˆ›å»ºself aclTensor
    std::vector<float> selfData(GetShapeSize(selfShape), 1);
    aclTensor *self = nullptr;
    void *selfdeviceAddr = nullptr;
    ret = CreateAclTensor(selfData, selfShape, &selfdeviceAddr, aclDataType::ACL_FLOAT, &self);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> selfTensorPtr(self, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> selfdeviceAddrPtr(selfdeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºinput aclTensor
    std::vector<float> inputData(GetShapeSize(inputShape), 1);
    aclTensor *input = nullptr;
    void *inputdeviceAddr = nullptr;
    ret = CreateAclTensor(inputData, inputShape, &inputdeviceAddr, aclDataType::ACL_FLOAT, &input);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> inputTensorPtr(input, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> inputDeviceAddrPtr(inputdeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºweight aclTensor
    std::vector<float> weightData(GetShapeSize(weightShape), 1);
    aclTensor *weight = nullptr;
    void *weightDeviceAddr = nullptr;
    ret = CreateAclTensor(weightData, weightShape, &weightDeviceAddr, aclDataType::ACL_FLOAT, &weight);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> weightTensorPtr(weight, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> weightDeviceAddrPtr(weightDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºbias aclTensor
    std::vector<float> biasData(GetShapeSize(biasShape), 1);
    aclTensor *bias = nullptr;
    void *biasDeviceAddr = nullptr;
    ret = CreateAclTensor(biasData, biasShape, &biasDeviceAddr, aclDataType::ACL_FLOAT, &bias);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> biasTensorPtr(bias, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> biasDeviceAddrPtr(biasDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºgradInput aclTensor
    std::vector<float> gradInputData(GetShapeSize(inputShape), 1);
    aclTensor *gradInput = nullptr;
    void *gradInputDeviceAddr = nullptr;
    ret = CreateAclTensor(gradInputData, inputShape, &gradInputDeviceAddr, aclDataType::ACL_FLOAT, &gradInput);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> gradInputTensorPtr(gradInput, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> gradInputDeviceAddrPtr(gradInputDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºgradWeight aclTensor
    std::vector<float> gradWeightData(GetShapeSize(weightShape), 1);
    aclTensor *gradWeight = nullptr;
    void *gradWeightDeviceAddr = nullptr;
    ret = CreateAclTensor(gradWeightData, weightShape, &gradWeightDeviceAddr, aclDataType::ACL_FLOAT, &gradWeight);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> gradWeightTensorPtr(gradWeight, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> gradWeightDeviceAddrPtr(gradWeightDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // åˆ›å»ºgradBias aclTensor
    std::vector<float> gradBiasData(GetShapeSize(gradBiasShape), 1);
    aclTensor *gradBias = nullptr;
    void *gradBiasDeviceAddr = nullptr;
    ret = CreateAclTensor(gradBiasData, gradBiasShape, &gradBiasDeviceAddr, aclDataType::ACL_FLOAT, &gradBias);
    std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor *)> gradBiasTensorPtr(gradBias, aclDestroyTensor);
    std::unique_ptr<void, aclError (*)(void *)> gradBiasDeviceAddrPtr(gradBiasDeviceAddr, aclrtFree);
    CHECK_FREE_RET(ret == ACL_SUCCESS, return ret);

    // 3. è°ƒç”¨CANNç®—å­åº“APIï¼Œéœ€è¦ä¿®æ”¹ä¸ºå…·ä½“çš„Apiåç§°
    uint64_t workspaceSize = 0;
    aclOpExecutor *executor;
    // è°ƒç”¨aclnnConvTbcBackwardç¬¬ä¸€æ®µæ¥å£
    ret = aclnnConvTbcBackwardGetWorkspaceSize(self, input, weight, bias, pad, cubeMathType, gradInput, gradWeight,
                                               gradBias, &workspaceSize, &executor);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnConvTbcBackwardGetWorkspaceSize failed. ERROR: %d\n", ret);
                   return ret);
    // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
    void *workspaceAddr = nullptr;
    std::unique_ptr<void, aclError (*)(void *)> workspaceAddrPtr(nullptr, aclrtFree);
    if (workspaceSize > 0) {
        ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
        CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret);
        workspaceAddrPtr.reset(workspaceAddr);
    }
    // è°ƒç”¨aclnnConvTbcBackwardç¬¬äºŒæ®µæ¥å£
    ret = aclnnConvTbcBackward(workspaceAddr, workspaceSize, executor, stream);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnConvTbcBackward failed. ERROR: %d\n", ret); return ret);
    // 4. ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
    ret = aclrtSynchronizeStream(stream);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);
    // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
    auto size = GetShapeSize(gradInputShape);
    std::vector<float> gradInputResult(size, 0);
    ret = aclrtMemcpy(gradInputResult.data(), gradInputResult.size() * sizeof(gradInputResult[0]), gradInputDeviceAddr,
                      size * sizeof(gradInputResult[0]), ACL_MEMCPY_DEVICE_TO_HOST);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret);
                   return ret);
    for (int64_t i = 0; i < size; i++) {
        LOG_PRINT("gradInputResult[%ld] is: %f\n", i, gradInputResult[i]);
    }

    size = GetShapeSize(gradWeightShape);
    std::vector<float> gradWeightResult(size, 0);
    ret = aclrtMemcpy(gradWeightResult.data(), gradWeightResult.size() * sizeof(gradWeightResult[0]), gradWeightDeviceAddr,
                      size * sizeof(gradWeightResult[0]), ACL_MEMCPY_DEVICE_TO_HOST);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret);
                   return ret);
    for (int64_t i = 0; i < size; i++) {
        LOG_PRINT("gradWeightResult[%ld] is: %f\n", i, gradWeightResult[i]);
    }

    size = GetShapeSize(gradBiasShape);
    std::vector<float> gradBiasResult(size, 0);
    ret = aclrtMemcpy(gradBiasResult.data(), gradBiasResult.size() * sizeof(gradBiasResult[0]), gradBiasDeviceAddr,
                      size * sizeof(gradBiasResult[0]), ACL_MEMCPY_DEVICE_TO_HOST);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret);
                   return ret);
    for (int64_t i = 0; i < size; i++) {
        LOG_PRINT("gradBiasResult[%ld] is: %f\n", i, gradBiasResult[i]);
    }
    return ACL_SUCCESS;
}

int main()
{
    // 1. ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–
    // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
    int32_t deviceId = 0;
    aclrtStream stream;
    auto ret = aclnnConvTbcBackwardTest(deviceId, stream);
    CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnConvTbcBackwardTest failed. ERROR: %d\n", ret); return ret);

    Finalize(deviceId, stream);
    return 0;
}
```
